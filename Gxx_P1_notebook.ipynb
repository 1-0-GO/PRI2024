{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>PRI 2023/24: first project delivery</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GROUP 11**\n",
    "- Francisco Martins, 99068\n",
    "- Tunahan Güneş, 108108\n",
    "- Sebastian Weidinger, 111612"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Part I: demo of facilities</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    texts = []\n",
    "    file_paths = []\n",
    "    for folder in os.listdir(path):\n",
    "        category_path = os.path.join(path, folder)\n",
    "        texts.append([])\n",
    "        for file in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, file)\n",
    "            file_paths.append(file_path)\n",
    "            with open(file_path, \"r\", errors=\"ignore\") as f:\n",
    "                text = f.read()\n",
    "                texts[-1].append(text)\n",
    "                \n",
    "    print(\"Number of Categories:\",len(os.listdir(path)))\n",
    "    for i in range(len(os.listdir(path))):\n",
    "        print(\"Number of Articles in\", \"'\"+os.listdir(path)[i]+\"'\", \"Category:\",len(texts[i]))\n",
    "    return file_paths, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: BBC News Summary\\BBC News Summary\\News Articles\n",
      "Number of Categories: 5\n",
      "Number of Articles in 'business' Category: 510\n",
      "Number of Articles in 'entertainment' Category: 386\n",
      "Number of Articles in 'politics' Category: 417\n",
      "Number of Articles in 'sport' Category: 511\n",
      "Number of Articles in 'tech' Category: 401\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(\"BBC News Summary\", \"BBC News Summary\", \"News Articles\")\n",
    "print(\"Dataset path:\", dataset_path)\n",
    "file_paths, categorized_articles = read_files(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.\n",
      "\n",
      "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n",
      "\n",
      "Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\n",
      "\n",
      "Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\n",
      "\n",
      "TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n",
      "\n",
      "['BBC News Summary\\\\BBC News Summary\\\\News Articles\\\\business\\\\509.txt', 'BBC News Summary\\\\BBC News Summary\\\\News Articles\\\\business\\\\510.txt', 'BBC News Summary\\\\BBC News Summary\\\\News Articles\\\\entertainment\\\\001.txt', 'BBC News Summary\\\\BBC News Summary\\\\News Articles\\\\entertainment\\\\002.txt']\n"
     ]
    }
   ],
   "source": [
    "#Examplary text. The structure of the read file is: articles[category_no][document_no]. \n",
    "print(categorized_articles[0][0])\n",
    "print(file_paths[508:512])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) **Indexing** (preprocessing and indexing options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from typing import Union\n",
    "import nltk\n",
    "import numpy as np\n",
    "import math\n",
    "import sklearn\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter, defaultdict\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten list to get uncategorized collection \n",
    "def flatten(lists) -> list: \n",
    "    return [element for sublist in lists for element in sublist]\n",
    "\n",
    "articles = flatten(categorized_articles)\n",
    "N = len(articles)\n",
    "dict_path_to_articleID = {path:i for i, path in enumerate(file_paths)}\n",
    "def map_path_to_articleID(path):\n",
    "    path = os.path.normpath(path)\n",
    "    return dict_path_to_articleID.get(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverted Index Structure \n",
    " \n",
    "Each term points to a dictionary of document identifier and the term frequency in the document.\n",
    "\n",
    "t1 -> {doc1: TF, doc5: TF, ...}\\\n",
    "t2 -> {doc7: TF, doc8: TF, ...}\\\n",
    "...\n",
    "t2 -> [DF, {doc7: [TF_(t2, doc7), {s1: TF, s4: TF, ...}], doc8: [TF_(t2, doc8), {s2: TF, s4: TF, ...}], ...}]\\\n",
    "\n",
    "use class structure\n",
    "\n",
    "TODO: \n",
    "* Optimize structure?\n",
    "    * Is there a more efficient way? \n",
    "    * Add maybe pointers to sentences and their term frequency? -> Faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_width = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TermFrequencies: \n",
    "    def __init__(self) -> None:\n",
    "        self.tf_d_t = 0\n",
    "        self.sent_tf = list()\n",
    "\n",
    "    def add_sentence(self, sent_number, term_frequency):\n",
    "        self.sent_tf.append((sent_number, term_frequency))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        padding = 5 - len(str(self.tf_d_t))\n",
    "        return f'TF_d_t: {self.tf_d_t}{\" \" * padding}TF_per_sentence: {self.sent_tf}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndexEntry:\n",
    "    def __init__(self) -> None:\n",
    "        self.df_term = 0\n",
    "        self.term_dict = defaultdict(TermFrequencies)\n",
    "    \n",
    "    def get_document(self, document):\n",
    "        return self.term_dict.get(document, None)\n",
    "\n",
    "    def get_or_default_document(self, document):\n",
    "        return self.term_dict[document]\n",
    "\n",
    "    def update_document(self, document, new_value):\n",
    "        self.term_dict[document] = new_value\n",
    "    \n",
    "    def __repr__(self):\n",
    "        out = f'Document Frequency: {self.df_term}\\n {\" \" * (max_width+2)} Term frequencies:\\n'\n",
    "        for doc_number, tfs in self.term_dict.items():\n",
    "            padding = 5 - len(str(doc_number))\n",
    "            out += f'{\" \" * (max_width + 3)} Doc {doc_number}{\" \" * padding}→ {tfs}\\n'\n",
    "        return out\n",
    "    \n",
    "    def calculate_df(self):\n",
    "        self.df_term = len(self.term_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndex:\n",
    "    def __init__(self, collection_size) -> None:\n",
    "        self.inverted_index = defaultdict(InvertedIndexEntry)\n",
    "        self.sentence_lengths = list()\n",
    "        self.indexing_time = 0\n",
    "        self.N = collection_size\n",
    "    \n",
    "    def __repr__(self):\n",
    "        out = f'Time to index: {self.indexing_time}\\nInverted Index:\\n'\n",
    "        for term, entry in self.inverted_index.items():\n",
    "            padding = max_width - len(term)\n",
    "            out += f'{term} {\" \" * padding} → {entry}\\n'\n",
    "        return out\n",
    "\n",
    "    def get_or_default(self, term, document):\n",
    "        return self.inverted_index[term].get_or_default_document(document)\n",
    "    \n",
    "    def update(self, term, document, new_value):\n",
    "        self.inverted_index[term].update_document(document, new_value)\n",
    "    \n",
    "    def set_indexing_time(self, indexing_time):\n",
    "        self.indexing_time = indexing_time\n",
    "    \n",
    "    def calculate_dfs(self):\n",
    "        for entry in self.inverted_index.values():\n",
    "            entry.calculate_df()  \n",
    "    \n",
    "    def get_sentence_lengths(self, document):\n",
    "        return self.sentence_lengths[document]\n",
    "\n",
    "    def get_document_info(self, document):          \n",
    "        info = {'Vocabulary': [], 'DF_t': [], 'TF_d_t': [], 'TF/sentence': []}\n",
    "        for term, entry in self.inverted_index.items():\n",
    "            doc_tfs = entry.get_document(document)\n",
    "            if doc_tfs == None:\n",
    "                continue\n",
    "            info['Vocabulary'].append(term)\n",
    "            info['DF_t'].append(entry.df_term)\n",
    "            info['TF_d_t'].append(doc_tfs.tf_d_t)\n",
    "            info['TF/sentence'].append(str(doc_tfs.sent_tf))\n",
    "        return info\n",
    "    \n",
    "    def doc_to_string(self, document):\n",
    "        out = f'Document {document} vocabulary and term frequencies:\\n'\n",
    "        info = self.get_document_info(document)\n",
    "        table = zip(*info.values())\n",
    "        headers = info.keys()\n",
    "        return out + tabulate(table, headers, tablefmt=\"pretty\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "indexing(D,args)\n",
    "    @input document collection D and optional arguments on text preprocessing\n",
    "\n",
    "    @behavior preprocesses the collection and, using existing libraries, \n",
    "    builds an inverted index with the relevant statistics for the subsequent summarization functions\n",
    "    \n",
    "    @output pair with the inverted index I and indexing time\n",
    "'''\n",
    "def indexing(articles, args=None) -> InvertedIndex:\n",
    "    start_time = time.time()\n",
    "    inverted_index = InvertedIndex(len(articles))\n",
    "\n",
    "    # tokenizer split words and keep hyphons e.g. state-of-the-art\n",
    "    tokenizer = RegexpTokenizer(r'[\\w|-]+')\n",
    "\n",
    "    # loop through collection \n",
    "    for article_id, article in enumerate(articles): \n",
    "        # split into sentences\n",
    "        sents = nltk.sent_tokenize(article)\n",
    "        # remove title (not needed for summarization task)\n",
    "        sents = sents[1:]\n",
    "        # save words per sent in list \n",
    "        tokenized_sentences = [tokenizer.tokenize(sent.lower()) for sent in sents]\n",
    "        # calculate length of the sentences in the article\n",
    "        sent_lengths = [len(sentence_terms) for sentence_terms in tokenized_sentences]\n",
    "        inverted_index.sentence_lengths.append(sent_lengths)\n",
    "        # count the term frequencies per sentence\n",
    "        term_counter_per_sent = [Counter(sentence_terms) for sentence_terms in tokenized_sentences]\n",
    "        for sent_number, term_counter in enumerate(term_counter_per_sent):\n",
    "            for term in term_counter: \n",
    "                tf = term_counter[term]\n",
    "                term_document_tfs = inverted_index.get_or_default(term, article_id)\n",
    "                term_document_tfs.tf_d_t += tf \n",
    "                term_document_tfs.add_sentence(sent_number, tf)\n",
    "                inverted_index.update(term, article_id, term_document_tfs)\n",
    "    inverted_index.calculate_dfs()\n",
    "    end_time = time.time()\n",
    "    indexing_time = end_time - start_time\n",
    "    inverted_index.set_indexing_time(indexing_time)\n",
    "    return inverted_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = 'Title. The little white little rabbit. The person played with the ball.'\n",
    "s1 = 'Title. The white rabbit\\'s ball. Rabbit rabbit ball rabbit.'\n",
    "s2 = 'Title.  White, the little white rabbit. Little, little.'\n",
    "test = [s0, s1, s2]\n",
    "I_test = indexing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to index: 0.0004773139953613281\n",
      "Inverted Index:\n",
      "the                   → Document Frequency: 3\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 3    TF_per_sentence: [(0, 1), (1, 2)]\n",
      "                        Doc 1    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "                        Doc 2    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "\n",
      "little                → Document Frequency: 2\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 2    TF_per_sentence: [(0, 2)]\n",
      "                        Doc 2    → TF_d_t: 3    TF_per_sentence: [(0, 1), (1, 2)]\n",
      "\n",
      "white                 → Document Frequency: 3\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "                        Doc 1    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "                        Doc 2    → TF_d_t: 2    TF_per_sentence: [(0, 2)]\n",
      "\n",
      "rabbit                → Document Frequency: 3\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "                        Doc 1    → TF_d_t: 4    TF_per_sentence: [(0, 1), (1, 3)]\n",
      "                        Doc 2    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "\n",
      "person                → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "\n",
      "played                → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "\n",
      "with                  → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "\n",
      "ball                  → Document Frequency: 2\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "                        Doc 1    → TF_d_t: 2    TF_per_sentence: [(0, 1), (1, 1)]\n",
      "\n",
      "s                     → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 1    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(I_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 2 vocabulary and term frequencies:\n",
      "+------------+------+--------+------------------+\n",
      "| Vocabulary | DF_t | TF_d_t |   TF/sentence    |\n",
      "+------------+------+--------+------------------+\n",
      "|    the     |  3   |   1    |     [(0, 1)]     |\n",
      "|   little   |  2   |   3    | [(0, 1), (1, 2)] |\n",
      "|   white    |  3   |   2    |     [(0, 2)]     |\n",
      "|   rabbit   |  3   |   1    |     [(0, 1)]     |\n",
      "+------------+------+--------+------------------+\n"
     ]
    }
   ],
   "source": [
    "print(I_test.doc_to_string(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = indexing(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23, 13, 20, 13, 10, 18, 21, 28, 24, 12, 37, 24, 25, 20, 20, 20, 24, 31, 21], [24, 19, 12, 36, 37, 24, 10, 26, 33, 14, 40, 22, 42, 24]]\n"
     ]
    }
   ],
   "source": [
    "print(I.sentence_lengths[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 508 vocabulary and term frequencies:\n",
      "+------------------------+------+--------+--------------------------------------------------------------------------------------------------------------+\n",
      "|       Vocabulary       | DF_t | TF_d_t |                                                 TF/sentence                                                  |\n",
      "+------------------------+------+--------+--------------------------------------------------------------------------------------------------------------+\n",
      "|          the           | 2225 |   26   | [(0, 1), (1, 1), (2, 1), (4, 3), (5, 1), (6, 2), (7, 3), (8, 2), (9, 1), (10, 2), (11, 4), (12, 2), (13, 3)] |\n",
      "|           is           | 1885 |   2    |                                              [(1, 1), (11, 1)]                                               |\n",
      "|          one           | 992  |   5    |                                          [(1, 1), (8, 1), (10, 3)]                                           |\n",
      "|           of           | 2192 |   16   |     [(0, 1), (1, 1), (2, 1), (4, 2), (5, 1), (7, 2), (8, 2), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1)]     |\n",
      "|        biggest         | 205  |   2    |                                               [(0, 1), (8, 1)]                                               |\n",
      "|           in           | 2197 |   7    |                          [(1, 1), (4, 1), (5, 1), (7, 1), (9, 1), (10, 1), (12, 1)]                          |\n",
      "|          from          | 1520 |   2    |                                               [(4, 1), (8, 1)]                                               |\n",
      "|          and           | 2204 |   8    |                              [(0, 2), (4, 1), (5, 1), (7, 1), (9, 1), (12, 2)]                               |\n",
      "|          said          | 1880 |   2    |                                              [(9, 1), (12, 1)]                                               |\n",
      "|           to           | 2204 |   12   |                          [(4, 2), (5, 1), (6, 2), (7, 1), (9, 3), (10, 2), (12, 1)]                          |\n",
      "|           11           | 185  |   1    |                                                   [(7, 1)]                                                   |\n",
      "|          were          | 1104 |   2    |                                               [(2, 1), (9, 1)]                                               |\n",
      "|           a            | 2200 |   9    |                              [(3, 1), (4, 2), (8, 2), (9, 1), (11, 2), (12, 1)]                              |\n",
      "|           at           | 1711 |   1    |                                                  [(10, 1)]                                                   |\n",
      "|          for           | 2038 |   3    |                                          [(7, 1), (10, 1), (13, 1)]                                          |\n",
      "|          time          | 722  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|           on           | 1966 |   1    |                                                   [(6, 1)]                                                   |\n",
      "|          that          | 1832 |   6    |                                  [(3, 1), (7, 1), (9, 1), (11, 1), (12, 2)]                                  |\n",
      "|           it           | 1896 |   2    |                                              [(8, 1), (11, 1)]                                               |\n",
      "|          but           | 1625 |   5    |                                   [(0, 1), (1, 1), (4, 1), (6, 1), (9, 1)]                                   |\n",
      "|        business        | 255  |   4    |                                      [(2, 1), (3, 1), (7, 1), (10, 1)]                                       |\n",
      "|          had           | 1207 |   2    |                                                  [(12, 2)]                                                   |\n",
      "|          has           | 1615 |   2    |                                              [(8, 1), (10, 1)]                                               |\n",
      "|         three          | 528  |   1    |                                                  [(13, 1)]                                                   |\n",
      "|           s            | 2024 |   1    |                                                   [(9, 1)]                                                   |\n",
      "|        service         | 237  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|       customers        | 106  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|          also          | 1264 |   1    |                                                   [(9, 1)]                                                   |\n",
      "|           us           | 766  |   1    |                                                  [(11, 1)]                                                   |\n",
      "|        exchange        |  94  |   1    |                                                  [(12, 1)]                                                   |\n",
      "|        slightly        |  58  |   1    |                                                   [(8, 1)]                                                   |\n",
      "|          when          | 829  |   2    |                                              [(2, 1), (11, 1)]                                               |\n",
      "|         while          | 578  |   1    |                                                  [(12, 1)]                                                   |\n",
      "|          was           | 1747 |   1    |                                                  [(11, 1)]                                                   |\n",
      "|           or           | 835  |   1    |                                                   [(8, 1)]                                                   |\n",
      "|          all           | 884  |   2    |                                               [(4, 1), (5, 1)]                                               |\n",
      "|         chief          | 323  |   4    |                                      [(6, 1), (9, 1), (12, 1), (13, 1)]                                      |\n",
      "|       executive        | 226  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|         growth         | 225  |   1    |                                                   [(1, 1)]                                                   |\n",
      "|         around         | 303  |   1    |                                                   [(6, 1)]                                                   |\n",
      "|           as           | 1611 |   3    |                                              [(8, 1), (11, 2)]                                               |\n",
      "|          into          | 737  |   1    |                                                   [(7, 1)]                                                   |\n",
      "|        already         | 372  |   1    |                                                   [(7, 1)]                                                   |\n",
      "|          deal          | 233  |   1    |                                                   [(6, 1)]                                                   |\n",
      "|          with          | 1798 |   3    |                                          [(6, 1), (8, 1), (12, 1)]                                           |\n",
      "|         europe         | 240  |   2    |                                               [(1, 1), (5, 1)]                                               |\n",
      "|          new           | 896  |   2    |                                              [(5, 1), (12, 1)]                                               |\n",
      "|         dollar         |  92  |   1    |                                                  [(11, 1)]                                                   |\n",
      "|           1            | 443  |   2    |                                              [(12, 1), (13, 1)]                                              |\n",
      "|          euro          |  48  |   1    |                                                  [(12, 1)]                                                   |\n",
      "|         about          | 955  |   3    |                                           [(2, 1), (7, 1), (8, 1)]                                           |\n",
      "|         months         | 345  |   1    |                                                  [(13, 1)]                                                   |\n",
      "|           mr           | 790  |   1    |                                                  [(12, 1)]                                                   |\n",
      "|         after          | 916  |   2    |                                               [(1, 1), (4, 1)]                                               |\n",
      "|          much          | 440  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|          more          | 1074 |   3    |                                              [(4, 1), (12, 2)]                                               |\n",
      "|          can           | 804  |   1    |                                                   [(6, 1)]                                                   |\n",
      "|          year          | 956  |   2    |                                              [(8, 1), (11, 1)]                                               |\n",
      "|        worries         |  27  |   1    |                                                   [(0, 1)]                                                   |\n",
      "|           do           | 589  |   1    |                                                   [(7, 1)]                                                   |\n",
      "|          have          | 1601 |   3    |                                          [(6, 1), (7, 1), (10, 1)]                                           |\n",
      "|         prices         | 143  |   1    |                                                   [(0, 1)]                                                   |\n",
      "|         fallen         |  43  |   1    |                                                   [(8, 1)]                                                   |\n",
      "|         rates          | 103  |   1    |                                                  [(12, 1)]                                                   |\n",
      "|           -            | 1071 |   7    |                                      [(1, 2), (4, 2), (10, 2), (13, 1)]                                      |\n",
      "|          many          | 524  |   1    |                                                   [(6, 1)]                                                   |\n",
      "|         could          | 838  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|           be           | 1705 |   2    |                                               [(4, 1), (6, 1)]                                               |\n",
      "|         result         | 188  |   1    |                                                   [(8, 1)]                                                   |\n",
      "|          both          | 392  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|         firms          | 200  |   1    |                                                   [(1, 1)]                                                   |\n",
      "|          are           | 1420 |   4    |                                       [(0, 1), (1, 1), (3, 1), (5, 1)]                                       |\n",
      "|           so           | 654  |   1    |                                                   [(7, 1)]                                                   |\n",
      "|         money          | 270  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|          not           | 1345 |   3    |                                          [(0, 1), (1, 1), (11, 1)]                                           |\n",
      "|          they          | 1134 |   3    |                                           [(3, 1), (7, 1), (9, 1)]                                           |\n",
      "|          2004          | 370  |   1    |                                                  [(13, 1)]                                                   |\n",
      "|         costs          | 150  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|          last          | 880  |   2    |                                              [(8, 1), (13, 1)]                                               |\n",
      "|        decline         |  53  |   1    |                                                  [(11, 1)]                                                   |\n",
      "|      competition       | 139  |   2    |                                               [(0, 1), (8, 1)]                                               |\n",
      "|        low-cost        |  16  |   3    |                                           [(0, 1), (6, 1), (8, 1)]                                           |\n",
      "|         united         | 158  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|         states         |  87  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|        example         |  99  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|         world          | 618  |   2    |                                              [(6, 1), (13, 1)]                                               |\n",
      "|       suggested        |  97  |   1    |                                                  [(12, 1)]                                                   |\n",
      "|         global         | 146  |   4    |                                          [(3, 1), (9, 1), (10, 2)]                                           |\n",
      "|         leader         | 181  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|          home          | 351  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|          two           | 780  |   1    |                                                   [(2, 1)]                                                   |\n",
      "|         parts          |  48  |   1    |                                                   [(7, 1)]                                                   |\n",
      "|         their          | 1073 |   7    |                                  [(0, 1), (2, 1), (7, 1), (9, 3), (12, 1)]                                   |\n",
      "|          just          | 596  |   1    |                                                   [(8, 1)]                                                   |\n",
      "|        suggests        |  61  |   1    |                                                  [(11, 1)]                                                   |\n",
      "|        through         | 396  |   1    |                                                   [(6, 1)]                                                   |\n",
      "|       according        | 280  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|       favourable       |  9   |   1    |                                                  [(12, 1)]                                                   |\n",
      "|         there          | 955  |   1    |                                                   [(1, 1)]                                                   |\n",
      "|         number         | 476  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|         called         | 247  |   1    |                                                   [(5, 1)]                                                   |\n",
      "|           uk           | 455  |   1    |                                                   [(1, 1)]                                                   |\n",
      "|         brown          | 125  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|       countries        | 171  |   2    |                                               [(7, 1), (9, 1)]                                               |\n",
      "|         large          | 132  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|          oil           | 106  |   1    |                                                   [(0, 1)]                                                   |\n",
      "|        markets         |  81  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|         years          | 642  |   2    |                                               [(1, 1), (2, 1)]                                               |\n",
      "|       companies        | 258  |   6    |                              [(4, 1), (5, 1), (8, 1), (9, 1), (10, 1), (12, 1)]                              |\n",
      "|          say           | 386  |   2    |                                               [(3, 1), (7, 1)]                                               |\n",
      "|         nearly         |  91  |   1    |                                                   [(2, 1)]                                                   |\n",
      "|         during         | 344  |   1    |                                                  [(13, 1)]                                                   |\n",
      "|          same          | 295  |   1    |                                                   [(2, 1)]                                                   |\n",
      "|         trend          |  57  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|          hurt          |  32  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|         region         |  39  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|           30           | 175  |   2    |                                              [(2, 1), (12, 1)]                                               |\n",
      "|        decided         | 113  |   1    |                                                   [(6, 1)]                                                   |\n",
      "|         bosses         |  17  |   2    |                                               [(2, 1), (7, 1)]                                               |\n",
      "|          how           | 426  |   1    |                                                   [(6, 1)]                                                   |\n",
      "|       currently        | 224  |   1    |                                                   [(5, 1)]                                                   |\n",
      "|         moved          |  87  |   1    |                                                   [(7, 1)]                                                   |\n",
      "|          seen          | 265  |   1    |                                                  [(11, 1)]                                                   |\n",
      "|        another         | 306  |   1    |                                                   [(7, 1)]                                                   |\n",
      "|        quality         |  83  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|         facing         |  78  |   1    |                                                   [(3, 1)]                                                   |\n",
      "|          risk          |  84  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|         rapid          |  26  |   1    |                                                  [(11, 1)]                                                   |\n",
      "|       corporate        |  63  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|        growing         | 122  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|           28           |  60  |   1    |                                                   [(7, 1)]                                                   |\n",
      "|          ago           | 194  |   2    |                                              [(2, 1), (11, 1)]                                               |\n",
      "|         future         | 248  |   1    |                                                   [(7, 1)]                                                   |\n",
      "|        complex         |  36  |   1    |                                                   [(5, 1)]                                                   |\n",
      "|       positions        |  25  |   1    |                                                  [(12, 1)]                                                   |\n",
      "|          huge          | 171  |   1    |                                                  [(11, 1)]                                                   |\n",
      "|         survey         |  67  |   4    |                                      [(2, 1), (7, 1), (11, 1), (13, 1)]                                      |\n",
      "|          even          | 348  |   1    |                                                  [(11, 1)]                                                   |\n",
      "|        calling         |  40  |   1    |                                                   [(8, 1)]                                                   |\n",
      "|         forces         |  29  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|       operations       |  60  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|         polled         |  5   |   1    |                                                   [(7, 1)]                                                   |\n",
      "|       conducted        |  29  |   1    |                                                   [(2, 1)]                                                   |\n",
      "|          your          | 163  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|          work          | 390  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|         moving         |  64  |   1    |                                                   [(5, 1)]                                                   |\n",
      "|        adjusted        |  12  |   1    |                                                  [(12, 1)]                                                   |\n",
      "|         clear          | 184  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|      competitors       |  21  |   1    |                                                   [(6, 1)]                                                   |\n",
      "|       meanwhile        | 127  |   1    |                                                   [(5, 1)]                                                   |\n",
      "|         others         | 157  |   1    |                                                  [(12, 1)]                                                   |\n",
      "|          harm          |  23  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|          plan          | 145  |   1    |                                                   [(7, 1)]                                                   |\n",
      "|       prospects        |  24  |   1    |                                                   [(2, 1)]                                                   |\n",
      "|       confidence       |  82  |   1    |                                                   [(1, 1)]                                                   |\n",
      "|       standards        |  65  |   1    |                                                   [(5, 1)]                                                   |\n",
      "|       concerned        | 104  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|     third-largest      |  4   |   1    |                                                  [(11, 1)]                                                   |\n",
      "|        cheaper         |  35  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|        problem         | 181  |   1    |                                                  [(11, 1)]                                                   |\n",
      "|     sarbanes-oxley     |  4   |   1    |                                                   [(4, 1)]                                                   |\n",
      "|          act           | 128  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|        scandals        |  8   |   1    |                                                   [(4, 1)]                                                   |\n",
      "|         enron          |  10  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|        worldcom        |  15  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|         stock          |  86  |   1    |                                                   [(5, 1)]                                                   |\n",
      "|         middle         |  63  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|        leaders         |  67  |   1    |                                                   [(3, 1)]                                                   |\n",
      "|           t            | 646  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|        provide         | 120  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|       executives       |  44  |   3    |                                          [(6, 1), (12, 1), (13, 1)]                                          |\n",
      "|         across         | 182  |   1    |                                                   [(5, 1)]                                                   |\n",
      "|      significant       |  93  |   1    |                                                   [(8, 1)]                                                   |\n",
      "|          red           |  62  |   1    |                                                   [(6, 1)]                                                   |\n",
      "|          slow          |  55  |   1    |                                                   [(1, 1)]                                                   |\n",
      "|        western         |  27  |   1    |                                                   [(1, 1)]                                                   |\n",
      "|         locked         |  16  |   1    |                                                  [(12, 1)]                                                   |\n",
      "|         moves          |  26  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|          east          |  80  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|          lot           | 239  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|         cited          |  13  |   1    |                                                  [(11, 1)]                                                   |\n",
      "|         doing          | 169  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|       accounting       |  24  |   1    |                                                   [(5, 1)]                                                   |\n",
      "|       throughout       |  61  |   1    |                                                  [(13, 1)]                                                   |\n",
      "|         threat         |  68  |   2    |                                              [(8, 1), (11, 1)]                                               |\n",
      "|          ups           |  5   |   1    |                                                   [(0, 1)]                                                   |\n",
      "|       paperwork        |  4   |   1    |                                                   [(4, 1)]                                                   |\n",
      "|          won           | 356  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|         worry          |  33  |   1    |                                                   [(8, 1)]                                                   |\n",
      "|       reputation       |  32  |   1    |                                                   [(9, 1)]                                                   |\n",
      "|      successfully      |  20  |   1    |                                                  [(12, 1)]                                                   |\n",
      "|        assault         |  17  |   1    |                                                   [(3, 1)]                                                   |\n",
      "|        process         | 110  |   1    |                                                   [(5, 1)]                                                   |\n",
      "|         appear         |  80  |   1    |                                                   [(6, 1)]                                                   |\n",
      "|         upside         |  3   |   1    |                                                  [(10, 1)]                                                   |\n",
      "|       regulatory       |  17  |   1    |                                                   [(3, 1)]                                                   |\n",
      "|        advisers        |  7   |   1    |                                                   [(2, 1)]                                                   |\n",
      "|        anymore         |  13  |   2    |                                              [(10, 1), (11, 1)]                                              |\n",
      "|        reality         |  39  |   1    |                                                  [(12, 1)]                                                   |\n",
      "| pricewaterhousecoopers |  3   |   2    |                                              [(2, 1), (13, 1)]                                               |\n",
      "|          pwc           |  2   |   3    |                                          [(2, 1), (9, 1), (10, 1)]                                           |\n",
      "|         string         |  18  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|        advisory        |  10  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|      transparent       |  12  |   1    |                                                   [(4, 1)]                                                   |\n",
      "|          buys          |  5   |   1    |                                                  [(12, 1)]                                                   |\n",
      "|      interviewed       |  19  |   1    |                                                  [(13, 1)]                                                   |\n",
      "|         hardly         |  26  |   1    |                                                   [(6, 1)]                                                   |\n",
      "|        threats         |  27  |   2    |                                               [(0, 1), (8, 1)]                                               |\n",
      "|         terror         |  29  |   1    |                                                   [(0, 1)]                                                   |\n",
      "|        avoided         |  19  |   1    |                                                   [(6, 1)]                                                   |\n",
      "|           54           |  18  |   1    |                                                   [(8, 1)]                                                   |\n",
      "|       interviews       |  14  |   1    |                                                  [(12, 1)]                                                   |\n",
      "|        possibly        |  26  |   1    |                                                   [(8, 1)]                                                   |\n",
      "|         gloomy         |  6   |   1    |                                                   [(2, 1)]                                                   |\n",
      "|       exception        |  7   |   1    |                                                   [(1, 1)]                                                   |\n",
      "|         unlike         |  25  |   1    |                                                  [(11, 1)]                                                   |\n",
      "|         samuel         |  8   |   1    |                                                   [(9, 1)]                                                   |\n",
      "|         frank          |  39  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|      surprisingly      |  9   |   1    |                                                  [(11, 1)]                                                   |\n",
      "|    over-regulation     |  1   |   1    |                                                   [(0, 1)]                                                   |\n",
      "|          wild          |  26  |   1    |                                                   [(0, 1)]                                                   |\n",
      "|         downs          |  4   |   1    |                                                   [(0, 1)]                                                   |\n",
      "|        lacking         |  10  |   1    |                                                   [(1, 1)]                                                   |\n",
      "|      two-pronged       |  1   |   1    |                                                   [(3, 1)]                                                   |\n",
      "|    exchange-listed     |  1   |   1    |                                                   [(5, 1)]                                                   |\n",
      "|          ifrs          |  1   |   1    |                                                   [(5, 1)]                                                   |\n",
      "|        hacking         |  5   |   1    |                                                   [(6, 1)]                                                   |\n",
      "|          tape          |  12  |   1    |                                                   [(6, 1)]                                                   |\n",
      "|        low-wage        |  1   |   1    |                                                   [(7, 1)]                                                   |\n",
      "|        dipiazza        |  1   |   2    |                                              [(9, 1), (12, 1)]                                               |\n",
      "|       outsource        |  1   |   1    |                                                   [(9, 1)]                                                   |\n",
      "|          kill          |  15  |   1    |                                                  [(10, 1)]                                                   |\n",
      "|         hedged         |  1   |   1    |                                                  [(12, 1)]                                                   |\n",
      "|          324           |  2   |   1    |                                                  [(13, 1)]                                                   |\n",
      "+------------------------+------+--------+--------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "document_path = 'BBC News Summary/BBC News Summary/News Articles\\\\business\\\\509.txt'\n",
    "print(I.doc_to_string(map_path_to_articleID(document_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization \n",
    "\n",
    "TF: \n",
    "* Document: Term frequencies are assessed on document level.\n",
    "* Sentence: Term frequencies are assessed on sentence level.\n",
    "\n",
    "IDF: Inverted document frequencies is assessed on collection level.\\\n",
    "\\\n",
    "Additional parameter \"N\" and \"article_id\". Is this allowed?\n",
    "\n",
    "TODO: \n",
    "* Evaluate choice and give reason: \n",
    "    * IDF on document level?\n",
    "    * TF on document level for sentences? \n",
    "* \"order\" parameter o\n",
    "* BM25\n",
    "* BERT embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_term(N, df_t, tf_t_d):\n",
    "    return (1 + math.log10(tf_t_d)) * math.log10(N/df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "summarization(d,p,l,o,I,args)\n",
    "    @input document d (the index in I/D), maximum number of sentences (p) and/or characters (l), order\n",
    "    of presentation o (appearance in text vs relevance), inverted index I or the\n",
    "    collection D, and optional arguments on IR models\n",
    "\n",
    "    @behavior preprocesses d, assesses the relevance of each sentence in d against I ac-\n",
    "    cording to args, and presents them in accordance with p, l and o\n",
    "    \n",
    "    @output summary s of document d, i.e. ordered pairs (sentence position in d, score)\n",
    "'''\n",
    "def summarization(d: int, p: int, l: int, o: int, I_or_D: Union[InvertedIndex, list], **args) -> list:\n",
    "\n",
    "    if args['model'] != 'BERT':\n",
    "\n",
    "        ## if we receive the collection instead of the inverted index we must compute it first\n",
    "        if type(I_or_D) == list:\n",
    "            I = indexing(I_or_D)         \n",
    "        else: \n",
    "            I = I_or_D\n",
    "        \n",
    "        doc_info = I.get_document_info(d)\n",
    "        sentence_lengths = I.get_sentence_lengths(d)\n",
    "        term_doc_info = zip(*doc_info.values())    \n",
    "\n",
    "    scores = defaultdict()\n",
    "\n",
    "    if args['model'] == 'TF-IDF':\n",
    "        for term, df_t, tf_t_d, tf_per_sentence in term_doc_info:\n",
    "            rel_t_d = tf_idf_term(I.N, tf_t_d, df_t)\n",
    "            for sent_number, tf_s_t in tf_per_sentence:\n",
    "                scores[sent_number] += rel_t_d * (1 + math.log10(tf_s_t))\n",
    "        # normalization\n",
    "        for sent_number, score in scores.items():\n",
    "            scores[sent_number] = score / sentence_lengths[sent_number] \n",
    "    \n",
    "    elif args['model'] == 'BM25':\n",
    "        pass\n",
    "    \n",
    "    elif args['model'] == 'BERT':\n",
    "        document = I_or_D[d]\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Currently we only support the following models:\\n→ TF-IDF\\n→ BM-25\\n→ BERT\")\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Extraction\n",
    "\n",
    "Calculates the keywords based on the tf-idf of the document.\\\n",
    "\\\n",
    "Additional parameter \"N\" and \"article_id\". Is this allowed?\n",
    "\n",
    "Parameter for including only noun phrases. \n",
    "\n",
    "TODO:\n",
    "* Nouns: just unigrams or also bigrams?\n",
    "* BM25\n",
    "* BERT embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import Senna\n",
    "from nltk.tag import SennaChunkTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkeyword extraction(d,p,I,args)\\n    @input document d, maximum number of keywords p, inverted index I, and op-\\n    tional arguments on IR model choices\\n\\n    @behavior extracts the top informative p keywords in d against I according to args\\n    \\n    @output ordered set of p keywords\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "keyword extraction(d,p,I,args)\n",
    "    @input document d, maximum number of keywords p, inverted index I, and op-\n",
    "    tional arguments on IR model choices\n",
    "\n",
    "    @behavior extracts the top informative p keywords in d against I according to args\n",
    "    \n",
    "    @output ordered set of p keywords\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goldfinger: 4.354976755313726\n",
      "goldeneye: 3.7342276913546106\n",
      "bond: 3.6992505932864606\n",
      "masterminds: 3.3473300153169503\n",
      "commander-in-chief: 3.3473300153169503\n",
      "juices: 3.3473300153169503\n",
      "nightfire: 3.3473300153169503\n",
      "aura: 3.3473300153169503\n",
      "crosshair: 3.3473300153169503\n",
      "firefights: 3.3473300153169503\n",
      "{'goldfinger': 4.354976755313726, 'goldeneye': 3.7342276913546106, 'bond': 3.6992505932864606, 'masterminds': 3.3473300153169503, 'commander-in-chief': 3.3473300153169503, 'juices': 3.3473300153169503, 'nightfire': 3.3473300153169503, 'aura': 3.3473300153169503, 'crosshair': 3.3473300153169503, 'firefights': 3.3473300153169503}\n"
     ]
    }
   ],
   "source": [
    "def keyword_extraction(article: str, max_num: int, inverted_index: dict, N: int, article_id: int, use_only_nouns=False, args=None) -> dict: \n",
    "    # tokenizer split words and keep hyphons e.g. state-of-the-art\n",
    "    tokenizer = RegexpTokenizer(r'[\\w|-]+')\n",
    "    # tokenize sentences\n",
    "    sents = nltk.sent_tokenize(article)\n",
    "    # remove title (not needed for summarization task)\n",
    "    sents = sents[1:]\n",
    "    \n",
    "    # get words per document\n",
    "    # either use all words or only nouns\n",
    "    if use_only_nouns: \n",
    "        #tagger = SennaChunkTagger('/usr/share/senna-v3.0/senna')\n",
    "        words_per_doc = list()\n",
    "        for sent in sents: \n",
    "            words = tokenizer.tokenize(sent.lower())\n",
    "            \n",
    "            # senna chunk tagging of nouns \n",
    "            # not sure if needed, just a test\n",
    "            #tags = tagger.tag(words)\n",
    "            #chunks = list(tagger.bio_to_chunks(tags, chunk_type='N'))\n",
    "\n",
    "            # nltk pos tag \n",
    "            tagged_words = nltk.pos_tag(words)\n",
    "            named_entities = nltk.ne_chunk(tagged_words)\n",
    "            for word, tag in named_entities:\n",
    "                if 'NN' in tag: \n",
    "                    words_per_doc.append(word)\n",
    "    else: \n",
    "        words_per_sent = [set(tokenizer.tokenize(sent.lower())) for sent in sents]\n",
    "        words_per_doc = flatten(words_per_sent)\n",
    "\n",
    "    doc_tf_idf = defaultdict(str)\n",
    "    for word in words_per_doc: \n",
    "        # inverse document frequency (idf)\n",
    "        idf = math.log10(N/len(inverted_index[word]))\n",
    "        # term frequency (tf) by document\n",
    "        # get it from inverted index \n",
    "        doc_tf = inverted_index[word][article_id]\n",
    "        doc_tf = 1 + math.log10(doc_tf)\n",
    "\n",
    "        # tf-idf for the document \n",
    "        doc_tf_idf[word] = doc_tf * idf\n",
    "    \n",
    "    doc_tf_idf = dict(sorted(doc_tf_idf.items(), key=lambda item: item[1], reverse=True)[:max_num])\n",
    "    for word in doc_tf_idf: \n",
    "        print(f\"{word}: {doc_tf_idf[word]}\")\n",
    "    print(doc_tf_idf)\n",
    "\n",
    "keyword_extraction(articles[0], 10, inverted_index, len(articles), 0, use_only_nouns=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "TODO:\n",
    "* Implement evaluation\n",
    "* Evaluation:\n",
    "    * Statistics \n",
    "    * F-meassure\n",
    "    * Recall-precision-curve\n",
    "    * MAP\n",
    "    * Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nevaluation(Sset,Rset,args)\\n    @input the set of summaries Sset produced from selected documents Dset ⊆ D\\n    (e.g. a single document, a category of documents, the whole collection),\\n    the corresponding reference extracts Rset, and optional arguments (evalu-\\n    ation, preprocessing, model options)\\n\\n    @behavior assesses the produced summaries against the reference ones using the tar-\\n    get evaluation criteria\\n\\n    @output evaluation statistics, including F-measuring at predefined p-or-l summary\\n    limits, recall-and-precision curves, MAP, and efficiency\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "evaluation(Sset,Rset,args)\n",
    "    @input the set of summaries Sset produced from selected documents Dset ⊆ D\n",
    "    (e.g. a single document, a category of documents, the whole collection),\n",
    "    the corresponding reference extracts Rset, and optional arguments (evalu-\n",
    "    ation, preprocessing, model options)\n",
    "\n",
    "    @behavior assesses the produced summaries against the reference ones using the tar-\n",
    "    get evaluation criteria\n",
    "\n",
    "    @output evaluation statistics, including F-measuring at predefined p-or-l summary\n",
    "    limits, recall-and-precision curves, MAP, and efficiency\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(S: list, R: list, args=None) -> list:\n",
    "    # do evaluation... \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) **Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.1 Summarization solution: results for a given document*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bond game fails to shake or stir\n",
      "\n",
      "For gaming fans, the word GoldenEye evokes excited memories not only of the James Bond revival flick of 1995, but also the classic shoot-em-up that accompanied it and left N64 owners glued to their consoles for many an hour.\n",
      "\n",
      "Adopting that hallowed title somewhat backfires on this new game, for it fails to deliver on the promise of its name and struggles to generate the original's massive sense of fun. This however is not a sequel, nor does it relate to the GoldenEye film. You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6. Your new commander-in-chief is the portly Auric Goldfinger, last seen in 1964, but happily running around bent on world domination. With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "\n",
      "Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter. The notion is of course to add a novel dark edge to a 007 game, but the premise simply does not get the juices flowing like it needs to.\n",
      "\n",
      "Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise. This title lacks that aura, and when the Bond magic shines through, it feels like a lucky accident. The central problem is that the gameplay just is not good enough. Quite aside from the bizarre inability to jump, the even more bizarre glaring graphical bugs and dubious enemy AI, the levels simply are not put together with much style or imagination. Admittedly the competition has been tough, even in recent weeks, with the likes of Halo 2 and Half Life 2 triumphing in virtually every department. What the game is good at is enveloping you in noisy, dynamic scenes of violent chaos. As is the trend of late, you are made to feel like you are in the midst of a really messy and fraught encounter. Sadly that sense of action is outweighed by the difficulty of navigating and battling within the chaos, meaning that frustration is often the outcome. And irregular save points mean you have to backtrack each time you are killed. A minute red dot passes for a crosshair, although the collision-detection is so suspect that the difficulties of aiming weapons are compensated for. Shooting enemies from a distance can be tricky, and you will not always know you have picked them off, since dead enemies vanish literally before they have fully hit the floor, and they do so in some woefully uninspiring death animations. It is perhaps indicative of a lack of confidence that the game maker's allow you several different weapons almost immediately and throw you quickly into raging firefights - no time is risked with a measured build-up.\n",
      "\n",
      "By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "\n",
      "There is a real thrill from doing battle with these legendary villains, and it is a testament to the power of the Bond universe that they can cut such a dash. But the in-game niggles, combined with a story and presentation that just do not feel sufficiently well thought-through, will make this a disappointment for most. Diehard fans of Bond will probably find enough here to make it a worthwhile purchase and try to ignore the failings. The game is weak, not completely unplayable. Then again, 007 fanatics may also take umbrage at the cavalier blending of characters from different eras. Given James Bond's healthy pedigree in past games, there is every reason to hope that this is just a blip, a commendable idea that just has not worked, that will be rectified when the character inevitably makes his return.\n",
      "\n",
      "GoldenEye: Rogue Agent is out now\n",
      "\n",
      "0.2495193303958334: By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "0.21019493577531412: Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter.\n",
      "0.20079836196045564: You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6.\n",
      "0.1995382299926325: With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "0.19033491063190966: Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{19: 0.2495193303958334,\n",
       " 5: 0.21019493577531412,\n",
       " 2: 0.20079836196045564,\n",
       " 4: 0.1995382299926325,\n",
       " 7: 0.19033491063190966}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code, statistics and/or charts here\n",
    "article_id = 0\n",
    "print(articles[article_id])\n",
    "summarization(articles[article_id], num_sent=5, order=\"rel\", inverted_index=inverted_index, N=len(articles), article_id=article_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.2 IR models (TF-IDF, BM25 and EBRT)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.3 Reciprocal rank funsion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.4 Maximal Marginal Relevance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) **Keyword extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bond game fails to shake or stir\n",
      "\n",
      "For gaming fans, the word GoldenEye evokes excited memories not only of the James Bond revival flick of 1995, but also the classic shoot-em-up that accompanied it and left N64 owners glued to their consoles for many an hour.\n",
      "\n",
      "Adopting that hallowed title somewhat backfires on this new game, for it fails to deliver on the promise of its name and struggles to generate the original's massive sense of fun. This however is not a sequel, nor does it relate to the GoldenEye film. You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6. Your new commander-in-chief is the portly Auric Goldfinger, last seen in 1964, but happily running around bent on world domination. With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "\n",
      "Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter. The notion is of course to add a novel dark edge to a 007 game, but the premise simply does not get the juices flowing like it needs to.\n",
      "\n",
      "Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise. This title lacks that aura, and when the Bond magic shines through, it feels like a lucky accident. The central problem is that the gameplay just is not good enough. Quite aside from the bizarre inability to jump, the even more bizarre glaring graphical bugs and dubious enemy AI, the levels simply are not put together with much style or imagination. Admittedly the competition has been tough, even in recent weeks, with the likes of Halo 2 and Half Life 2 triumphing in virtually every department. What the game is good at is enveloping you in noisy, dynamic scenes of violent chaos. As is the trend of late, you are made to feel like you are in the midst of a really messy and fraught encounter. Sadly that sense of action is outweighed by the difficulty of navigating and battling within the chaos, meaning that frustration is often the outcome. And irregular save points mean you have to backtrack each time you are killed. A minute red dot passes for a crosshair, although the collision-detection is so suspect that the difficulties of aiming weapons are compensated for. Shooting enemies from a distance can be tricky, and you will not always know you have picked them off, since dead enemies vanish literally before they have fully hit the floor, and they do so in some woefully uninspiring death animations. It is perhaps indicative of a lack of confidence that the game maker's allow you several different weapons almost immediately and throw you quickly into raging firefights - no time is risked with a measured build-up.\n",
      "\n",
      "By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "\n",
      "There is a real thrill from doing battle with these legendary villains, and it is a testament to the power of the Bond universe that they can cut such a dash. But the in-game niggles, combined with a story and presentation that just do not feel sufficiently well thought-through, will make this a disappointment for most. Diehard fans of Bond will probably find enough here to make it a worthwhile purchase and try to ignore the failings. The game is weak, not completely unplayable. Then again, 007 fanatics may also take umbrage at the cavalier blending of characters from different eras. Given James Bond's healthy pedigree in past games, there is every reason to hope that this is just a blip, a commendable idea that just has not worked, that will be rectified when the character inevitably makes his return.\n",
      "\n",
      "GoldenEye: Rogue Agent is out now\n",
      "\n",
      "goldfinger: 4.354976755313726\n",
      "goldeneye: 3.7342276913546106\n",
      "bond: 3.6992505932864606\n",
      "masterminds: 3.3473300153169503\n",
      "commander-in-chief: 3.3473300153169503\n",
      "juices: 3.3473300153169503\n",
      "nightfire: 3.3473300153169503\n",
      "aura: 3.3473300153169503\n",
      "crosshair: 3.3473300153169503\n",
      "firefights: 3.3473300153169503\n",
      "{'goldfinger': 4.354976755313726, 'goldeneye': 3.7342276913546106, 'bond': 3.6992505932864606, 'masterminds': 3.3473300153169503, 'commander-in-chief': 3.3473300153169503, 'juices': 3.3473300153169503, 'nightfire': 3.3473300153169503, 'aura': 3.3473300153169503, 'crosshair': 3.3473300153169503, 'firefights': 3.3473300153169503}\n"
     ]
    }
   ],
   "source": [
    "#code, statistics and/or charts here\n",
    "article_id = 0\n",
    "print(articles[article_id])\n",
    "keyword_extraction(articles[0], 10, inverted_index, len(articles), 0, use_only_nouns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D) **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Part II: questions materials (optional)</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** Corpus *D* and summaries *S* description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** Summarization performance for the overall and category-conditional corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**...** (additional questions with empirical results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>END</H3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
