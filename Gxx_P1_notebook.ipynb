{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>PRI 2023/24: first project delivery</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GROUP 11**\n",
    "- Francisco Martins, 99068\n",
    "- Tunahan Güneş, 108108\n",
    "- Sebastian Weidinger, 111612"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Part I: demo of facilities</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_article(text: str) -> str: \n",
    "    text = text.split(\"\\n\\n\")\n",
    "    # remove title\n",
    "    text = text[1:]\n",
    "    text = \" \".join(text)\n",
    "    text = text.strip()\n",
    "    text = text.replace(\" ?\", \"?\")\n",
    "    text = text.replace(\" !\", \"!\")\n",
    "    text = re.sub(r'\\s+', r' ', text)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_summary(text: str) -> str: \n",
    "    text = text.replace(\" ?\", \"?\")\n",
    "    text = text.replace(\" !\", \"!\")\n",
    "    text = re.sub(r'\\s+', r' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(article_path, summary_path):\n",
    "    articles = []\n",
    "    summaries = []\n",
    "    article_file_paths = []\n",
    "    summary_file_paths = []\n",
    "    category_names = list()\n",
    "    for folder in os.listdir(article_path):\n",
    "        category_names.append(folder)\n",
    "        article_category_path = os.path.join(article_path, folder)\n",
    "        summary_category_path = os.path.join(summary_path, folder)\n",
    "        articles.append([])\n",
    "        summaries.append([])\n",
    "        article_file_paths.append([])\n",
    "        summary_file_paths.append([])\n",
    "        for file in os.listdir(article_category_path):\n",
    "            article_file_path = os.path.join(article_category_path, file)\n",
    "            summary_file_path = os.path.join(summary_category_path, file)\n",
    "            article_file_paths[-1].append(article_file_path)\n",
    "            summary_file_paths[-1].append(summary_file_path)\n",
    "            # articles\n",
    "            with open(article_file_path, \"r\", errors=\"ignore\") as f:\n",
    "                text = f.read()\n",
    "                text = preprocess_article(text)\n",
    "                articles[-1].append(text)\n",
    "            #summaries \n",
    "            with open(summary_file_path, \"r\", errors=\"ignore\") as f: \n",
    "                text = f.read()\n",
    "                text = preprocess_summary(text)\n",
    "                summaries[-1].append(text)\n",
    "                \n",
    "    print(\"Number of Categories:\",len(os.listdir(article_path)))\n",
    "    for i in range(len(os.listdir(article_path))):\n",
    "        print(\"Number of Articles in\", \"'\"+os.listdir(article_path)[i]+\"'\", \"Category:\",len(articles[i]))\n",
    "    \n",
    "    return article_file_paths, articles, summary_file_paths, summaries, category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article path: BBC News Summary\\BBC News Summary\\News Articles\n",
      "Summary path: BBC News Summary\\BBC News Summary\\Summaries\n",
      "Number of Categories: 5\n",
      "Number of Articles in 'business' Category: 510\n",
      "Number of Articles in 'entertainment' Category: 386\n",
      "Number of Articles in 'politics' Category: 417\n",
      "Number of Articles in 'sport' Category: 511\n",
      "Number of Articles in 'tech' Category: 401\n"
     ]
    }
   ],
   "source": [
    "article_path = os.path.join(\"BBC News Summary\", \"BBC News Summary\", \"News Articles\")\n",
    "summary_path = os.path.join(\"BBC News Summary\", \"BBC News Summary\", \"Summaries\")\n",
    "print(\"Article path:\", article_path)\n",
    "print(\"Summary path:\", summary_path)\n",
    "article_file_paths, categorized_articles, summary_file_paths, categorized_summaries, category_names= read_files(article_path, summary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier. The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL. Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding. Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins. TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n",
      "[]\n",
      "TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn.Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues.Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters.Time Warner's fourth quarter profits were slightly better than analysts' expectations.\n"
     ]
    }
   ],
   "source": [
    "#Examplary text. The structure of the read file is: articles[category_no][document_no]. \n",
    "print(categorized_articles[0][0])\n",
    "print(article_file_paths[508:512])\n",
    "print(categorized_summaries[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lists) -> list: \n",
    "    return [element for sublist in lists for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_sentence_indices(articles: list, summaries: list) -> list: \n",
    "    categorized_summary_indices = list()\n",
    "    categorized_article_summary = list(zip(articles, summaries))\n",
    "    found_summary = 0\n",
    "    faulty_summaries = list()\n",
    "    for category_id, category in enumerate(categorized_article_summary): \n",
    "        article_summary_tuples = list(zip(category[0], category[1]))\n",
    "        categorized_summary_indices.append([])\n",
    "        for article_id, (article, summary) in enumerate(article_summary_tuples):\n",
    "            sentence_indices = list()\n",
    "            recreated_summary = \"\"\n",
    "            article_sents = sent_tokenize(article)\n",
    "            article_sents = set(article_sents)\n",
    "            for sent_id, sent in enumerate(article_sents): \n",
    "                if summary.find(sent) != -1: \n",
    "                    sentence_indices.append(sent_id)\n",
    "                    recreated_summary += sent\n",
    "            categorized_summary_indices[-1].append(sentence_indices)\n",
    "            summary_length = len(summary)\n",
    "            recreated_summary_length = len(recreated_summary)\n",
    "            if abs(summary_length - recreated_summary_length) < 3: \n",
    "                found_summary += 1\n",
    "            else: \n",
    "                faulty_summaries.append((category_id, article_id))\n",
    "    print(f\"number of found summaries: {found_summary}\")\n",
    "    print(f\"number of summaries: {len(flatten(summaries))}\")\n",
    "    print(f\"{float(found_summary)/float(len(flatten(summaries))) * 100 :.2f}%\")\n",
    "    return categorized_summary_indices, faulty_summaries\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of found summaries: 2220\n",
      "number of summaries: 2225\n",
      "99.78%\n",
      "[[[3, 6, 8, 10, 11, 12, 15, 16], [0, 4, 6, 8, 13, 14], [0, 3, 4, 7, 8], [0, 4, 6, 9, 12, 14, 16, 17], [0, 1, 2, 6, 8], [2, 3, 6, 8], [0, 1, 5, 6, 10, 13], [0, 2, 5, 8, 12, 13], [2, 4, 6, 10, 11], [2, 4, 8, 9], [1, 2, 6, 8, 9], [0, 4, 5, 8, 10, 11], [0, 3, 4, 5, 7, 13], [2, 6, 7, 10, 14, 16, 17, 19, 21], [0, 4, 6, 7, 9, 10, 13, 15, 16, 17, 18, 19], [0, 1, 2, 7, 9], [1, 4, 5, 7, 8], [0, 2, 3, 4], [0, 1, 2, 6, 10], [2, 4, 7, 8, 13, 14, 16, 18, 19, 21, 22, 23], [0, 1, 2, 5, 9, 11], [0, 1, 2, 3, 10, 13], [0, 3, 5, 7, 8], [3, 4, 6, 7, 10, 12], [2, 5, 7, 8, 9, 12, 13, 14, 19, 22], [0, 4, 7, 8, 12, 13], [4, 5, 6, 8, 10, 12], [3, 5, 6, 8], [0, 8, 9, 11, 14, 16, 18, 19], [1, 2, 4, 8, 10, 12, 16], [3, 4, 8, 10, 12, 13, 14], [1, 2, 6, 7, 9, 13], [3, 5, 8, 9], [0, 6, 7, 11, 12, 13], [1, 3, 4, 6, 7], [0, 2, 4, 7, 8, 13], [2, 4, 7, 8, 9, 10, 11, 13], [0, 1, 5, 7], [0, 1, 2, 6, 10], [0, 1, 4, 6, 9], [0, 1, 5, 9, 10, 13], [0, 1, 2, 6, 10, 11], [0, 1, 3, 6], [0, 1, 2, 3, 7, 8, 14, 16], [2, 3, 4, 5, 6, 12], [3, 4, 7, 11, 13, 14], [1, 4, 5, 7, 10], [0, 1, 5, 10, 11], [2, 4, 8, 10, 11, 14, 15, 18, 19, 21, 25, 27], [3, 4, 6, 7, 13, 14], [3, 6, 7, 9, 11, 12, 14], [0, 3, 4, 8, 9, 10, 11, 15, 20], [3, 4, 5, 7], [0, 2, 4, 6, 8], [0, 1, 4, 7, 12, 14], [0, 1, 6, 8, 9, 11], [1, 2, 4, 6, 8, 16, 18, 19, 20], [0, 1, 3, 4, 6], [0, 3, 6, 7, 8, 9], [0, 2, 4, 6], [1, 2, 6, 9], [0, 2, 4, 5, 10, 11], [3, 4, 9, 11, 13, 14], [2, 4, 5, 9, 11, 12], [5, 7, 8, 9, 10, 11, 14], [0, 1, 2, 9, 10, 13], [0, 1, 8, 9, 11, 13], [2, 7, 8, 9, 11, 14, 15], [0, 3, 5, 7, 9, 10, 18, 20, 21, 23], [3, 5, 6, 7], [2, 4, 6, 9], [0, 1, 5, 7, 10, 12], [1, 3, 4, 5, 8], [1, 3, 4, 6, 7], [2, 4, 6, 7], [1, 2, 3, 5, 9, 11], [3, 4, 5, 7, 8, 12, 13, 17, 19], [2, 3, 4, 8, 11], [2, 3, 4, 9, 10], [4, 5, 7, 9, 10], [1, 2, 4, 5, 8, 11], [0, 1, 2, 4], [1, 4, 6, 8, 9, 13, 17, 18, 19, 21], [1, 2, 6, 7, 8], [2, 5, 7, 9], [2, 3, 6, 8], [0, 1, 3, 4, 9, 10, 11, 17], [1, 2, 3, 5, 8], [0, 3, 6, 7, 9, 15, 16, 17], [0, 4, 10, 11, 13, 14, 15, 16], [1, 2, 3, 11, 13, 14, 15], [0, 1, 3, 8, 11, 15, 16, 17], [1, 3, 5, 7, 8, 13], [0, 2, 5, 6], [1, 2, 4, 8, 11], [2, 4, 6], [1, 2, 4, 9, 11, 13, 17, 19, 20, 22], [1, 4, 6, 8], [3, 7, 8, 9, 11, 13, 14], [0, 1, 2, 6, 11, 14, 15], [0, 2, 5, 8, 10, 11, 15], [1, 2, 4, 5, 8], [0, 4, 5, 7, 8, 9, 11, 16], [1, 4, 5, 7, 11, 13, 14], [0, 3, 4, 6], [0, 2, 3, 4, 5, 9], [1, 2, 3, 10, 11], [0, 1, 2, 5], [0, 2, 4, 7], [1, 4, 6, 8, 9, 12], [2, 3, 8, 14, 15, 16, 17, 18, 20, 22], [1, 6, 7, 8, 11, 14], [0, 1, 11, 13, 14, 15, 16], [2, 4, 5, 8, 11, 13, 15, 17], [3, 5, 6, 7], [0, 2, 5, 9, 10], [3, 4, 5, 7, 9, 14, 16, 17, 20], [0, 1, 6, 8, 11], [0, 1, 3, 4, 10, 14, 17, 18, 20], [2, 4, 5, 10, 12, 14], [0, 1, 2, 8, 10, 12, 14, 17, 18, 21], [1, 4, 6, 7, 12, 14, 15, 17], [0, 3, 5, 9], [0, 3, 4, 5], [0, 2, 8, 9, 10], [0, 3, 7, 12, 14, 15, 16, 18], [0, 2, 3, 4, 5, 8, 9, 10, 13], [0, 2, 5, 6, 7, 8, 13], [2, 5, 6, 7], [5, 8, 10, 11, 12, 16, 17, 19], [0, 4, 6, 8, 11, 13, 14, 15, 20, 21], [4, 6, 7, 8, 10], [1, 4, 6, 7, 8, 12], [0, 1, 3, 6, 10, 11], [1, 4, 6, 9, 10, 12, 13, 19], [3, 6, 8, 9, 10, 13, 14, 17, 18, 19, 21], [0, 1, 4, 5, 10], [3, 6, 8, 10, 12, 13], [1, 5, 8, 9, 10, 14], [1, 2, 7, 8, 10, 13, 14, 19, 20], [0, 1, 5, 7, 10, 11], [3, 4, 7, 9, 12, 14], [3, 5, 8, 10, 11], [0, 2, 5, 7], [1, 2, 4, 7, 10], [1, 2, 4, 5, 7, 15, 16, 18, 20, 26, 30, 31, 33, 35, 37, 38, 39, 40, 42], [1, 2, 4, 5, 8], [0, 1, 2, 4, 8], [1, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 27], [2, 7, 10, 11, 12, 14, 15], [0, 2, 5, 7, 9, 10], [1, 3, 4, 8, 12, 14, 16], [0, 2, 4, 5, 7, 9, 11, 15, 18], [0, 4, 5, 7, 9, 10, 11], [2, 5, 6, 7, 8, 10], [0, 6, 7, 8, 10, 11], [0, 5, 7, 9, 11], [2, 4, 6], [0, 3, 4, 5, 6, 10, 11, 14, 18, 22], [1, 3, 9, 10, 11, 12, 14], [1, 4, 5, 7, 10, 15, 16, 17], [2, 3, 6, 8, 10, 13], [0, 1, 4, 5, 8, 9, 11], [0, 3, 4, 8, 10, 11, 14, 15], [1, 5, 7, 10, 11, 13, 16], [2, 3, 6, 7, 10], [1, 2, 3, 6, 8], [0, 4, 6, 8, 9], [0, 1, 6, 7], [0, 1, 5, 8], [3, 4, 5, 7, 9], [0, 2, 3, 4, 13, 14, 15, 16], [0, 1, 4, 6, 8, 9, 12, 15], [4, 7, 10, 11, 12, 13], [0, 4, 7, 9, 10], [0, 2, 4, 5], [1, 2, 8, 10, 12, 14, 15], [1, 3, 4, 8, 10, 11], [2, 4, 6, 7], [1, 7, 8, 9, 10, 12], [7, 8, 10, 12, 13, 17, 18, 19, 21], [1, 2, 3, 7, 10], [2, 4, 6, 10, 12, 13, 14, 16, 18, 19, 20, 27, 30, 35, 36, 38], [2, 3, 4, 6, 7, 8], [0, 1, 5, 6, 11], [1, 3, 8, 10, 11], [1, 4, 5, 6, 12, 14], [2, 3, 6, 7, 9, 14, 15, 17], [0, 3, 12, 13, 14, 15, 16, 18], [0, 2, 6, 7, 9, 13, 15, 16], [0, 2, 5, 7, 8, 9, 11, 13], [0, 2, 7, 9, 11, 14, 15], [4, 5, 7, 8, 9, 12], [2, 5, 7, 9], [0, 1, 7, 8, 12, 14, 16, 17, 18], [0, 8, 9, 10, 11, 14], [0, 7, 9, 10, 11, 12], [2, 3, 5, 7, 11, 12], [3, 6, 7, 8, 12, 13, 14, 16], [0, 4, 6, 9, 10, 15, 16, 17, 24, 25, 27, 29], [0, 1, 4, 6, 9, 10], [0, 1, 2, 4, 6, 8, 10], [2, 7, 8, 10, 11, 13], [1, 2, 3, 4, 5, 7, 8, 11, 16, 18], [1, 3, 4, 10, 11, 12], [0, 2, 3, 5, 6, 8, 11], [1, 2, 4, 6, 8, 13], [0, 1, 3, 9, 10, 13], [0, 4, 6, 8, 10, 11, 17, 20, 21, 22, 24], [0, 9, 10, 12, 13, 15, 17], [2, 6, 7, 8, 11], [3, 5, 8, 9, 10, 11], [0, 1, 2, 3, 5, 6, 8, 13], [1, 4, 7, 8, 9], [1, 4, 6, 10, 11, 12, 15, 16, 20, 22], [3, 5, 6, 7, 8, 10, 16], [3, 4, 9, 14, 15, 16, 17, 18, 19, 20], [1, 3, 7, 9], [4, 6, 8, 9, 10, 12], [4, 6, 7, 8, 10, 12], [0, 3, 4, 8, 9, 10, 13], [2, 6, 7, 8, 9, 15, 16, 18, 19, 22], [0, 3, 7, 8, 9, 11], [8, 9, 13, 14, 15, 18, 20, 21, 22, 23], [2, 3, 4, 6, 9], [0, 2, 5, 9, 11, 12], [0, 1, 3, 8], [1, 2, 4, 5, 6], [0, 5, 6, 9, 12, 16, 18, 19, 20, 22], [0, 1, 2, 5, 11], [1, 2, 5, 7, 12, 13], [0, 1, 6, 8, 9, 11], [0, 1, 4], [1, 5, 6, 7], [1, 3, 4, 6], [3, 4, 7, 8, 11, 14, 15, 16], [2, 3, 7, 9, 10], [1, 5, 8, 10, 12, 14, 15], [0, 1, 4, 6], [1, 4, 7, 8, 9], [5, 7, 9, 11, 12, 13, 14, 16, 18, 19, 24, 25, 26, 34], [0, 1, 2, 5, 6, 7, 8, 13, 14, 21, 22, 23, 25], [0, 2, 4, 8, 9, 12, 17, 23, 24, 27, 29, 30, 32, 33, 34, 37, 40], [0, 1, 3, 6, 8, 12, 14, 16, 19, 21], [0, 2, 3, 6, 8, 9, 13, 17, 18, 20, 21, 23, 27, 30, 33, 35, 36, 39, 40, 43], [0, 1, 5, 8, 14, 15, 17, 19, 20], [0, 1, 5, 6, 8, 10], [2, 3, 8, 9, 11, 14], [1, 2, 4, 7, 9, 10, 11, 12, 16, 20, 22], [0, 1, 3, 6, 7, 10], [1, 3, 4, 8, 13, 15, 16], [2, 3, 4, 7, 14, 15, 16, 18, 21, 23, 24], [0, 1, 5, 6, 10, 13], [1, 5, 10, 11, 13, 14, 15], [1, 3, 6, 7], [3, 4, 5, 7, 10], [1, 3, 5, 6, 10, 15, 16, 17, 21], [2, 4, 6, 8, 10, 15, 17, 18], [0, 2, 5, 6, 8], [0, 3, 5, 6, 7, 8, 9, 11, 20, 23, 25], [1, 2, 6, 8, 12, 17, 19, 20, 23, 28, 29, 30, 31, 32], [2, 7, 8, 9, 10, 13, 16, 18, 19, 20, 26, 29, 30, 31], [1, 6, 9, 12, 13, 14, 15], [0, 3, 4, 7, 10, 12, 15, 16], [0, 2, 4, 7, 8, 12], [0, 1, 3, 9, 10, 12, 15, 16, 18, 19, 24, 29], [4, 5, 7, 9], [0, 1, 6, 7, 8, 9, 10, 18, 19, 21, 23, 25, 27, 35, 36, 37], [0, 1, 3, 4, 8, 10, 12, 14], [0, 3, 5, 6, 7, 9, 10, 15, 18, 20, 24, 25], [2, 4, 6, 7, 9, 12, 15, 17], [2, 6, 7, 9, 10, 11, 15], [0, 3, 10, 11, 12, 13, 18, 20, 21, 22], [0, 4, 5, 9, 11], [0, 2, 3, 4, 8, 10], [1, 4, 6, 7], [0, 5, 6, 9, 11, 14, 15, 16, 19, 22, 26, 35, 36, 37, 38, 39], [0, 6, 7, 9, 10], [1, 2, 3, 6, 8, 9, 12, 16], [1, 2, 3, 5], [0, 3, 4, 7, 9], [0, 1, 5, 8, 9, 11], [1, 3, 5, 6], [2, 3, 4, 5, 9, 12, 15, 17, 20, 22, 23, 26, 27, 31], [2, 5, 6, 10, 11], [4, 6, 10, 13, 14, 15, 16, 17], [1, 4, 5, 7, 8, 10, 11, 12, 15, 17, 18, 22, 24, 28, 31, 33, 35, 41, 44], [1, 5, 6, 7, 8, 12], [0, 1, 3, 5, 8, 11, 14], [0, 4, 10, 11, 17, 18, 19, 20, 21], [3, 5, 7, 8, 10, 11, 16, 18], [0, 2, 3, 4, 9, 13, 14], [1, 3, 4, 6, 9, 14, 15, 17], [2, 5, 7, 12, 14, 15, 16, 17, 18, 22], [0, 2, 4, 6, 9, 13, 14], [0, 2, 6, 7, 12, 14, 15, 19, 20], [0, 2, 3, 4, 9, 10], [0, 2, 3, 4], [0, 1, 3, 6, 9, 11, 14], [1, 5, 6, 7], [0, 1, 2, 6], [0, 2, 5, 8, 10], [0, 1, 2, 7, 11, 14, 15], [1, 2, 5, 8, 11], [4, 7, 9, 10, 11], [3, 4, 7, 8], [0, 2, 3, 4, 7, 8, 12, 17, 19, 23], [4, 7, 9, 11, 12, 13], [0, 2, 7, 9, 11], [1, 2, 4, 6], [1, 4, 7, 8], [0, 1, 3, 4, 5, 9], [2, 8, 9, 10, 12, 13], [0, 5, 6, 7, 8, 11, 12, 17, 18, 22, 25, 27, 30, 31], [1, 2, 3, 9, 10, 13], [3, 5, 7, 12, 14, 15, 16], [0, 1, 2, 3, 4, 10, 13, 18], [0, 1, 2, 6, 7, 9, 13, 15, 17], [1, 3, 7, 8, 10, 12], [1, 5, 6, 8, 11, 12], [1, 3, 6, 7], [0, 1, 3, 7], [0, 3, 4, 7, 8, 10, 11, 18], [0, 1, 3, 4, 5, 10, 15], [0, 2, 4, 8, 9, 12], [3, 7, 10, 11, 13, 14, 16, 17], [1, 2, 3, 4, 7, 11], [1, 2, 4, 6, 9], [0, 2, 3, 4, 5, 10], [1, 2, 5, 7, 8, 9, 10, 12, 14, 17, 18, 19, 22, 29, 31, 33, 34, 40], [1, 2, 3, 5, 10], [0, 4, 9, 11, 12, 13, 16, 19, 21, 23, 24, 25], [0, 2, 4, 7, 8, 12], [2, 6, 7, 8, 10], [2, 3, 4, 6, 7, 11], [0, 3, 4, 6, 9, 12, 16, 17], [1, 2, 4, 8, 10, 11, 15], [4, 6, 7, 9, 10], [0, 1, 2, 3, 6, 10], [0, 3, 6, 10, 12, 14], [0, 6, 7, 8, 10], [1, 3, 4, 7, 11, 13, 16], [0, 1, 5], [0, 1, 2, 8, 10, 13, 15], [0, 5, 6, 10, 11, 13, 14, 18, 20, 22], [0, 3, 5, 10, 11, 12, 15, 17, 21, 23, 26, 28, 29, 31], [0, 5, 6, 7, 8], [4, 7, 9, 10, 13, 14, 15, 18, 19], [0, 1, 3, 5, 6, 8, 16], [1, 2, 6, 8, 10], [0, 1, 2, 3, 8], [1, 4, 5], [0, 2, 3, 7, 8, 9, 14, 15, 16, 25, 28, 29, 33, 35, 37, 38, 39], [0, 5, 6, 7, 9, 11, 12, 13, 23, 25, 26, 27], [0, 3, 4, 9, 10], [2, 4, 6, 8, 10, 15, 17, 18], [2, 3, 4, 7, 9, 13], [5, 6, 10, 12, 15, 16, 17, 18], [1, 3, 6, 9, 10, 11], [0, 2, 3, 4, 10], [0, 3, 4, 5, 10], [3, 4, 8, 9], [0, 1, 2, 4, 9], [3, 5, 6, 8, 9], [4, 5, 7, 9], [2, 8, 10, 12, 13, 14, 15, 16], [0, 3, 5, 9, 11, 14, 15], [0, 2, 4, 9, 11], [1, 5, 6, 8, 9], [4, 7, 8, 9, 10], [3, 4, 5, 7, 10], [0, 1, 3, 6], [1, 2, 6, 7], [0, 4, 5, 8, 9, 11], [0, 2, 4, 6, 8, 11], [0, 2, 3, 4, 6, 13, 14], [2, 5, 6], [3, 4, 7, 9, 10], [5, 6, 7, 8, 9], [2, 3, 5, 8, 9], [0, 2, 3, 4, 7], [0, 2, 4, 6, 9, 10], [1, 2, 6, 8, 9, 13], [2, 5, 8, 9, 10, 12, 15], [0, 1, 2, 5], [5, 7, 8, 9, 12, 13], [1, 3, 5, 11, 13, 14, 16], [4, 5, 7, 8, 10], [1, 5, 6, 7, 8], [3, 5, 6, 7], [2, 4, 5, 6, 8, 10, 12, 14], [0, 6, 8, 11, 13, 14, 15], [0, 4, 6, 8, 11, 14, 16], [0, 4, 6, 7], [1, 2, 4, 5, 10], [0, 2, 4, 6], [5, 6, 7, 10, 12, 14, 15], [0, 1, 6, 9, 11, 12], [2, 7, 9, 10, 11, 13, 15, 16, 18, 24, 25, 27], [1, 2, 6, 8, 11, 12], [0, 1, 2, 4, 9, 10], [1, 4, 6, 7, 9, 10], [1, 2, 6, 8, 13, 14, 15], [2, 3, 5, 9, 10], [2, 3, 5, 8, 10, 11, 12, 20, 21], [1, 7, 8, 9, 13, 14, 15, 16, 18, 19], [2, 3, 4, 8, 9, 10], [0, 4, 5, 6], [0, 3, 5, 6, 8, 9, 13, 18, 20, 22, 23, 24, 29], [1, 2, 6, 8], [2, 5, 6, 9, 10], [0, 6, 8, 10, 11, 12, 14], [0, 6, 7, 8, 11, 14, 15, 16], [0, 1, 4, 5, 6, 7, 13], [0, 2, 4, 9, 13, 15, 16, 17], [0, 2, 3, 4, 9, 13, 14], [1, 3, 4, 7, 8], [0, 2, 3, 5], [1, 2, 6, 8, 9], [0, 4, 5, 6, 7], [5, 7, 8, 9, 12, 13], [1, 3, 4, 6], [2, 5, 7, 9, 10], [0, 1, 6, 8, 12, 13, 15], [0, 2, 3, 5, 9], [1, 2, 6, 7, 11, 12, 13, 18, 19], [1, 2, 4, 5, 7, 9], [1, 2, 4, 5, 8, 10, 12, 14, 18, 19, 22, 28], [2, 3, 5, 11, 12, 13], [2, 3, 4, 6, 7, 8, 9, 18], [1, 3, 4, 5], [1, 2, 3, 5], [2, 6, 7, 8], [0, 2, 3, 6, 14, 15, 16, 21, 22, 25, 26], [1, 3, 4, 9, 14, 15, 16, 18, 19, 21], [1, 3, 6, 7, 9, 12], [0, 1, 2, 5, 9, 14, 16, 19, 22, 24], [0, 4, 10, 11, 17, 18, 19, 20, 21], [1, 3, 5, 6, 7, 12], [0, 3, 4, 5, 6, 10, 16, 18], [0, 2, 4, 5, 6, 7, 13, 17], [0, 4, 7, 9, 10, 12], [1, 4, 5, 8], [0, 3, 6, 8, 10, 12], [2, 4, 6, 8, 11, 12, 14, 17], [0, 3, 4, 6, 9, 12], [1, 2, 4, 10, 11], [1, 4, 6, 8, 12, 13, 16, 17], [3, 6, 9, 10, 12, 14, 15, 18], [5, 6, 8, 9, 11, 14, 15, 17], [1, 2, 4, 7, 10, 11], [0, 2, 3, 6, 13, 14, 16], [0, 5, 6, 8, 10, 13], [0, 1, 2, 6, 11, 13, 15, 18, 21], [6, 7, 8, 9, 10, 13, 16], [1, 2, 3, 5], [2, 3, 4, 8, 11, 13, 15], [1, 6, 8, 12, 13, 14], [1, 2, 6, 8, 10, 12], [3, 4, 5, 6, 8, 14, 15, 16], [0, 5, 6, 11, 12, 13], [0, 3, 4, 6, 12, 13], [0, 1, 2, 3], [0, 3, 6, 7, 9], [4, 5, 6, 9, 10], [1, 4, 7, 8, 10, 12], [1, 3, 4, 8, 10], [1, 2, 3, 4, 5, 8, 10], [0, 4, 5, 6, 9, 13], [0, 5, 6], [3, 7, 8, 9, 11, 12, 14, 17, 20, 21], [0, 2, 3, 5, 8, 9, 12, 14, 20, 22], [1, 4, 5], [0, 1, 3, 4, 7], [2, 3, 7, 10, 11, 13], [1, 4, 5, 6, 7], [3, 5, 7, 8, 10], [0, 1, 2, 3, 5, 9], [1, 2, 3, 6, 7, 10, 14, 15], [0, 1, 2, 7, 9], [2, 8, 10, 11, 12, 13, 15], [0, 8, 11, 12, 13, 16, 17, 18, 19], [0, 2, 4, 5], [0, 3, 6, 7], [4, 5, 6, 7, 8, 12], [0, 4, 7, 10, 11, 12], [3, 8, 10, 12, 14, 16, 17, 20, 21, 22, 25, 26, 27], [3, 4, 6, 9, 12, 13], [0, 1, 4, 11, 12, 14], [0, 1, 2, 5, 7, 13], [1, 3, 4, 5, 6, 12], [3, 5, 6], [4, 6, 10, 13, 14, 15, 16, 17], [1, 4, 6, 10, 11, 12, 15, 16, 20, 22], [1, 2, 3, 4, 5, 10, 12, 17, 21, 22], [1, 4, 7, 8], [2, 3, 7, 8, 10, 11, 13], [0, 3, 4, 9, 11, 12, 13, 16, 17, 20], [0, 3, 4, 7, 11], [0, 2, 4, 9, 11], [0, 1, 5, 8, 10, 11, 12, 18, 19, 20, 22], [1, 6, 7, 9], [1, 3, 4, 5, 9], [1, 3, 4, 5, 6, 9, 10, 14], [4, 8, 9, 10, 11, 12], [0, 2, 3, 6, 7], [0, 4, 6, 10, 11, 13, 16, 19], [0, 1, 4, 6], [0, 1, 4, 6, 7, 10], [2, 3, 6]], [[2, 7, 8, 9, 10], [2, 8, 9, 10, 11, 12], [0, 2, 4, 5], [1, 4, 5, 7, 8], [1, 2, 5, 7], [1, 3, 5, 7], [2, 3, 7, 9, 11, 12, 13, 14], [1, 2, 7, 11, 12, 13], [1, 3, 7, 8, 9, 14], [0, 1, 2, 8, 9, 12], [4, 8, 9, 10, 11, 12], [8, 9, 12, 13, 14, 15, 16, 17, 20], [1, 2, 5, 7, 9, 14, 17, 18, 19, 24], [1, 2, 4, 6, 9], [0, 1, 3, 9, 10], [3, 4, 5, 6, 8, 10, 13, 14, 15, 22, 23, 25, 26, 27, 31], [0, 1, 4, 8, 11], [3, 6, 7, 9], [2, 3, 5, 8], [4, 8, 9, 10, 11], [1, 2, 8, 9, 11, 14, 17, 20, 22, 24, 26], [1, 4, 6, 7, 8, 15, 19, 20, 21, 22, 24, 27], [0, 1, 2, 4, 6, 10], [0, 4, 6, 8, 9, 10, 12, 13], [0, 3, 5, 6, 8, 9], [2, 4, 7, 9, 10, 11, 12], [0, 3, 5, 6, 10, 12, 15], [0, 3, 4, 7, 10], [2, 3, 4, 7, 11, 12], [2, 6, 7, 8, 10], [0, 1, 2, 3, 8, 13, 15], [3, 5, 10, 14, 15, 19, 20, 21, 22, 23, 24, 27], [0, 3, 4, 6, 8, 11], [1, 2, 4, 8, 9, 11], [0, 1, 5, 7, 8], [0, 5, 7, 9, 11], [1, 3, 4, 6, 10, 11], [1, 2, 3, 7, 9, 12], [1, 2, 5, 7, 10, 13], [0, 2, 3, 4, 8], [0, 1, 2, 3], [0, 2, 4, 7], [0, 3, 6, 9, 11, 13, 15, 17], [0, 1, 8, 10, 11, 13, 14], [1, 2, 4, 7, 9], [4, 5, 8, 9, 10], [3, 4, 5, 7, 9], [0, 2, 4, 6, 8, 10], [5, 6, 9, 10, 11, 12], [0, 1, 4, 6, 7, 10], [3, 4, 6, 7, 10, 13, 14, 15], [1, 3, 7, 9, 10], [0, 2, 3, 4, 10], [2, 5, 6, 8, 9, 12], [1, 2, 5, 6, 8, 10], [1, 3, 6, 8, 10, 12], [0, 2, 5, 6, 10, 11], [1, 2, 3, 4, 7, 12], [1, 4, 5, 6, 10], [2, 3, 4, 6], [1, 3, 6, 7, 10, 11, 12, 19, 21, 22, 25, 27, 29, 30], [0, 1, 2, 3, 5, 10], [0, 2, 7, 8, 12, 13], [0, 1, 3, 4, 6, 15, 17, 20, 21, 22, 25], [0, 1, 6, 7], [4, 5, 6, 10, 12, 13], [0, 4, 5, 9, 10], [1, 2, 3, 4, 8], [3, 4, 6, 7, 10, 13, 14, 15], [1, 5, 6, 10, 11], [0, 1, 4, 5, 6, 7], [1, 4, 5, 8, 10, 12], [1, 2, 3, 8], [1, 3, 5, 6, 10, 13], [3, 4, 8, 10, 11, 15, 16], [1, 5, 7, 8], [2, 3, 4, 5, 6, 7, 10, 12], [0, 4, 7, 10, 12, 14, 16, 17], [2, 7, 8, 9, 10], [1, 6, 7, 9, 10], [0, 2, 3, 5, 7, 10], [1, 2, 5, 7, 10, 13], [1, 2, 3, 7], [1, 3, 6, 9], [2, 3, 6, 9, 11, 12, 18, 19, 20], [2, 6, 7, 10, 12, 13], [3, 5, 7, 9], [1, 3, 5, 6, 10, 13], [2, 4, 6], [0, 2, 5, 8, 9, 10], [0, 1, 8, 9], [0, 3, 4, 6], [0, 2, 5, 8, 9, 12], [0, 2, 4, 5, 6, 9, 12, 18], [1, 2, 5, 9, 10, 13, 17, 19, 20, 23], [0, 4, 5, 6, 11, 12, 13], [1, 5, 6, 9, 10, 14], [3, 4, 5, 7, 8], [2, 4, 5, 7], [1, 2, 7, 8, 9, 10], [0, 1, 3, 5, 7, 10], [1, 5, 7, 8], [4, 5, 8, 10, 11, 13, 15], [2, 4, 8, 9], [3, 4, 7, 8, 10], [0, 1, 7, 10, 11], [2, 3, 7, 8], [1, 3, 4, 6, 7, 13, 14, 17], [0, 3, 7, 8], [2, 3, 4, 5, 8, 13], [1, 3, 6, 7, 9, 11], [1, 2, 6, 7], [0, 1, 7, 8, 9], [2, 3, 5, 6, 8, 11], [1, 2, 4, 5, 11, 13], [0, 1, 4, 8], [1, 5, 6, 7, 11, 12], [2, 4, 5, 6, 8, 13], [2, 4, 5, 8, 9], [3, 6, 7, 10, 13, 15, 17, 19, 22, 26, 27, 28, 31, 33, 34, 36, 37, 39], [1, 2, 3, 6, 8], [3, 4, 7, 9, 11, 14, 15, 16, 17, 20, 26, 28, 30], [0, 2, 3, 6, 10, 12], [1, 7, 8, 9], [2, 3, 7, 9, 10], [1, 2, 4, 5], [4, 5, 8, 10, 11, 13, 15], [3, 5, 6, 7], [0, 1, 2, 6, 8], [0, 3, 8, 9, 10, 13], [2, 3, 5, 8, 10, 11, 12, 14, 21, 23, 25, 26, 27, 28, 34, 36, 38, 43, 44, 47, 48, 54, 57, 60, 61, 63], [0, 1, 3, 4, 5, 6, 14, 18], [0, 6, 7, 9, 13, 15, 16], [2, 3, 7, 8], [1, 3, 6, 8], [3, 4, 6, 7], [1, 3, 8, 9, 10, 13], [2, 5, 7, 8, 9], [0, 2, 4, 7], [1, 7, 9, 10, 11], [0, 1, 2, 3, 4, 5, 9, 14, 18, 20, 25, 27, 30, 34, 35], [3, 5, 7, 8, 10, 12, 17, 18, 20], [0, 4, 5, 6, 8, 9, 12, 17], [3, 7, 8, 9], [0, 6, 7, 9, 13, 15, 16], [0, 1, 8, 9, 10, 12], [0, 1, 3, 5, 10], [1, 5, 8, 11, 12, 14, 15, 16], [1, 2, 3, 5, 6, 13], [0, 1, 5, 7], [3, 5, 6, 7, 12, 13], [1, 2, 3, 4, 5, 9], [0, 2, 3, 9, 11, 13, 14, 15, 20, 21, 25, 26], [5, 6, 7, 8], [0, 2, 3, 4, 6], [2, 3, 4, 5, 6], [1, 4, 6], [2, 5, 7, 8, 9], [2, 3, 4, 10, 11, 12, 14, 16], [0, 4, 5, 7], [1, 2, 8, 10, 11, 13, 16, 19, 21], [0, 3, 6, 8, 10], [1, 3, 4, 8, 10], [0, 1, 5, 7], [0, 1, 3, 5], [1, 3, 8, 9, 10, 11, 15], [1, 2, 3, 6, 10, 11, 12, 14], [1, 3, 6, 8, 11, 13], [1, 4, 5, 6, 8], [1, 2, 4, 5], [3, 4, 6, 9, 10], [0, 2, 8, 9], [0, 4, 5, 6], [1, 5, 6, 7, 10], [1, 6, 8, 10, 11, 12], [0, 3, 7, 8, 10], [0, 3, 5, 7], [2, 4, 6, 7, 9], [1, 5, 6, 7], [0, 3, 7, 9, 11, 12], [1, 3, 10, 11, 13, 16, 19, 21, 26, 28, 29, 31, 33, 34], [1, 2, 7, 8, 9, 13, 14, 15], [4, 7, 9, 10, 11, 13], [1, 5, 7, 9, 12, 14, 15, 17], [0, 2, 4, 5, 6], [0, 1, 2, 3], [1, 6, 7, 9, 10], [2, 3, 5, 8, 10], [1, 3, 6, 8], [1, 6, 7, 10, 11, 12, 13, 16], [2, 3, 4, 5, 7, 8, 15], [1, 2, 3, 6, 7, 11], [5, 9, 10, 13, 16, 17, 18, 20, 21], [4, 5, 8, 9], [1, 2, 7, 8], [3, 5, 6, 9, 11, 13], [4, 5, 10, 12, 13, 16, 17, 19, 20, 22], [0, 3, 4, 5], [2, 5, 6, 7, 10, 12], [1, 4, 5, 7], [3, 4, 5, 7, 10, 13, 15, 17, 18, 19], [1, 2, 4, 5, 12, 13, 14], [0, 3, 5, 10, 11, 12, 17, 18, 20], [4, 5, 6, 9, 11, 12], [1, 2, 4, 6, 9], [2, 3, 5, 7, 9, 10], [1, 4, 5, 9, 13, 15, 16], [2, 3, 6, 8, 9, 11, 16], [0, 3, 5, 8], [1, 2, 5, 6, 8, 11], [1, 3, 5, 6], [3, 6, 8, 9], [0, 2, 7, 8, 9, 10, 12, 17, 22, 23, 24, 26], [0, 2, 6, 7, 8, 10, 16, 17], [2, 4, 5, 6], [0, 5, 6, 7], [0, 4, 6, 7], [0, 1, 3, 7, 11], [1, 3, 4, 7, 10], [2, 3, 7, 10, 11, 12], [1, 2, 4, 6, 8, 13, 14, 15, 17], [0, 1, 2, 7], [1, 4, 5, 8, 10], [0, 1, 2, 5, 6], [1, 4, 6, 8, 11, 13], [2, 3, 7, 8, 11, 13], [4, 5, 6, 7, 8], [3, 4, 5, 6, 7, 9], [2, 4, 6, 7, 10, 12, 14, 18, 19, 21], [0, 3, 7, 8], [5, 6, 8, 10, 11, 14, 16, 17], [1, 3, 6, 7], [0, 2, 4, 5], [0, 1, 5, 8, 12, 13], [3, 4, 7, 8, 10], [0, 1, 2, 4, 5, 8, 11, 12, 13, 14, 18], [1, 4, 6, 8, 9], [1, 6, 7, 8, 11, 13], [0, 7, 11, 14, 15, 17, 18, 20, 21], [6, 7, 8, 9], [4, 5, 6, 9], [4, 6, 7, 8], [4, 5, 6, 9], [4, 7, 12, 13, 17, 20, 22, 23, 26, 28, 29, 31, 32, 33, 34], [2, 3, 8, 11, 14, 16, 17, 18], [1, 5, 6, 7], [0, 2, 4, 9, 10], [0, 2, 3, 4, 8, 13, 15, 16, 17, 18, 19], [0, 1, 5], [0, 3, 6, 8, 10], [1, 2, 3, 8, 9, 10, 11, 13], [0, 1, 4, 6, 10], [4, 9, 10, 12, 14, 17, 20, 21, 22, 23, 26, 30, 33, 34, 38, 41, 44, 49, 57, 59, 61, 63, 65, 68, 69, 73, 75, 77, 81, 84, 85, 87, 89, 90, 95, 98, 100, 103, 107, 109, 112, 113, 115, 122, 124, 127, 128, 129, 134, 135, 138, 141, 146, 147, 149, 150, 151, 154, 155, 157, 158, 160, 162, 167, 169, 171, 172, 174, 175, 178, 182, 183, 192, 194, 195, 196, 198, 200, 201, 203, 204, 205, 206, 207, 208, 209, 212, 216, 218, 219, 223, 230, 231], [0, 1, 5, 6, 9, 11, 12, 13], [1, 5, 6, 8, 9, 10, 12, 16, 18, 20, 22], [0, 1, 2, 3, 6, 7, 10, 12, 14, 16, 19, 20, 21, 25, 29, 32, 34, 37, 38, 39, 42, 45, 46, 47, 49, 50, 52, 55, 57, 58, 61, 62, 66, 70, 76, 79, 82, 83, 86, 90, 92, 93, 94, 95, 97, 98, 102, 107, 108, 109, 110, 116, 119, 125, 129, 134], [1, 2, 4, 6, 7, 10, 12, 15], [0, 4, 8, 9, 13, 14], [4, 5, 6, 7, 10, 11, 13, 17, 18, 23], [2, 3, 4, 5, 9], [0, 1, 2, 6, 8], [1, 2, 6, 8, 10, 13, 16, 18, 23, 26, 27, 29, 31, 36, 37, 39, 40], [0, 4, 7, 9, 12, 14, 15, 20, 21], [0, 1, 3, 5, 7, 9, 10, 12, 15, 17, 18, 22], [0, 1, 2, 6, 9, 11], [0, 3, 5, 6], [3, 5, 7, 9, 10], [0, 4, 5, 8, 10, 13, 17, 20, 21, 23, 24], [1, 3, 5, 6, 7, 9], [2, 3, 6, 7, 9], [1, 2, 4, 5, 8, 16, 17, 18, 19, 22], [0, 2, 4, 5], [0, 1, 2, 4, 6, 10], [0, 3, 5], [0, 1, 3, 8, 13, 15, 16], [0, 5, 6, 9, 11, 12, 16, 17], [2, 4, 5, 7, 11], [1, 4, 8, 10, 11], [0, 1, 7, 11, 12, 13, 15], [1, 5, 6, 9, 11, 14, 21, 22, 23, 25, 26, 28, 35, 36, 40, 42, 43, 44], [0, 2, 8, 9, 11], [0, 1, 2, 5, 6, 7, 9, 11, 15, 18, 23], [1, 2, 4, 5, 8], [7, 9, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26], [1, 2, 3, 5], [0, 3, 4, 6, 10], [3, 5, 8, 9, 11, 13], [2, 5, 7, 11, 12, 13, 14], [3, 4, 5, 8, 11, 12, 15], [0, 2, 4, 5], [3, 4, 5, 6, 7, 14, 16], [0, 2, 4, 6, 7, 9, 10], [0, 4, 6, 8, 11, 12], [1, 2, 4, 8, 10, 11, 13, 17], [0, 3, 4, 7], [1, 3, 4, 5, 7, 11], [0, 1, 3, 8], [2, 5, 8, 9, 11], [1, 3, 5, 9], [2, 4, 10, 11, 12, 15, 17, 18, 19, 22, 23, 27], [3, 7, 8, 9, 10, 13], [2, 4, 5, 7], [7, 8, 10, 12, 13, 14, 15, 17], [1, 2, 3, 9, 10, 11], [0, 3, 5, 7, 9, 10, 11, 12, 16, 22, 26, 28, 32, 35, 37, 38, 39, 41], [0, 2, 4, 8, 9, 13, 14, 19, 23, 25, 27, 29, 30, 31], [0, 1, 4, 6, 7, 12, 13], [1, 2, 3, 4, 8], [1, 2, 3, 6], [0, 1, 3, 8], [1, 2, 7, 10, 12, 13, 14, 17, 18, 23], [1, 2, 4, 5, 7, 9], [1, 3, 6, 7, 8], [2, 5, 6, 8, 11, 12, 15, 18, 20, 22, 24, 25, 26, 27, 29, 34, 39, 43, 45, 46, 48], [0, 2, 5, 6, 15, 16, 17, 19], [0, 3, 7, 9, 10, 13, 15, 17, 20, 22], [0, 1, 3, 4], [2, 3, 4, 7], [0, 1, 4, 6, 9, 10, 12], [2, 6, 7, 9], [2, 3, 4, 5, 8, 10, 12, 15], [1, 5, 6, 7, 9, 12], [2, 3, 5, 9, 11, 12, 17, 19, 20, 23, 24], [3, 5, 6, 7], [2, 3, 5, 6, 7, 12, 17, 18], [0, 5, 6, 10, 14, 17, 18, 20, 21, 23, 25, 26], [0, 6, 7, 8, 11, 12], [2, 6, 7, 10, 12, 13], [2, 3, 7, 10, 11, 12], [0, 3, 5, 6, 7], [2, 7, 8, 9, 10], [1, 2, 7, 8], [3, 5, 6, 7, 8, 9], [0, 4, 5, 6, 11, 12, 13], [5, 6, 9, 10, 11, 12], [4, 5, 8, 9, 10, 12, 13, 15], [0, 1, 2, 5, 6, 12], [4, 5, 8, 9, 10], [1, 2, 4, 6, 7], [0, 2, 5, 8, 9], [2, 5, 7, 8], [4, 5, 6, 9, 11, 12], [0, 1, 3, 4], [0, 2, 6, 7], [0, 5, 6, 8, 9], [2, 4, 8, 11, 12, 15, 16, 17], [4, 5, 8, 9, 11, 14, 15, 16], [1, 2, 3, 4, 7, 12], [0, 1, 3, 4, 5, 8, 13], [1, 2, 3, 8], [1, 2, 3, 8, 9, 10], [0, 1, 3, 5, 7, 10, 13, 18, 19, 20], [0, 2, 3, 5, 7, 8, 9, 10, 13, 15, 16, 18, 22, 26, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 46, 47, 51, 53, 55, 57, 63, 70, 77, 78, 79, 80, 82, 84, 89, 90, 95, 98, 102, 105, 112, 115, 118, 119, 125, 129, 132, 133, 135], [2, 6, 8, 13, 14, 15, 16, 17, 18, 20, 25, 26], [0, 1, 2, 5, 9, 11, 13, 14, 16, 17, 23], [0, 3, 6, 9, 11, 13, 15, 17], [1, 3, 4, 7, 11, 13, 17, 19, 21, 22, 24, 26], [0, 2, 3, 5, 6, 8, 10, 16, 21], [0, 2, 6], [0, 3, 4, 5, 7, 9, 11, 13], [3, 4, 5, 8, 10], [1, 5, 6, 10, 12, 13], [2, 4, 5, 6, 9, 13, 16, 17, 20, 23], [0, 1, 2, 4], [0, 3, 8, 9, 10], [0, 1, 2, 6, 9, 12, 13], [2, 3, 4, 8, 10, 11, 12, 17, 21, 23, 26, 27], [2, 4, 13, 14, 16, 17, 18, 21, 24, 25, 29, 32, 36, 39, 40, 42, 43, 46, 47, 48, 49], [1, 4, 6, 7, 9, 10, 12, 16, 18, 20, 24], [0, 1, 2, 3, 5, 10], [3, 4, 6, 7, 10], [0, 1, 5, 6, 7, 8, 10, 11, 14, 16, 20, 22, 30, 32, 34], [2, 3, 5, 6, 7, 11, 12, 16, 17, 23], [0, 1, 3, 5, 9], [3, 5, 8, 9, 10, 11, 16, 18, 19], [1, 3, 5, 6, 9, 11], [0, 3, 5, 7, 8], [0, 2, 3, 5, 8, 11, 14, 18], [1, 4, 5, 7], [2, 3, 6, 8], [0, 6, 7, 10, 11, 12], [1, 2, 4, 5, 9], [1, 2, 4, 5], [1, 4, 6, 10, 11], [1, 4, 5, 9, 10], [0, 5, 6, 7, 12, 13]], [[2, 3, 7, 13, 14, 15, 16, 17], [5, 7, 9, 10, 12, 14, 15, 16], [0, 2, 3, 5, 6, 8, 11, 12, 20, 21, 25], [0, 2, 3, 5, 6, 9], [0, 1, 2, 9, 11, 15, 17, 18, 19, 23], [0, 3, 8, 9, 10, 14], [3, 6, 7, 8, 9, 10, 11, 16, 18], [1, 2, 8, 9, 11, 12, 18, 19, 20, 22], [1, 2, 4, 7, 8, 9, 12, 14, 19, 20, 24, 28, 29], [2, 4, 8, 9], [1, 5, 8, 9, 12, 13, 15], [0, 1, 3, 4, 5, 7, 9, 10, 18, 22], [1, 3, 4, 5, 11, 13, 14, 16, 18, 20], [4, 5, 9, 12, 13, 14, 18, 19, 21, 22], [2, 4, 5, 7], [0, 2, 7, 8, 9], [0, 4, 5, 6], [0, 3, 6, 9, 11], [2, 5, 8, 10, 11, 13, 14, 15, 17, 22, 26], [3, 4, 5, 6, 8, 15, 17, 18, 20, 21], [1, 2, 3, 9, 10, 11, 14, 16, 19], [3, 4, 6, 10, 12, 15, 17, 19], [1, 2, 10, 11, 13, 14], [1, 2, 6, 8, 9], [1, 2, 3, 4, 9], [2, 4, 6, 7, 10], [0, 2, 3, 4, 6, 11, 12, 13, 15, 16, 21, 23], [0, 3, 6, 8, 9], [0, 6, 7, 9, 11, 14, 17, 18], [0, 3, 6, 10, 11, 13, 15, 16], [3, 4, 5, 7, 12, 13, 14, 20, 21], [4, 5, 6, 9, 10, 12, 16, 17], [1, 5, 7, 9, 10, 14, 16, 18, 19], [0, 1, 3, 5, 7, 16, 17, 18], [2, 5, 6, 8, 9], [3, 4, 5, 9, 13, 14, 15, 16], [0, 1, 6, 7, 8], [1, 2, 4, 6, 7, 12], [3, 4, 5, 8, 10, 14, 16, 17, 18, 22, 24, 25], [0, 3, 5, 6, 7, 10, 12, 13, 18, 22], [1, 3, 4, 10, 11, 16, 19, 20, 21, 22, 26, 27], [0, 4, 8, 10, 11, 12, 14, 16, 17, 18], [2, 3, 7, 10, 11], [0, 2, 4, 5, 11], [1, 2, 5, 6, 8, 9], [1, 3, 9, 12, 13, 14, 15, 16], [7, 9, 11, 12, 14, 15, 17, 18], [0, 3, 6, 7, 9, 10, 12, 17, 19], [3, 7, 11, 13, 14, 15, 16, 18, 20], [0, 2, 3, 8, 9, 10, 12, 15, 16, 21, 23], [0, 2, 4, 8, 10, 11, 15], [0, 2, 3, 4, 6, 10], [1, 3, 6, 7, 8, 10, 13, 17, 20, 21], [5, 6, 9, 10, 11], [1, 3, 4, 8, 10, 11, 16, 17, 18, 21], [2, 5, 8, 11, 13, 14, 16, 17, 21, 22], [3, 4, 7, 9, 10], [0, 4, 5, 9, 12, 15, 16, 17], [10, 13, 14, 15, 16, 17, 18, 19], [1, 4, 5, 9, 11, 12, 13, 15], [0, 1, 3, 5, 6, 7, 8], [2, 5, 6, 7, 9, 11, 13, 14, 16, 18], [0, 3, 6, 8, 9], [1, 7, 9, 10, 11, 12], [3, 4, 5, 7, 8, 10, 12, 14], [7, 10, 12, 14, 16, 17, 19, 22, 23, 24], [2, 4, 6, 12, 13, 15, 16, 18, 20, 21, 23], [0, 1, 2, 4, 5, 9, 11, 12, 13, 17, 20], [4, 5, 9, 13, 14, 16, 17, 19], [0, 4, 5, 6, 7, 12, 16, 17, 20, 22], [0, 1, 4, 9, 11], [4, 6, 7, 9, 13, 14, 16, 17, 22, 23], [2, 4, 5, 9, 10, 12, 13], [0, 1, 3, 4, 9], [2, 3, 8, 9, 10, 12, 15], [3, 7, 8, 9, 11, 12, 14], [1, 4, 5, 6], [0, 5, 7, 8, 10, 17, 19, 20, 21, 23, 26, 27], [2, 4, 7, 8, 12, 15, 18, 20, 21], [1, 2, 3, 6, 7, 10, 14, 19, 23, 25, 26], [0, 1, 4, 9, 11, 12, 14, 17], [1, 2, 4, 9, 13, 14, 15, 17, 18, 19, 20], [4, 8, 9, 10, 12, 13], [0, 1, 4, 9, 10, 11], [1, 5, 7, 8, 9, 15, 18, 19, 20], [0, 2, 4, 6, 7, 8, 11, 17, 21], [1, 4, 6, 7, 13, 17, 18, 19, 20, 21, 22], [1, 5, 6, 8, 9, 11, 12, 16, 17, 18, 26, 27], [4, 5, 6, 9, 12, 13, 16, 21, 22, 23, 25], [3, 4, 7, 8, 11, 12], [2, 3, 6, 7], [0, 1, 2, 9, 11, 13, 16, 18], [1, 2, 4, 8, 9], [1, 3, 6, 14, 15, 16, 18, 19, 20], [0, 4, 8, 9, 12, 13, 16], [4, 5, 6, 7, 9, 12, 13, 14], [0, 2, 10, 12, 14, 17, 18, 19], [2, 3, 7, 9, 13, 14], [2, 4, 7, 9, 14, 15, 17, 19], [0, 1, 5, 8, 10, 11, 12, 13, 16, 22, 25, 27], [0, 3, 6, 7, 11, 13, 14, 15, 18, 23, 25], [0, 1, 2, 4, 6, 7, 10, 13, 15, 19], [0, 3, 4, 7, 9, 12, 15], [0, 1, 3, 4, 6, 10, 13, 15, 18], [2, 3, 8, 10, 16, 17, 18, 20, 21, 23], [0, 2, 6, 7, 9, 16, 17, 20, 21, 22, 23], [1, 6, 7, 9, 10, 12], [1, 4, 5, 6], [2, 3, 4, 5, 9, 11], [2, 4, 8, 9, 10, 14, 19, 21, 23, 24, 25], [0, 1, 2, 8, 10, 11, 12, 14, 15, 16, 17, 18, 21, 23, 33, 34, 35, 36, 39, 41, 48, 51], [2, 3, 4, 6, 7, 8, 10, 15], [2, 4, 6, 9, 10, 14, 16, 18], [0, 1, 3, 6, 10, 11], [0, 1, 2, 4, 5, 7, 13, 15, 19, 23], [1, 2, 3, 5, 9, 11, 13, 17, 19], [1, 6, 7, 8, 10, 11], [1, 2, 4, 6, 9, 10, 13, 14], [3, 7, 9, 10, 11, 12, 13, 14, 16], [1, 3, 5, 7, 8, 10, 12, 17], [0, 5, 7, 8, 10, 13, 14, 17, 18, 19, 23, 27], [4, 6, 7, 14, 15, 16, 18, 20, 22, 24, 26], [1, 3, 4, 5], [1, 5, 6, 7, 10, 11, 17, 18, 21], [1, 3, 7, 11, 13, 14, 16, 18], [6, 7, 8, 9, 10, 13, 15, 16, 20, 22], [2, 5, 6, 7, 8, 11, 15, 16, 17, 19, 20], [1, 2, 4, 6, 7, 10, 14, 17, 18, 21, 22, 29, 30], [1, 4, 6, 7], [0, 2, 4, 8, 10, 12, 16, 20, 21], [0, 1, 2, 4, 11, 12], [4, 5, 8, 9, 12, 13], [5, 6, 10, 11, 12, 13], [4, 7, 10, 13, 14, 17, 18, 19], [0, 2, 5, 7, 8, 9, 11, 12, 18, 22, 24, 25], [0, 1, 4, 7, 10, 12, 15, 16, 17, 19], [3, 6, 9, 10, 11, 15, 16, 20, 21, 24, 26], [0, 3, 7, 8, 9, 11, 14], [1, 2, 7, 10, 13, 14], [0, 1, 2, 7, 8], [0, 3, 9, 14, 16, 18, 21, 22, 23, 25, 26], [2, 4, 5, 6, 7, 10, 14, 17, 20, 21], [0, 2, 5, 6, 9, 11, 14], [0, 1, 3, 10, 11, 12], [3, 5, 7, 8], [1, 3, 5, 6, 12, 14, 16, 17], [7, 9, 10, 11, 12, 14, 16, 19, 20, 21], [1, 3, 4, 9, 12, 13, 15, 17, 18, 20], [3, 5, 7, 8, 10, 13, 15], [2, 3, 5, 8, 10], [1, 3, 5, 10, 13, 14, 15, 17, 20, 22], [0, 1, 2, 5, 9, 14, 17, 18, 19, 22], [1, 2, 3, 4, 5, 9, 15, 17], [0, 3, 4, 5, 7, 9, 12, 19], [0, 1, 6, 12, 13, 14, 17, 18, 22, 23], [0, 2, 9, 10, 12, 13, 17, 18], [0, 1, 2, 5, 11, 12, 13, 16, 19, 23, 26, 28], [0, 3, 4, 8, 10], [0, 9, 11, 14, 15, 16, 17, 19, 20, 22, 23], [0, 5, 6, 8, 11, 12, 13, 20, 21], [2, 5, 6, 8, 12, 13], [1, 6, 8, 9, 12, 14], [1, 2, 3, 5], [1, 5, 6, 7, 10, 12], [0, 3, 4, 5, 10, 12, 14, 15, 19, 21], [1, 3, 4, 5, 9, 13, 17, 18], [2, 4, 5, 6, 8, 13, 14, 16], [2, 3, 7, 10, 12, 14, 15, 18, 20, 21, 25], [0, 1, 6, 7, 8, 15, 16, 18], [0, 6, 7, 8, 12, 14, 15, 17, 18], [1, 4, 6, 9, 10], [2, 5, 6, 7, 9, 11], [1, 3, 6, 7, 12, 13, 15, 19, 20], [1, 3, 6, 8, 12, 14, 15, 18, 19, 21, 27, 30], [3, 5, 7, 9, 11, 13], [0, 2, 5, 6, 10, 14, 15, 18], [1, 2, 5, 7, 8, 15, 16, 18, 19], [0, 2, 4, 8, 10], [0, 3, 10, 12, 14, 16, 17, 18, 20], [0, 1, 7, 11, 14, 15, 16, 19, 21, 23], [3, 6, 8, 10, 13, 15, 16, 17], [2, 7, 8, 11, 12, 13, 14, 17, 20, 24], [3, 4, 5, 6, 9, 10, 11], [6, 7, 10, 16, 17, 18, 19, 20, 21, 23], [0, 4, 5, 7, 8, 10, 11, 12, 18, 21], [2, 5, 6, 7, 8, 9, 14, 15, 19], [2, 3, 8, 10, 13, 15, 16], [3, 5, 6, 7, 9], [0, 5, 8, 9, 10, 12, 15, 16, 17, 19], [2, 4, 6, 7, 9, 13, 15], [1, 5, 7, 10, 11], [1, 2, 3, 6, 7, 12, 13, 15, 17, 20, 22, 27], [1, 3, 5, 6, 7, 10, 13, 16, 17, 22], [1, 3, 6, 10, 11, 12], [0, 4, 9, 11, 12, 14], [1, 2, 3, 4, 9, 11, 15], [1, 2, 3, 4, 5, 12], [1, 7, 9, 11, 12, 13, 14, 18, 22, 24], [0, 1, 3, 4, 6, 10, 11, 14, 16, 20], [0, 2, 3, 5, 6, 8, 9, 10, 17, 19], [1, 3, 4, 8, 9, 13], [1, 2, 3, 4, 6, 7, 10, 15], [2, 3, 4, 10, 14, 15, 16, 17], [0, 1, 2, 4, 5, 7, 9, 15], [0, 1, 2, 3, 7, 10, 11, 13, 18], [0, 2, 4, 6], [2, 5, 6, 7, 10], [5, 6, 8, 10, 11], [4, 5, 6, 7, 8, 11, 15], [0, 1, 4, 7, 8, 12, 15, 17, 18, 24, 25], [1, 2, 4, 6, 7, 9, 10, 11, 18, 22], [1, 3, 4, 7], [1, 2, 4, 5, 7, 12, 14, 19, 20, 22], [2, 3, 6, 7, 12, 13, 16, 17], [1, 8, 9, 12, 13, 14, 17, 18, 20, 25, 27, 28], [0, 4, 5, 9, 12, 13, 14, 15], [0, 5, 6, 8, 10], [0, 2, 3, 4, 8, 10, 11, 14, 17, 22, 25, 27], [0, 3, 4, 8, 9, 11, 12, 13], [1, 3, 7, 8, 10, 13, 14], [2, 5, 9, 12, 13, 14, 18, 19, 20], [5, 6, 7, 8, 13, 14], [1, 3, 4, 5, 7, 10], [0, 8, 9, 11, 13, 14, 17, 20, 21, 24], [0, 1, 3, 5, 7, 9, 11], [1, 4, 6, 11, 12, 14, 15], [1, 2, 6, 11, 14, 17, 18, 19, 20], [3, 4, 5, 6, 7, 9, 11], [0, 2, 3, 5, 7, 9, 13, 18, 20, 24, 25], [0, 1, 5, 7, 8, 12, 13, 17, 19], [4, 8, 10, 12, 13, 14], [1, 3, 5, 8, 9, 11], [1, 3, 5, 7, 10, 12], [3, 4, 5, 6, 8, 9, 18, 21, 22, 23], [1, 2, 5, 7], [2, 3, 4, 5], [0, 2, 4, 7], [3, 4, 7, 8, 10, 16, 17, 18], [0, 1, 10, 13, 14, 15, 16, 17, 21], [3, 4, 6, 8, 11, 12], [0, 4, 6, 10, 12, 13, 15, 17, 18, 23], [0, 4, 9, 12, 14, 15, 17, 19, 20], [1, 2, 4, 6], [0, 2, 4, 6, 8, 10, 11, 12, 18, 20], [1, 6, 8, 9, 11, 15, 17, 18], [0, 1, 4, 5, 10, 12, 16, 17, 22, 23], [2, 3, 6, 8, 9, 10], [2, 5, 6, 7, 11, 13], [0, 4, 5], [0, 2, 3, 5, 6, 12, 19, 20, 21, 26, 27, 31, 32, 37, 39, 40, 41, 44, 45, 49, 51, 53, 54, 55, 59, 60, 62, 64, 72, 74, 75, 76], [0, 1, 3, 5, 9, 16, 18, 19, 21, 22, 23], [0, 2, 3, 4, 5, 10, 11, 12, 13, 18], [0, 2, 3, 4, 8, 10, 11, 14, 17, 22, 25, 27], [0, 2, 8, 9, 15, 17, 20, 21, 22, 23, 24, 25, 26, 28], [0, 6, 7, 8, 9, 16, 18, 21, 22, 23, 24, 29], [2, 5, 7, 8, 9, 13, 14, 20, 21, 22], [2, 5, 11, 12, 14, 16, 17, 19, 20], [0, 1, 2, 3, 7, 8, 14, 18, 21], [1, 3, 5, 6, 8, 9, 11, 14, 18, 20, 26, 27, 28, 29, 32], [1, 3, 4, 5, 6, 9, 13, 17, 20], [2, 3, 9, 11, 14, 15, 17, 19, 21, 22, 24], [1, 5, 6, 7, 8, 11, 14, 16, 17, 18], [0, 4, 9, 10, 16, 17, 18, 23, 24, 25, 27, 28, 29, 31, 32], [0, 3, 6, 7, 11, 14, 16, 20, 21, 22], [4, 6, 7, 8, 10, 13, 15, 19], [1, 3, 4, 9, 10, 12], [2, 8, 10, 11, 13, 14, 15, 16, 21, 24, 25, 26, 29, 31, 33, 35, 38, 41, 43, 44], [0, 3, 6, 8, 9, 11, 13, 15, 17, 23, 24], [3, 5, 6, 8], [1, 3, 7, 9, 10, 12, 15, 19, 21, 22], [0, 2, 7, 8, 10, 12, 14, 15, 20, 22, 24], [0, 2, 4, 5, 7, 9, 10, 14, 15], [1, 3, 5, 6, 8, 9, 10, 14], [0, 4, 6, 10, 13, 14, 15, 17], [0, 1, 2, 3, 9, 12, 15, 17], [7, 8, 10, 11, 12, 13, 14, 18, 20], [1, 3, 7, 9, 11], [2, 3, 4, 5, 6, 13], [0, 5, 6, 7, 9, 13, 15, 16, 20], [7, 10, 11, 12, 13, 14], [1, 2, 7, 8, 12, 17, 18, 19, 20], [1, 2, 3, 4, 8, 13, 15, 18, 19, 23], [0, 1, 2, 5, 11, 12, 13, 17], [0, 2, 3, 4, 6, 8, 9, 11, 13, 23, 26], [4, 8, 9, 10, 12, 13], [1, 3, 7, 11, 13, 14, 16, 18], [1, 6, 7, 8, 10, 11], [2, 6, 8, 10, 12, 13], [0, 1, 3, 7, 9, 13, 14, 16], [0, 3, 4, 6, 7, 9, 13, 15, 19, 21, 23, 31, 35, 36, 40, 42, 43, 44, 46, 48, 62, 64, 65, 76, 78, 83, 85, 86, 88, 89, 90, 92, 93, 98, 103, 106, 108, 109, 111, 112, 113, 114, 117, 118, 122, 129, 131, 135, 136, 137, 140, 141, 142, 145, 146, 147, 149, 151, 154, 156, 157, 160, 161, 163, 165, 168, 170, 172, 174, 176, 179, 182, 184, 186, 191, 193, 198, 201, 204, 206, 209, 210, 211, 215, 216, 217, 219, 227, 230, 232, 233, 236, 238, 239, 242, 243, 244, 245, 246], [1, 4, 5, 6], [1, 2, 5, 8, 10, 11, 13, 14, 16, 20, 21, 26, 30, 32], [0, 1, 3, 6, 7, 9, 10, 17, 18, 23, 25, 27, 28, 29, 30, 36, 38, 40, 49, 50, 53, 57, 60, 66, 69, 70, 71, 72, 75, 76, 78, 79, 80, 85, 94, 95, 96, 98, 99, 101, 102, 103, 104, 112, 113, 116, 117, 118, 120, 121, 122, 123, 126, 130], [1, 2, 6, 8, 10, 12], [2, 4, 7, 11, 12, 14], [0, 3, 4, 6, 9, 13, 14], [1, 2, 3, 4, 9, 11, 15], [10, 13, 14, 15, 16, 17, 18, 19], [0, 1, 4, 9, 11, 12, 14, 17], [0, 3, 9, 14, 16, 18, 21, 22, 23, 25, 26], [1, 2, 7, 8, 9, 10, 15, 18, 20, 22], [1, 3, 4, 8, 10, 12, 17, 19], [2, 3, 5, 7, 10, 11, 12, 16, 21, 23, 25], [2, 3, 6, 7], [6, 9, 10, 11, 16, 20, 21, 22, 23, 24], [1, 3, 4, 9, 12, 13, 15, 16], [0, 1, 5, 6, 7, 8], [0, 1, 7, 9], [0, 2, 4, 6], [1, 3, 4, 5], [4, 5, 9, 13, 14, 16, 17, 19], [4, 5, 10, 12, 14, 17, 18, 19, 20], [0, 2, 4, 8, 12, 13, 14, 15], [0, 5, 6, 10, 11], [4, 6, 8, 9, 13, 16, 17, 19, 20, 23, 26], [0, 3, 8, 10, 13, 15, 17, 19, 20, 22], [8, 9, 10, 11, 12, 13, 14, 17, 20], [1, 2, 6, 7, 8, 11], [1, 3, 4, 6, 8, 10, 12, 13, 16, 17, 23], [4, 10, 12, 13, 15, 16, 20, 21, 22, 23], [0, 5, 6, 8, 10], [0, 1, 2, 3, 13, 15, 18, 19, 21], [1, 4, 5, 8, 12, 13], [1, 2, 4, 6, 9, 11, 16, 17, 19, 21], [3, 4, 5, 7, 8, 10], [1, 7, 8, 10, 11, 12, 14, 17], [7, 8, 11, 12, 14, 17, 18, 22, 24, 25, 28, 29, 30], [0, 5, 6, 10, 11, 13, 14, 15, 20, 24, 25], [1, 3, 4, 7], [0, 2, 3, 5, 6, 9], [3, 6, 9, 10, 11, 12, 15, 20, 21, 22], [2, 6, 8, 10, 13, 14, 15], [3, 6, 7, 9, 13, 15, 16, 17, 19], [3, 7, 10, 11, 12, 15, 16], [0, 1, 3, 4, 8, 13, 14], [10, 11, 13, 15, 17, 18, 21, 23, 25, 27, 31, 32, 33, 34, 37, 38, 40], [0, 2, 5, 7, 8, 9, 11, 12, 16, 17, 19], [0, 7, 9, 12, 13, 14, 15, 17], [8, 9, 11, 14, 15, 16, 18, 21, 22, 24, 25], [3, 6, 8, 10, 12, 14, 15, 16, 22, 23], [1, 3, 4, 5, 7, 10], [1, 6, 7, 9, 10, 12], [2, 3, 4, 5], [1, 6, 7, 14, 15, 16, 17, 20, 21], [1, 5, 6, 10, 11, 13, 15], [3, 4, 5, 6, 8, 13, 14, 17], [2, 4, 7, 8, 11, 12, 13, 16], [0, 2, 3, 4, 5, 8, 17, 19], [0, 1, 4, 5, 6, 11, 12, 14, 17, 19, 25], [1, 2, 3, 8, 9, 10, 17, 19, 20], [3, 6, 7, 8, 9, 10, 11, 16, 18], [0, 3, 4, 5, 6, 13, 15, 18], [4, 10, 11, 12, 15, 16, 19, 20, 21, 23, 26, 27, 29, 31, 34, 36], [1, 3, 4, 6, 9], [4, 5, 6, 12, 13, 14, 19, 20, 21, 25, 26], [1, 2, 3, 9, 10, 11, 14, 16, 19], [0, 4, 9, 11, 12, 13, 14], [0, 2, 5, 8, 10], [0, 1, 2, 9, 11, 15, 17, 18, 19, 23], [0, 5, 6, 9, 10, 12, 14, 16], [0, 1, 2, 4, 6, 10, 12, 14], [0, 3, 4, 9, 10, 16, 17, 19], [1, 4, 6, 7, 10, 13, 14], [0, 2, 8, 9, 10, 11, 16, 17], [0, 2, 3, 10, 11, 12], [0, 2, 5, 6, 7, 10, 11, 17, 19, 22], [2, 4, 8, 9, 10, 14, 19, 21, 23, 24, 25], [4, 7, 8, 10, 12, 14, 16], [0, 4, 9, 10, 11, 13, 15], [0, 1, 2, 7, 10, 12, 14, 19, 20], [0, 3, 4, 8, 9, 12], [5, 9, 11, 12, 13, 14, 15, 18, 19], [0, 2, 6, 8, 15, 16, 17, 19, 20, 21, 22, 28, 30, 31], [4, 5, 6, 7, 8, 12, 16], [3, 8, 9, 11, 13, 15, 16, 18, 20, 21, 22, 25, 27, 30], [0, 1, 4, 5, 6], [1, 4, 6, 9, 10, 12, 15], [0, 4, 6, 11, 12, 13, 17, 19, 20], [1, 2, 3, 5, 8, 9, 13, 17, 21, 22], [1, 2, 3, 4, 8, 12, 14, 15, 18, 23, 24, 29, 30, 31, 36, 37, 38, 39, 44, 47, 49, 55, 57, 63, 64, 65, 68, 70, 71, 74, 75, 77, 80, 82, 87, 88, 92, 94, 95, 96, 98, 99, 101, 103, 107, 110, 114, 116, 120, 121, 122, 125, 128, 130, 139, 140, 141, 143, 145, 146], [3, 4, 8, 9], [3, 4, 5, 6, 7, 8, 10, 13, 16, 20, 26, 27], [1, 2, 4, 9, 13, 14, 15, 17, 18, 19, 20], [0, 1, 3, 8, 9, 12, 15, 17, 19, 20, 25], [6, 7, 8, 9, 10, 12], [0, 1, 2, 3, 5, 10, 14, 17, 18], [0, 3, 6, 8, 10, 11, 14, 16], [0, 1, 2, 4, 5, 10, 11, 19, 21, 23], [0, 3, 8, 10, 11, 12, 14, 15, 18], [2, 4, 6, 12, 13, 15, 16, 18, 20, 21, 23], [0, 4, 5, 8], [2, 5, 6, 7, 8, 9, 13], [0, 4, 5, 9, 12, 14, 15, 17, 19, 24, 26, 28, 29], [0, 3, 5, 6, 7, 12, 13, 14], [4, 6, 8, 10, 11, 13, 14, 16], [2, 3, 6, 11, 12, 14, 19, 22, 24, 25, 26, 29, 30, 31], [0, 2], [0, 2, 4], [0, 3, 4, 5, 7, 10, 11, 19, 20, 23, 26], [3, 4, 5, 6, 12, 15, 18, 19, 20, 21, 22, 28, 30, 31], [0, 1, 2, 6, 7], [3, 4, 6, 9, 10, 13], [2, 4, 5, 9, 11, 12, 13, 14, 20], [0, 2, 6, 9, 11, 12], [0, 2, 3, 4, 7, 9, 13, 16, 18, 21], [0, 4, 8, 10, 13, 15, 19, 20, 21, 26, 27, 29, 31, 33, 35], [1, 3, 5, 9, 11, 13, 16, 17], [1, 6, 8, 9, 11, 12, 14, 17, 23, 26, 27, 28], [2, 5, 7, 8, 10], [3, 5, 6, 8, 10, 12], [3, 8, 11, 14, 16, 18, 19, 20, 21, 23, 24, 26, 29, 31, 32, 33], [1, 6, 7, 8, 10], [0, 2, 4, 5], [1, 3, 4, 5, 6, 11, 13, 15, 19], [0, 2, 3, 4, 10], [1, 2, 4, 6, 9, 11], [2, 10, 12, 13, 15, 16, 17, 19, 21, 22]], [[1, 3, 4, 6, 8], [2, 3, 4], [2, 5, 6, 7, 8, 10, 13, 17, 18, 19], [0, 1, 3, 5], [0, 1, 7, 9], [1, 2, 6], [0, 1, 2], [0, 1, 6, 8], [2, 3, 7, 9, 10, 12, 13, 14, 18], [0, 2, 3, 10, 11], [6, 7, 8, 9, 10], [2, 5, 6, 7, 9], [0, 2, 4, 5, 6, 11, 14], [0, 6, 7, 11, 12, 13, 14, 15, 17], [0, 2, 4], [2, 3, 4, 9, 11], [1, 4, 5, 8, 11], [0, 2, 4, 5, 9], [0, 2, 4], [2, 5, 6, 7, 9], [0, 3, 4, 5, 7, 12], [0, 7, 8, 10, 12, 13], [1, 2, 3, 6, 7, 9, 12, 13, 18], [1, 3, 4], [0, 2, 4, 6, 9, 12], [1, 3, 6, 7], [1, 3, 4, 6], [3, 5, 11, 12, 13, 15, 16], [0, 4, 6, 7], [1, 4, 6, 7, 8, 9, 12, 13, 14, 19, 23, 24], [3, 4, 5, 7], [2, 7, 8, 10, 11], [4, 5, 6, 8, 10, 13], [1, 6, 7, 10, 12, 15, 16, 18, 24, 26, 27, 33, 34, 35, 36, 39, 40, 41, 42], [1, 3, 6, 8, 12, 14, 16], [0, 3, 7, 9], [0, 1, 4, 6, 7, 8], [0, 6, 7, 8, 11, 14, 16, 19, 20], [1, 3, 4, 7], [0, 1, 6, 7, 9, 14, 18, 20, 22, 23, 24, 28, 31, 34, 37, 39, 40], [1, 2, 3, 5], [3, 4, 5, 6, 10], [0, 2, 4, 5, 7, 13, 19, 20, 21], [2, 3, 4, 7, 11, 13], [0, 1, 2, 5, 10, 13], [1, 3, 5, 7], [3, 4, 6, 9, 11, 12], [0, 3, 6, 7, 13, 14, 16, 19], [0, 2, 5, 9, 12, 13, 14, 16, 18, 19], [0, 1, 4, 6, 7, 12], [0, 1, 4, 9, 11, 12], [0, 2, 6], [0, 4, 5], [2, 5, 7, 10, 11, 12, 14, 15], [0, 1, 5, 7, 8], [3, 4, 5], [0, 3, 4, 6, 7, 9, 10, 11, 18, 19, 21, 22, 25, 31, 35, 37], [4, 6, 8, 9, 12, 13, 14, 17, 22, 24, 27, 32, 33, 34, 38, 40, 41, 44, 46], [0, 3, 5, 6, 8, 12, 13, 14, 23, 25, 26, 27, 30, 34], [1, 2, 4, 5, 6, 9, 11, 13], [1, 5, 6, 12, 13, 14, 15, 16, 17, 19, 20, 25, 26], [2, 4, 7, 8, 9], [2, 3, 4, 10, 13, 14], [4, 5, 6, 8, 9], [2, 5, 6, 7, 8, 14], [2, 4, 8, 12, 15, 17, 18, 19, 20, 25, 29, 30, 35, 37, 38, 39], [0, 1, 2, 3], [1, 7, 8, 12, 19, 22, 23, 25, 27, 29, 30, 32, 33, 36, 37, 41, 43, 44, 46], [0, 5, 6, 7, 13, 14, 17, 18, 20, 21, 26, 28, 33, 35, 37, 39], [2, 5, 6, 8, 13, 14, 18, 20, 22, 24, 27, 28, 30], [0, 2, 5, 7], [1, 4, 5, 12, 15, 16, 17, 18, 19, 21], [0, 1, 4, 5, 8], [1, 3, 4], [2, 3, 6, 7, 12, 13, 16, 17, 21, 22], [1, 3, 6, 7], [0, 2, 5], [0, 1, 2, 4], [1, 5, 6, 7, 8], [4, 7, 8, 9, 10], [0, 1, 2, 7, 8, 13, 15, 17], [2, 5, 8, 12, 13, 14, 15, 17, 18], [1, 2, 4], [0, 2, 6], [2, 3, 5], [2, 4, 7, 8, 10], [1, 3, 4, 6], [0, 2, 5, 9, 12, 13, 14, 16, 18, 19], [0, 1, 5, 8, 11, 13, 14], [3, 5, 7, 9, 10, 12, 13, 17], [2, 3, 4, 6, 7, 12], [1, 2, 3, 8, 10], [0, 2, 3, 4, 9, 13, 14, 15, 17, 19, 22, 32, 33, 34, 37, 39, 40], [1, 2, 3, 6, 11], [0, 2, 3, 4, 5, 10, 17, 22, 23, 24, 26, 27], [2, 4, 5, 8, 9], [1, 6, 8, 11, 14, 15, 16, 18, 19], [0, 4, 5, 7, 10], [0, 1, 2, 3, 6, 7], [1, 3, 5, 6, 10, 11], [2, 3, 6, 7, 8, 11, 12, 15, 16, 17, 18, 19, 23, 24, 34], [1, 2, 6, 9, 10, 13], [0, 5, 6, 7, 9], [1, 2, 3, 5, 9, 13, 14, 15, 18, 20, 21, 22, 25], [2, 5, 6, 7, 8, 11, 12, 16, 18, 22, 23, 24, 27, 30, 33], [7, 9, 10, 11, 17, 19, 20, 21, 23, 24, 25, 27, 29, 31], [0, 3, 4, 5, 7, 10, 11, 13, 14, 18, 21, 24], [1, 3, 5, 8, 10, 12, 13, 14, 17, 21, 25], [4, 5, 6, 7, 12, 13, 14, 17, 19, 20, 21, 23], [1, 5, 6, 7, 9], [1, 5, 6, 7, 8, 11, 12, 15, 16, 18, 20], [0, 2, 6, 7, 9, 10, 11, 14, 16, 19, 24, 25, 30, 31, 35, 38, 45, 46, 50, 51, 54, 56, 58, 60, 62, 65, 67, 68, 70, 71, 74, 77], [2, 6, 8, 11, 12, 15, 16], [0, 1, 2, 4, 9, 13, 14], [2, 4, 5, 7, 8, 9, 11, 12, 16, 17, 23, 25], [3, 5, 6, 8], [4, 5, 7, 8, 9], [5, 6, 9, 10, 12, 18, 19, 23, 27, 29, 30, 32, 34, 35, 38, 39, 44, 46, 47, 48], [2, 3, 5, 8, 12, 15, 17, 18, 22, 23], [0, 3, 5, 7], [0, 2, 6, 7, 9, 10, 11, 14, 16, 19, 24, 25, 30, 31, 35, 38, 45, 46, 50, 51, 54, 56, 58, 60, 62, 65, 67, 68, 70, 71, 74, 77], [3, 5, 6, 8, 9, 11, 14, 16], [0, 2, 4, 5, 7], [2, 7, 8, 9, 13, 14], [0, 3, 6, 8, 9, 12, 15], [1, 3, 5, 6, 8, 9, 10, 13, 18, 22], [2, 3, 4], [2, 3, 4, 7, 11], [0, 1, 3, 4], [0, 4, 6, 7], [2, 3, 5, 6, 7, 8], [0, 2, 3, 6, 7], [8, 10, 11, 12, 13, 14], [0, 2, 3, 7, 9, 10, 12, 15, 16], [0, 3, 4], [1, 4, 5, 7], [1, 2, 9, 12, 16, 18, 19, 20, 21, 22], [1, 4, 7, 9, 10], [0, 4, 6, 10, 11, 12, 15, 16, 18, 19, 23, 24], [1, 2, 6, 10, 13, 14, 18, 21, 22, 23], [2, 6, 7, 8], [1, 2, 6, 8, 10, 11, 12, 13, 14], [3, 4, 5, 7], [0, 5, 6, 9, 10], [0, 4, 5, 6, 9, 10, 14], [2, 3, 5, 8, 9, 12, 14, 17, 20, 22], [1, 4, 6, 8, 9, 10, 11, 12], [1, 4, 5], [0, 3, 4, 5, 9], [0, 2, 3, 5, 6, 14, 16], [1, 4, 7, 9, 10, 11], [0, 1, 9, 10, 11, 12, 13, 17, 19, 20], [1, 2, 7, 8], [0, 5, 7, 8, 12, 15, 16, 17], [1, 5, 9, 10, 13, 14, 16], [0, 2, 5, 10, 11, 13], [0, 1, 2, 3, 4, 6, 8, 11], [3, 4, 6, 7, 8, 12, 14, 15, 17, 21], [1, 4, 5, 6, 8, 13], [0, 1, 4, 7, 8, 14, 15, 18, 19, 21], [0, 5, 6, 8], [3, 4, 6], [0, 3, 5, 9, 12, 13, 15, 18, 20, 22, 24], [0, 2, 3, 8], [3, 5, 6, 8], [0, 4, 5, 8, 10, 12, 16, 19, 20], [3, 5, 6], [2, 3, 5, 6, 7, 13, 14], [0, 1, 2, 5, 7], [2, 3, 9, 10, 11, 12, 13, 17], [0, 3, 5], [0, 1, 2, 3, 4, 15, 16, 17], [2, 3, 5, 9], [0, 1, 2], [3, 5, 6], [0, 5, 9, 10, 11, 13], [0, 1, 3, 4, 5, 11], [0, 1, 3, 6, 7, 11], [1, 3, 4, 6, 15, 16, 17, 22, 23, 26, 27, 28], [1, 3, 6, 10, 11, 12, 17, 18, 19, 20, 23, 25], [0, 3, 5, 9, 10, 11, 13, 15, 16, 18, 23], [0, 3, 5, 9, 10, 11, 13, 15, 16, 18, 23], [3, 6, 8, 9, 13, 14], [1, 2, 4, 5], [0, 6, 7, 9], [0, 3, 4, 9, 10, 11], [3, 4, 5, 6, 10], [1, 3, 4, 10, 11, 14, 16], [0, 5, 8, 9, 12, 14], [5, 6, 7, 9, 11, 12], [2, 3, 4], [2, 5, 6, 8, 11, 12, 14, 17], [0, 3, 4, 9, 12, 13], [0, 1, 2, 8], [0, 1, 2, 5, 8, 11, 12, 13, 17, 20], [3, 4, 5, 7, 8, 11, 12], [1, 4, 6, 8, 9, 10, 11], [1, 4, 6, 9, 11], [4, 5, 8, 9, 10, 14, 18, 19, 20], [1, 4, 5, 7, 9, 10, 14], [2, 3, 5, 6, 7, 10, 15, 17, 19], [0, 2, 8, 11, 12, 13], [0, 2, 4], [1, 3, 6, 7], [3, 4, 5, 8, 11], [0, 2, 3, 6, 13, 14], [1, 2, 3, 9, 12, 13, 16, 18, 19, 20], [0, 2, 3, 6, 13, 16, 19, 20, 22, 23, 25], [3, 4, 10, 11, 12, 14, 15], [0, 4, 7, 8, 9, 17, 18, 19, 22, 23, 25, 29, 33, 35], [3, 5, 7, 9, 12, 15, 16], [0, 1, 4, 6, 10, 11, 12, 18], [1, 3, 6, 9, 10], [1, 2, 5, 7], [0, 4, 5, 7, 9, 12], [3, 5, 7, 9, 11, 13, 16, 18, 22, 26, 27], [0, 2, 5, 6, 7, 9, 10, 13, 20], [1, 3, 7, 8, 11, 12, 16, 19, 20, 29, 30, 31, 32, 33, 35, 37, 39], [2, 3, 4, 6, 11], [1, 5, 6], [0, 3, 6, 8], [1, 2, 3, 8, 10, 11, 14, 15, 17], [1, 5, 6, 7, 9, 11, 12, 13, 15], [0, 1, 3, 8, 9, 11], [3, 6, 7, 10, 11], [3, 5, 6, 7, 9], [2, 3, 5, 7, 10, 12, 13, 18, 20, 21, 22, 23, 24, 26, 35], [0, 2, 10, 12, 15, 17, 20, 21, 22, 23], [1, 4, 5], [0, 1, 3, 7], [2, 3, 6, 9, 10, 12, 14, 15, 17, 20], [1, 5, 6, 7, 8, 11, 12, 16, 20, 21], [2, 3, 4, 5, 7, 11, 14], [0, 3, 4, 5, 6], [0, 1, 2, 4, 5, 10, 13, 14, 17, 18, 20, 21, 23, 25, 27, 30, 31, 32, 38, 42], [1, 2, 3, 7, 9, 10, 13], [2, 4, 6, 8, 9], [0, 3, 5, 6, 8, 14], [3, 5, 6], [0, 3, 4, 14, 16, 18, 20, 21, 22, 24], [0, 2, 3, 6], [1, 5, 6, 7, 8], [1, 3, 5, 6, 9, 10, 11, 18, 21, 23], [0, 1, 2, 4, 10], [3, 4, 7, 9, 10, 13], [2, 4, 6, 7, 11, 13, 15, 19, 20, 21, 22, 23, 29], [0, 2, 4, 7, 10, 13], [0, 1, 2, 9, 12, 14, 17, 19, 20, 24, 26], [1, 4, 5, 7], [0, 2, 5, 8, 11, 12], [0, 2, 5, 9, 10, 11, 16, 19, 20, 24, 27, 28, 30], [2, 4, 5, 7], [0, 1, 2, 3, 4, 11, 12], [0, 2, 3, 4, 6, 9, 15, 17, 20, 22], [2, 4, 5, 7], [1, 4, 5, 7], [0, 1, 3, 4, 6, 7], [0, 1, 3, 4, 6, 7], [0, 1, 2, 6, 7], [2, 3, 6, 9, 12, 14, 16, 17, 21, 22, 26, 27], [2, 4, 6, 7], [0, 2, 3], [1, 3, 6, 9], [2, 4, 5, 6, 7, 8, 11, 15], [1, 2, 8, 9, 10], [2, 5, 6, 7], [2, 3, 7, 8, 12, 15, 16], [0, 1, 4, 9, 12, 14, 15, 22, 24, 25, 28, 29, 31], [4, 6, 9, 11, 14, 15, 16, 18, 19, 22], [0, 2, 5, 7, 8], [0, 6, 7, 8], [2, 3, 8, 9, 12, 13], [0, 3, 5, 7, 13, 14, 17, 18], [4, 5, 6, 9, 10, 12, 14, 15], [0, 3, 4, 6, 11, 12], [3, 5, 6, 7, 12, 13, 17, 18], [0, 1, 5, 8, 9], [0, 2, 3, 5, 6, 7, 12, 13, 14, 19], [0, 3, 4], [2, 3, 4, 6], [2, 4, 6, 7, 12, 15, 16], [0, 4, 6, 7], [0, 2, 5, 6, 11, 12, 16, 21, 23, 24, 25], [1, 3, 5, 6, 7, 9, 10, 12, 13, 21, 23], [0, 1, 3, 7, 8, 10, 12], [0, 1, 2, 4, 6, 9, 14], [1, 3, 7, 9, 11, 13], [0, 1, 3, 5, 6, 9], [1, 2, 4, 5, 7, 11, 13, 20, 21, 23], [0, 1, 2, 3, 4, 6, 13, 17, 18, 21], [1, 2, 4, 6, 9, 10, 12, 18, 19], [1, 3, 5, 7, 12, 13, 14], [0, 2, 3, 7, 8, 14, 16], [2, 3, 4, 7, 9, 10, 11, 14, 16], [0, 1, 4], [0, 2, 4, 6], [0, 2, 3, 6], [2, 3, 4, 5, 9], [0, 1, 2, 5, 9, 14, 17, 18], [0, 4, 7, 9, 11], [0, 4, 6, 11, 12, 14], [0, 5, 6, 9, 13, 16, 17, 20, 21, 22], [1, 7, 8, 9, 11, 13, 14, 17, 20, 22, 23, 24], [0, 1, 5, 6, 7], [2, 5, 8, 9], [0, 1, 4, 5, 8, 9], [0, 4, 6, 7, 8, 9, 10, 18], [2, 3, 5, 6, 10, 13, 16, 19, 20, 23, 24, 26, 27, 29], [5, 6, 8, 10, 11, 15, 17, 19, 21, 24, 26], [1, 2, 4, 8, 9, 10, 12], [0, 1, 3, 8, 13, 15, 17, 20, 21, 24, 26], [4, 5, 6, 9, 11, 14, 18, 19, 20, 23, 27, 28, 29], [2, 3, 4, 6, 8, 10, 16, 17, 18, 22, 24, 26, 28], [0, 5, 6, 9, 13, 16, 17, 20, 21, 22], [1, 2, 4, 9, 10, 11], [0, 6, 9, 10, 11, 13, 14], [1, 3, 4], [1, 2, 3, 8, 9, 10, 11], [0, 1, 2], [3, 5, 7, 9, 12, 13, 14, 15], [0, 2, 5, 6, 8], [0, 1, 3, 4, 10, 11, 14, 18], [0, 2, 3, 5, 7, 8, 11, 12, 19, 20, 23], [0, 1, 2, 6], [0, 2, 3], [0, 1, 4, 6, 9, 12, 15, 17], [0, 2, 8, 12, 13, 15, 16, 18, 20, 22], [3, 4, 7, 9, 10, 13, 15, 16, 19, 22, 23], [3, 4, 7, 9, 10, 13, 15, 16, 19, 22, 23], [3, 5, 7, 8, 9, 10, 12, 13, 16, 19, 20, 26], [4, 5, 6, 8, 9, 12, 15, 16], [0, 2, 3, 4, 7, 12], [3, 5, 6, 7, 9, 10, 15], [2, 4, 5, 6, 7, 9], [3, 4, 5, 8, 10], [1, 3, 5, 10, 11, 14, 16, 19, 22, 24], [0, 2, 6, 9, 10, 13, 16, 19], [5, 6, 10, 12, 14, 16, 17, 19, 21, 23, 24], [0, 2, 6, 9], [0, 4, 5, 7, 12, 13, 16, 18, 19, 21, 24], [1, 4, 5, 6, 10], [2, 5, 6, 8, 14, 15, 17, 18], [2, 4, 5, 7, 9], [0, 2, 3, 4, 11, 12], [0, 2, 4, 6, 10, 11], [0, 2, 4, 9, 11, 13], [0, 1, 2, 6, 9, 12, 14], [1, 2, 3, 7, 8, 9, 15], [0, 3, 4, 9, 11, 14, 15, 17], [0, 3, 6, 7], [1, 4, 6, 8], [1, 6, 7, 9, 10, 11], [0, 1, 6, 8, 11], [0, 4, 5, 6, 8, 10, 14, 16, 18, 20, 28, 29], [0, 1, 3, 4, 5, 8], [0, 2, 5], [4, 5, 7, 8], [2, 3, 8, 11, 13, 14, 16, 19, 20, 22], [0, 1, 4, 5, 6, 12, 15, 16], [1, 4, 5, 7, 10], [0, 3, 8, 10, 12, 13], [0, 1, 3, 8], [0, 1, 2, 4, 9, 14, 16], [2, 3, 5, 8, 13, 16, 18, 19, 22, 24, 28, 30, 31, 32, 35], [2, 6, 7, 8, 9, 11, 15, 19], [0, 2, 3, 8, 13, 14, 15, 18], [0, 1, 4, 5, 7, 11, 12, 13], [1, 2, 5, 7, 11, 12, 14, 18, 22, 24, 26, 27], [0, 5, 6, 9], [0, 1, 2, 3, 5, 6, 13], [2, 3, 7, 11, 15, 17, 18, 19, 20, 23, 25, 29, 30, 36, 37, 38, 43, 44, 45, 46, 47, 50], [2, 4, 6, 9], [1, 2, 4, 6, 7, 10, 13], [0, 1, 5, 6, 11, 12], [4, 5, 7, 11, 16, 17, 18, 19, 21, 24, 25, 26], [0, 1, 2, 3, 4, 5, 12, 13, 17], [0, 3, 4, 5, 6, 8, 12, 20, 21, 22, 23], [0, 4, 5, 7, 9, 10, 12, 14], [3, 4, 6, 8, 11, 14, 15, 16], [3, 4, 8, 11, 13, 14, 17, 18], [4, 5, 7, 9], [0, 4, 9, 11, 13, 14, 18, 19], [2, 3, 8, 11, 14, 15, 16, 18, 23, 24], [1, 8, 12, 13, 16, 17, 19, 20, 21], [0, 2, 4, 6, 7, 11, 19, 20, 22, 23], [3, 4, 6, 9, 10, 11], [0, 2, 4, 6, 7, 11, 19, 20, 22, 23], [1, 4, 5, 7], [0, 4, 5, 9, 10], [0, 1, 6, 7], [5, 10, 12, 14, 17, 18, 19, 20, 21, 22], [1, 4, 6, 8], [0, 4, 7, 8], [0, 1, 2, 8], [0, 1, 5, 7, 11, 12, 16, 19, 22, 25, 26], [4, 5, 8, 9, 10, 11, 12, 14], [2, 3, 5, 8, 9, 12, 16, 17, 20, 22], [0, 2, 4, 8, 10], [0, 3, 7, 10, 12, 13, 14, 16], [1, 2, 3, 8, 10, 14, 15], [0, 1, 2, 3, 6, 8, 10, 15, 17, 20, 25], [4, 6, 8, 9], [1, 3, 4, 8, 12, 14, 15, 18, 19, 20, 23, 25], [3, 7, 8, 9, 11, 15, 18, 19, 22, 23, 29, 31, 33, 34], [1, 3, 4, 6, 9, 12, 13, 16, 19, 21, 24, 25, 31], [1, 2, 4, 5, 7, 11, 13, 20, 21, 23], [4, 10, 11, 13, 14, 15, 16, 17, 20], [3, 4, 5, 8, 10], [0, 3, 4, 6, 8, 12, 16, 19, 20, 21], [0, 2, 6, 8, 9], [0, 2, 5, 7, 12, 14], [0, 2, 3, 8, 9, 12], [2, 3, 4, 6, 7, 8, 9, 13, 16], [0, 2, 5, 8, 12, 13, 15, 16, 17, 23, 27, 29, 30], [1, 2, 3, 6, 8, 9, 12, 14, 18], [4, 5, 6, 9, 11, 14, 18, 19, 20, 23, 27, 28, 29], [2, 3, 5, 6, 9, 11], [0, 1, 4, 8], [2, 6, 8, 9], [2, 3, 8, 10, 12, 13], [3, 4, 6, 8, 9, 12], [2, 4, 5, 6], [6, 7, 8, 9, 10, 13, 14, 18, 19, 21], [0, 2, 5, 6, 10, 12, 15], [3, 4, 7, 8, 9, 12, 14], [1, 2, 3, 8, 9, 10, 15, 16], [2, 3, 6, 12, 13, 14], [0, 2, 5, 6], [2, 6, 8, 9], [1, 2, 3, 5, 12, 13, 15], [0, 2, 7, 8, 9, 10], [0, 1, 2, 5, 9, 13], [3, 4, 7, 8, 9, 12, 14], [2, 5, 7, 8, 10], [1, 2, 4, 6, 7, 11, 14, 16], [1, 2, 3, 5, 12, 13, 15], [2, 4, 5, 9, 10], [0, 1, 2, 5, 9, 13], [1, 3, 4, 6, 7, 10], [2, 4, 6], [0, 4, 5], [1, 2, 5, 7], [3, 4, 5, 6], [0, 4, 5, 7], [5, 7, 9, 11, 13, 14, 15, 18], [0, 4, 5, 7, 9, 10, 16, 23, 24, 25, 28, 29], [3, 5, 6, 8, 9, 10, 15], [5, 7, 11, 13, 16, 17, 20, 21, 22, 24, 25], [0, 1, 2, 3, 8, 9, 10, 16, 21, 22, 23], [1, 2, 7, 8, 10, 12, 15, 17, 18, 20], [0, 1, 5, 7], [3, 5, 7, 8], [1, 4, 6], [1, 3, 5, 6], [0, 4, 6, 8, 10, 13], [3, 5, 6, 8], [1, 3, 5], [0, 7, 8, 10, 11], [2, 3, 5, 8], [4, 5, 6, 7], [0, 1, 2, 5, 11, 13], [3, 6, 7, 8, 11], [1, 2, 3, 6], [0, 1, 2, 6, 7, 8, 12, 13, 21], [1, 4, 5, 7, 9, 11, 12], [0, 1, 2, 5, 6, 8, 14, 16, 17, 20], [1, 2, 5], [1, 3, 4, 5, 9, 10, 17, 20, 21], [2, 5, 8, 9, 11, 15, 20, 21, 23, 24, 26], [2, 5, 8, 9, 11, 15, 20, 21, 23, 24, 26], [1, 2, 5], [2, 4, 6, 7, 8, 14, 16, 18], [0, 5, 8, 13, 14, 15, 17, 20, 21, 22, 24, 27], [3, 6, 8, 9, 10, 11, 14, 17, 18, 20, 23], [0, 1, 2, 8, 11], [1, 2, 5, 7, 8, 10, 13, 16, 20, 22, 23], [3, 4, 5, 7, 8, 10, 14, 16], [4, 7, 8, 10, 11], [4, 7, 8, 10, 11], [0, 1, 2, 5, 11, 12, 15, 16, 18, 21, 22], [2, 4, 6, 9, 10, 12], [0, 1, 3, 6], [4, 5, 6, 7, 9, 12, 15], [1, 2, 3, 6], [1, 2, 3], [1, 2, 3, 8, 14, 15, 16, 17, 18, 23], [1, 4, 7, 8], [0, 3, 4, 5, 6, 10, 12, 15], [1, 4, 6, 16, 17, 20, 21, 24, 25, 27, 28, 29], [1, 4, 6, 16, 17, 20, 21, 24, 25, 27, 28, 29], [8, 10, 13, 15, 16, 21, 22, 24, 28, 30, 32, 37, 38, 41, 42, 43, 45, 48, 49, 55, 58, 60, 61, 63, 65, 66, 67, 70, 71, 75, 76, 78, 80], [0, 2, 4, 9, 10], [1, 5, 9, 11, 13, 15, 16, 17, 19, 21, 26, 28, 30, 35, 36], [1, 3, 4, 5], [1, 2, 9, 13, 14, 15, 16, 18, 19, 23, 25, 28], [0, 4, 5, 10, 11, 13], [3, 7, 9, 10, 11], [2, 3, 6], [0, 1, 4, 7], [1, 2, 4, 7, 8, 10, 12, 18], [0, 3, 5], [3, 4, 5, 6, 7, 12, 13, 15, 20], [3, 7, 8, 11, 13, 14], [0, 2, 3, 7], [0, 1, 2], [1, 4, 5], [2, 4, 7, 8, 11, 12], [1, 4, 6], [2, 3, 6, 12, 13, 14], [0, 2, 4, 7, 11, 12], [1, 2, 5, 6, 9, 14]], [[2, 10, 12, 13, 14, 15, 17, 18, 20, 24, 26, 27, 28], [2, 4, 6, 8, 9, 10, 12, 15], [1, 3, 5, 6], [0, 1, 4, 5, 6, 11, 12, 14], [2, 7, 10, 11, 14, 18, 19, 21, 22, 23, 24, 27, 28, 33, 34], [0, 1, 5, 7, 9, 10, 12, 15, 16, 18, 22, 24], [0, 2, 4, 5, 10, 11], [0, 1, 2, 4, 5, 11], [3, 5, 9, 10, 11, 19, 24, 25, 28, 37, 39, 40, 41, 42, 43, 45, 50, 54, 56, 58, 59, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 75, 76, 79, 82, 84, 85, 93], [2, 4, 6, 11, 12, 13, 16, 17, 18, 21], [0, 3, 4, 6, 9, 10, 12, 13, 17, 18, 20, 25], [0, 3, 5, 7, 8], [3, 5, 9, 11, 14, 17, 19, 20, 21, 22], [0, 1, 3, 6, 9, 10], [1, 4, 5, 8, 10, 14], [0, 1, 2, 6, 8, 12, 14, 20, 21, 22, 24, 28, 31, 33, 35], [1, 5, 8, 9, 10, 11, 16, 17, 18, 21], [1, 2, 4, 7, 11, 13, 15, 16], [0, 5, 8, 9, 11, 17, 18, 19], [4, 6, 9, 12, 13, 14, 16, 17, 20, 21], [1, 3, 7, 10, 14, 15, 16], [2, 5, 6, 7, 9, 12], [0, 2, 6, 7, 9, 12, 19, 20, 21], [0, 3, 4, 8, 10, 13], [4, 5, 7, 8], [0, 12, 13, 14, 15, 16, 17, 19], [2, 3, 4, 5, 7, 8, 9, 14, 18, 19], [2, 3, 5, 9, 10, 14, 16, 17, 18], [4, 5, 9, 11, 12, 14], [0, 3, 5, 6, 9, 11], [4, 5, 8, 9, 14, 18, 20, 21, 23, 24, 25, 28, 29, 31, 33, 37, 38, 40, 41], [1, 2, 5, 6, 8, 9, 10, 13, 21, 22, 27, 28, 30], [3, 5, 6, 9, 11, 12, 15], [0, 7, 9, 10, 12, 13, 16, 18, 19, 23], [3, 4, 8, 9, 11, 12, 13, 19], [1, 3, 5, 6], [2, 3, 4, 8, 9], [1, 4, 6, 7, 10, 11, 12, 17], [2, 3, 7, 10, 11], [1, 5, 6, 7, 10, 11, 14, 17, 22, 23, 25], [0, 4, 5, 8, 9, 13, 14, 17, 19], [0, 4, 8, 9, 11], [0, 1, 6, 9, 11, 12], [3, 4, 5, 7, 8, 12], [0, 2, 4, 6, 11, 13], [5, 6, 8, 9, 12, 15, 16, 17], [2, 3, 4, 7, 10, 11, 14], [4, 6, 7, 9, 11, 12], [1, 5, 6, 7, 9, 14, 19, 20, 21], [1, 2, 4, 6, 8, 10, 15, 16], [2, 3, 6, 9, 10, 12, 15], [2, 5, 8, 9, 11, 14, 16, 17, 20], [2, 3, 4, 7, 8, 9, 15, 16], [1, 2, 5, 9, 11, 12], [0, 1, 2, 5, 10], [1, 7, 11, 12, 13, 14, 15, 17, 18], [0, 3, 6, 8, 10], [0, 1, 2, 3, 8, 10, 17, 18], [1, 2, 3, 5, 6, 7, 9, 14, 20, 23, 24, 27, 30], [0, 2, 4, 5, 10, 11], [3, 4, 6, 8, 11, 14, 16, 18], [0, 1, 4, 7, 8, 9, 14, 19], [0, 1, 4, 5, 6, 11, 12, 14], [0, 3, 4, 5, 8, 9, 11, 15, 16, 21, 23, 27], [1, 2, 3, 6, 9, 12], [2, 4, 5, 6, 10, 11, 12, 16, 20, 22, 25], [0, 5, 10, 12, 14, 15, 16, 18, 22, 25, 26, 28, 30], [0, 2, 6, 8, 13, 15, 17, 18], [2, 3, 7, 12, 13, 15, 17, 18, 20, 21, 24, 27], [0, 2, 3, 6, 8, 10], [0, 2, 4, 5, 8, 9, 12, 13, 16, 24, 25, 29], [2, 3, 4, 9, 11, 15, 17, 21, 22, 25, 26, 28, 30, 31, 33, 38, 39], [0, 2, 4, 8, 9, 12, 13, 15, 16, 17, 18], [1, 3, 4, 8, 9, 10, 13, 14, 21, 22], [2, 5, 6, 7, 8, 13], [2, 8, 9, 10, 11, 13, 16, 17], [2, 3, 6, 7, 12, 15, 18, 22, 23, 24, 25], [0, 5, 9, 10, 12, 14, 15], [3, 4, 9, 11, 13, 15, 16, 17], [0, 2, 5, 8, 9, 12], [1, 8, 9, 11, 15, 16, 17, 18], [1, 4, 8, 11, 14, 16, 18, 19, 21, 23], [0, 5, 10, 12, 13, 14, 17, 19, 20], [1, 2, 5, 8, 9, 10, 14, 16, 21, 23], [1, 2, 6, 8, 12, 14, 15, 19], [0, 6, 8, 10, 13, 16, 18, 19], [5, 6, 8, 9, 10, 13, 16, 19, 22, 24, 25, 27], [0, 2, 10, 12, 13, 15, 18, 19, 21, 23, 25], [0, 1, 3, 4, 6, 7, 12, 14], [2, 3, 8, 10, 11, 17, 18, 19, 21, 24, 26, 27, 30, 32, 33, 36, 37, 42], [0, 2, 7, 9, 10, 11, 14], [1, 3, 7, 8, 9, 14, 15], [2, 4, 6, 9, 10, 14, 16, 20, 21, 22, 24, 26, 31, 33], [3, 8, 9, 12, 16, 17, 21, 22, 23, 24, 27, 29, 31, 35, 38, 42, 43, 44], [0, 3, 6, 7, 9, 11, 13, 15, 17, 18, 19, 23, 27, 30, 33, 35, 36, 42], [3, 5, 8, 9, 11, 13, 15], [7, 9, 11, 12, 13, 14, 15, 19], [1, 2, 4, 6, 8, 9, 16, 18, 19, 21], [0, 3, 4, 7, 11, 12, 13, 14, 17, 18, 22, 28, 29], [2, 7, 9, 12, 13, 15, 16, 18], [1, 2, 3, 4, 6, 7, 14], [1, 3, 5, 7, 8, 10, 11, 13, 14, 16, 19, 23, 26, 35, 36, 39], [0, 2, 4, 6, 7, 11, 12, 19, 21, 23, 25, 27, 30], [0, 3, 4, 5, 8, 13, 16, 17], [1, 2, 6, 9, 10, 14, 15, 16], [1, 7, 9, 15, 16, 20, 22, 26, 30, 33, 34, 36, 37, 38, 39, 41, 42, 44], [0, 1, 9, 10, 13, 14], [2, 4, 11, 12, 13, 15, 16, 17, 23, 26, 27, 29, 30], [0, 7, 9, 11, 12, 13, 14, 16], [0, 1, 4, 10, 11, 12, 14, 19, 20, 21, 22, 23, 26, 27, 28, 30, 32, 38, 42, 43, 48, 49], [0, 1, 6, 9, 12, 13, 14], [0, 7, 9, 10, 11, 12, 15], [1, 2, 4, 5, 8, 11, 14, 17, 18, 19, 20, 23], [3, 4, 5, 6, 7, 10, 12, 14, 17], [1, 6, 12, 13, 14, 15, 16, 17], [0, 2, 6, 7, 10, 12], [0, 1, 3, 4, 7, 14], [1, 2, 3, 6, 8, 10, 12, 15], [0, 2, 3, 4, 5, 9, 12, 15], [1, 3, 4, 6, 7, 13, 16, 17, 20], [0, 2, 4, 6, 9, 10, 15], [0, 2, 6, 10, 11, 14, 16, 17, 18, 21, 22, 25], [0, 1, 4, 5, 11, 14, 15, 17, 19, 24, 26, 27], [4, 5, 7, 8, 11, 12, 14, 15], [0, 2, 4, 8, 10, 11, 12, 14, 16, 22, 26], [1, 2, 4, 6, 12, 13, 14], [0, 1, 2, 3, 4, 6, 9, 16], [3, 5, 7, 8, 10, 12], [0, 2, 3, 4, 7, 8, 9, 15], [0, 1, 3, 5, 6, 8, 14, 16, 19], [1, 2, 4, 5, 9, 11], [4, 5, 7, 9, 12, 14, 16], [1, 2, 3, 7, 8, 10, 11, 12, 20, 23, 24, 27], [0, 5, 6, 7, 10, 12, 14, 16, 21, 24], [0, 1, 4, 5, 8, 11, 14, 16, 17, 21, 22, 25, 29, 31, 32, 34, 38], [1, 4, 5, 7, 12, 14], [7, 8, 10, 11, 13, 14, 15, 17, 19, 20, 22, 23, 25, 29, 31, 32, 33, 34, 45], [1, 2, 4, 5, 9, 10, 11, 12, 14, 16, 21, 24], [0, 2, 4, 8, 10, 13, 18, 20, 21, 24, 26, 28, 30], [3, 5, 9, 10, 13, 16, 17, 18, 19, 22], [0, 3, 4, 6, 11, 14, 15, 18], [0, 1, 3, 11, 13, 14, 17, 18, 21, 22, 25, 26, 28, 32, 33, 39], [0, 1, 4, 5, 9, 12, 15, 16, 18, 23, 25, 26], [0, 1, 2, 5, 7, 10, 12, 17, 18, 20, 24, 25, 27, 30, 32, 36], [2, 4, 5, 6, 7, 12, 13, 14, 15, 19], [1, 2, 8, 10, 11, 12, 14], [0, 3, 7, 8, 12, 15, 17, 18], [0, 2, 3, 6, 10, 14], [1, 3, 4, 5, 9, 11], [3, 6, 7, 8, 10, 13], [2, 4, 5, 7, 10, 14, 16, 19, 22, 24, 25, 29], [1, 2, 6, 8, 12, 13, 16, 17], [0, 2, 3, 6, 10, 13, 14, 17, 18, 21, 23, 24], [1, 4, 5, 11, 13, 16, 17, 18, 19, 20, 22, 23, 26, 28, 31, 36, 38, 39, 44, 46, 47], [1, 3, 4, 6, 11, 13, 15, 17, 18, 20, 24, 25, 28, 33], [2, 3, 4, 5, 9, 10, 12, 13, 14, 17, 18, 19, 21, 24], [0, 3, 5, 6, 9, 12, 16, 17, 18, 22], [1, 2, 8, 10, 11, 12, 14], [0, 3, 7, 8, 12, 15, 17, 18], [1, 5, 6, 12, 13, 14], [3, 4, 7, 8, 10, 12, 14, 16, 17, 24, 28, 30, 32, 34, 35, 40, 42], [1, 3, 4, 5, 9, 11], [2, 6, 9, 11, 12, 13, 14, 16, 23, 24, 25, 26], [0, 7, 10, 13, 17, 19, 20, 21, 22, 24, 26, 31, 32, 33], [1, 3, 5, 6, 7, 9, 13], [1, 3, 5, 6, 7, 9, 13], [0, 6, 8, 10, 15, 16, 18, 19], [0, 2, 8, 12, 13, 14, 17, 19, 21, 24, 25, 28], [0, 3, 5, 9, 12, 13], [4, 5, 8, 10, 11, 12, 15, 18], [1, 2, 4, 6, 12, 13, 14], [0, 1, 2, 3, 4, 6, 9, 16], [1, 5, 6, 8, 9, 12, 13, 16, 18, 25, 31, 34, 35, 37, 38, 39], [1, 8, 13, 18, 20, 23, 25, 27, 29, 32, 33, 35, 38, 39, 40, 42, 45, 46, 47], [0, 2, 3, 4, 7, 8, 9, 15], [4, 5, 7, 9, 12, 14, 16], [2, 3, 5, 6, 10, 11, 12, 15], [0, 1, 3, 5, 6, 8, 14, 16, 19], [1, 2, 4, 5, 9, 11], [1, 2, 3, 7, 8, 10, 11, 12, 20, 23, 24, 27], [2, 6, 7, 9, 10], [0, 1, 3, 5, 6, 7, 11], [0, 2, 3, 5, 7, 10, 11, 12], [0, 5, 8, 9, 10, 12, 17, 24, 25, 26, 29, 30, 31, 32], [0, 2, 3, 6, 10, 13, 14, 17, 18, 21, 23, 24], [1, 2, 7, 11, 13, 15, 16, 17], [1, 2, 9, 11, 13, 14, 16, 21, 22, 24, 25], [0, 1, 3, 4, 8, 11, 12, 13, 14, 15, 24, 27, 28, 31, 36, 37, 39, 41, 42, 43, 45, 46, 51, 57, 63, 64, 66, 71, 73, 74], [0, 6, 7, 13, 14, 15, 16, 17, 21, 23], [2, 3, 4, 7, 12, 14], [2, 6, 9, 11, 14, 15, 16, 18, 19, 24], [5, 7, 9, 11, 13, 14, 15, 16], [0, 1, 5, 7, 9, 11, 16, 19, 20, 21, 26, 27], [1, 2, 3, 6, 10, 11], [0, 1, 2, 5, 6, 11, 12, 13, 16, 23], [1, 3, 5, 7, 9, 10, 16, 19, 20], [0, 2, 5, 7, 10, 11, 13], [0, 4, 8, 9, 13, 19, 20, 21, 22, 23, 29, 32, 33, 34, 35], [3, 5, 8, 9, 10, 12, 13, 15, 23, 24, 25, 27, 30, 31, 32, 38, 40, 41, 42], [2, 3, 5, 8, 9, 10], [2, 3, 5, 6, 11, 16, 17, 19, 20], [4, 5, 8, 12, 13, 15, 17, 18, 19, 21], [0, 10, 11, 13, 14, 17, 18, 19, 20, 22], [3, 5, 8, 9, 10, 11, 14], [1, 2, 3, 4, 7, 14, 16, 17], [0, 1, 3, 5, 6, 7, 9, 12, 16, 18, 23, 24], [0, 4, 5, 6, 7], [1, 3, 4, 5, 9, 12, 16, 18, 19, 22, 26], [4, 5, 7, 9, 11], [3, 4, 6, 9, 12, 15, 17, 18, 20, 22], [0, 1, 2, 5, 6, 9, 13, 15, 16], [0, 2, 4, 7, 10, 14, 17, 20, 21, 26, 27, 29, 30], [0, 2, 5, 6, 11, 14, 17, 18, 19, 22, 23], [0, 1, 5, 6, 7, 8, 10, 15], [0, 6, 8, 10, 15, 16, 18, 19], [0, 2, 6, 16, 19, 21, 22, 23, 24, 25, 27, 28, 29], [0, 3, 4, 9, 10, 12, 13, 17], [2, 4, 10, 12, 15, 16, 17, 19, 21, 23], [0, 1, 4, 5, 7, 10, 14], [1, 2, 5, 8, 14, 16, 18, 19, 20], [0, 2, 3, 5, 6, 8, 10], [2, 3, 4, 5, 10, 15, 17, 18, 21, 22, 25, 27, 29, 31], [1, 5, 6, 7, 8, 14, 16, 17, 20], [0, 1, 4, 5, 7, 10, 14], [0, 2, 5, 8, 11, 15, 18, 21, 22, 27, 28, 29, 30], [0, 1, 2, 5, 6, 9, 13, 15, 16], [1, 3, 4, 6, 8, 11], [1, 2, 5, 6, 7, 9, 12, 13, 18, 19, 21, 28], [0, 2, 3, 10, 12, 15, 17, 20, 21, 22, 23, 25, 29, 31, 35], [2, 4, 6, 9, 10, 15, 16, 17], [3, 6, 8, 11, 12, 14, 15, 16, 19], [3, 5, 6, 9, 10, 12, 15], [0, 3, 5, 9, 12, 13], [1, 6, 12, 14, 16, 17, 18, 20, 23, 25, 27, 29], [2, 7, 8, 9, 10, 11, 12, 16, 17, 18, 25, 26, 28, 32], [7, 8, 10, 11, 12, 13, 15, 17], [0, 1, 2, 8, 10], [1, 5, 6, 8], [0, 1, 4, 5, 9], [0, 3, 4, 7, 11, 14, 16, 17, 20, 24, 26, 29, 31, 33], [3, 4, 6, 9], [0, 3, 5, 8, 9], [1, 4, 5, 6, 10, 11, 14, 15], [1, 3, 6, 9, 11, 12, 13, 14, 17, 18, 19, 22, 26], [1, 4, 5, 6, 10, 12, 13, 16, 17, 19, 25, 27], [2, 5, 7, 8, 12, 14, 16, 17], [0, 1, 3, 7, 11, 12], [1, 2, 3, 6, 10], [0, 1, 2, 4, 10, 11], [0, 5, 6, 11, 12, 15, 16, 17], [0, 3, 5, 9, 11, 15, 18, 19], [0, 1, 2, 4, 5, 11], [0, 1, 6, 7, 10, 12], [4, 5, 6, 8, 9, 12], [0, 2, 5, 9, 12, 13], [0, 3, 5, 9, 13, 17, 19, 20, 21, 22, 25, 26], [1, 2, 5, 6, 9, 11], [0, 1, 4, 6, 11], [0, 1, 4, 9, 10, 11, 14], [1, 3, 5, 8, 12, 13, 14, 15, 19], [1, 2, 5, 6, 7, 8, 12, 13, 16, 22], [0, 2, 5, 8], [0, 2, 5, 12, 15, 16, 17, 18], [3, 4, 7, 8, 10, 14, 17, 18, 21, 22, 25, 27, 29], [0, 2, 3, 5, 6, 11, 13, 15], [0, 3, 5, 7, 9, 11, 13], [2, 7, 10, 11, 14, 15, 16, 17, 19, 23, 25, 27, 28, 30, 35], [0, 1, 2, 7, 10, 11, 17, 19, 20, 21, 28, 29, 30], [3, 4, 9, 12, 13, 16, 18, 19, 20], [1, 7, 9, 10, 14, 15, 18, 19, 20, 21, 23, 30, 31, 34], [0, 1, 3, 7, 11, 12], [1, 2, 4, 7, 12, 13], [0, 3, 4, 8, 10, 13, 15, 16], [2, 6, 13, 15, 16, 17, 18, 19, 20], [1, 3, 8, 14, 16, 17, 18, 20, 21, 23], [3, 4, 9, 11, 17, 18, 19, 20, 23, 24, 26], [0, 1, 3, 4, 8, 9, 10, 13, 14, 18, 20, 26], [0, 1, 6, 7, 13, 17, 20, 21, 22, 23], [0, 2, 4, 5, 7, 11, 13], [3, 4, 6, 7, 10, 13, 14, 19, 21, 23, 26, 27], [0, 4, 10, 15, 16, 20, 21, 22, 24, 25, 26, 27, 28, 29, 35], [4, 5, 9, 12, 13, 14, 16, 17, 18, 19, 21, 23], [1, 2, 3, 5, 9, 11, 19, 21, 22, 23, 28, 29], [1, 5, 6, 7], [0, 1, 8, 9, 11, 13, 14, 16, 18, 21, 24, 26], [3, 7, 11, 12, 13, 14, 16, 20, 23, 24, 26, 28, 29, 33, 36, 37], [1, 2, 3, 4, 5, 14, 16], [0, 2, 9, 11, 16, 17, 21, 24, 25, 28, 29, 30, 32, 33, 34], [1, 2, 4, 6, 8, 9, 16, 18, 19, 21], [0, 2, 6, 7, 10, 12], [2, 6, 9, 11, 12, 13, 14, 16, 23, 24, 25, 26], [2, 3, 5, 6, 10, 11, 12, 15], [2, 3, 4, 5, 9, 10, 12, 13, 14, 17, 18, 19, 21, 24], [1, 3, 4, 6, 11, 13, 15, 17, 18, 19, 24, 25, 28, 33], [1, 2, 5, 6, 7, 9, 12, 13, 18, 19, 21, 28], [0, 1, 5, 7, 9, 11, 16, 19, 20, 21, 26, 27], [1, 3, 5, 8, 12, 13, 14, 15, 19], [0, 2, 5, 12, 15, 16, 17, 18], [1, 7, 9, 10, 14, 15, 18, 19, 20, 21, 23, 30, 31, 34], [4, 6, 8, 10, 12, 15, 18, 19, 21, 26, 27, 28, 34, 35, 36, 37, 39, 40], [1, 3, 6, 8, 9, 10, 14, 15, 18, 19, 23, 27, 32, 33, 36, 38, 44, 48, 49, 51, 53, 54, 59, 60, 61], [0, 2, 4, 5, 7, 11, 13], [2, 5, 6, 7, 8, 13], [0, 1, 8, 9, 11, 13, 14, 16, 18, 21, 24, 26], [1, 2, 3, 7, 8, 10, 13, 17, 20, 21], [1, 2, 5, 7, 9, 14, 17, 18, 19, 21, 22, 25, 33, 35, 36], [2, 3, 5, 6, 8, 9, 12, 13, 16, 18, 21, 25], [0, 5, 10, 12, 13, 14, 17, 19, 20], [5, 6, 7, 8, 11, 14, 15, 18, 23, 27, 30, 31, 35, 37, 40, 42, 43, 44], [0, 1, 3, 4, 6, 7, 12, 14], [0, 3, 6, 7, 9, 11, 13, 15, 17, 18, 19, 23, 27, 30, 33, 35, 37, 43], [2, 3, 8, 10, 11, 17, 18, 19, 21, 24, 26, 27, 30, 32, 33, 36, 37, 42], [3, 8, 9, 12, 16, 17, 21, 22, 23, 24, 27, 29, 31, 35, 38, 42, 43, 44], [0, 1, 2, 5, 10], [2, 3, 4, 5, 7, 8, 9, 14, 18, 19], [0, 1, 4, 5, 9, 11, 12, 14, 16, 19, 21, 24], [4, 5, 7, 8], [0, 1, 4, 7, 8, 9, 14, 19], [1, 8, 9, 10, 11, 13, 16, 17, 19, 22, 29, 30, 31], [0, 2, 3, 4, 5, 10, 16, 17, 21], [3, 4, 6, 8, 11, 14, 16, 18], [1, 2, 3, 5, 6, 7, 9, 14, 20, 23, 24, 27, 30], [2, 3, 6, 9, 10, 12, 15], [3, 4, 5, 7, 8, 12], [3, 6, 8, 11, 13, 14, 15, 16, 17, 19, 20, 29, 30], [0, 1, 2, 7, 9, 10], [2, 3, 4, 7, 10, 11, 14], [1, 3, 7, 10, 14, 15, 16], [0, 5, 9, 10, 12, 17, 18, 19], [0, 1, 3, 6, 9, 10], [0, 3, 5, 7, 8], [1, 5, 6, 7, 10, 11, 14, 17, 22, 23, 25], [2, 3, 4, 8, 9], [2, 3, 7, 10, 11], [0, 1, 2, 5, 6, 8, 9, 10, 21, 22, 26, 27, 29], [2, 3, 7, 8, 9, 10, 16, 17, 20, 26, 27, 29, 31, 33], [0, 1, 2, 8, 10, 11, 12, 17, 21, 24, 25, 28], [0, 3, 4, 5, 8, 9, 11, 16, 17, 21, 23, 27], [0, 4, 8, 9, 11], [1, 5, 6, 7, 11, 14, 19, 20, 21], [0, 2, 3, 5, 7, 12], [4, 6, 7, 10, 12, 13], [2, 3, 4, 5, 6, 13, 14], [0, 1, 4, 8, 9], [3, 5, 8, 9, 11, 12], [3, 4, 9, 12, 13, 14], [2, 7, 8, 9, 10, 12, 13, 14, 17, 21, 23, 24], [0, 5, 8, 10, 11, 14, 15], [0, 5, 7, 9, 10, 12, 17, 19, 20, 23, 24, 25, 30, 33, 35, 37], [1, 3, 9, 10, 11, 12, 16, 17, 18, 22], [3, 5, 8, 9, 11, 12, 13, 17], [5, 6, 7, 10, 11, 13], [5, 6, 9, 11, 12, 14, 15, 19, 21, 22], [0, 2, 3, 4, 5, 9, 11, 14, 15, 17, 22, 26, 30, 34, 36, 38, 42, 44], [0, 4, 8, 9, 10, 12, 15, 17], [0, 1, 2, 6, 13, 14, 17, 18, 23, 24, 26], [2, 4, 8, 9, 10, 11, 13, 21, 22, 23], [0, 1, 4, 7, 10, 11, 12, 17, 18, 21, 25, 26, 28, 31, 33, 35, 36], [0, 1, 5, 6, 9, 10, 12, 14, 20], [3, 4, 5, 6, 8, 9, 10, 12, 22, 24, 25, 27, 28, 30, 33, 36], [1, 2, 3, 4, 6, 9, 12, 13, 15, 16, 18], [2, 3, 6, 8, 10, 11, 15, 16], [0, 1, 2, 6, 7, 9, 12, 15, 20], [2, 3, 5, 6, 7, 11, 13, 16, 18, 20, 21, 22, 29, 31, 32, 37, 42, 43, 45, 47, 48, 50, 54, 57], [1, 2, 5, 9, 11, 14, 15, 17], [1, 4, 7, 8, 12, 13, 16, 19, 23, 24, 27, 32, 33, 35, 38, 40, 41, 42, 45], [6, 8, 10, 12, 14, 16, 18, 19, 20, 22], [0, 1, 4, 8, 9, 10, 16, 17], [0, 3, 9, 10, 11, 12, 14, 17], [1, 3, 4, 6, 11, 12, 13, 14, 17, 18, 20], [0, 3, 10, 11, 13, 16, 18, 19, 20, 21, 24, 27, 29], [1, 2, 3, 4, 5, 14, 16], [3, 4, 9, 11, 13, 15, 16, 17], [3, 5, 7, 8, 10, 12], [0, 3, 7, 11, 12, 14, 15, 18, 21], [0, 4, 5, 8, 9, 13, 14, 17, 19], [3, 5, 8, 9, 11, 13, 15], [0, 2, 3, 8, 13, 17, 20, 22, 23, 24, 25], [0, 5, 7, 11, 13, 14, 15, 17, 19, 25, 31, 32, 33, 35, 39, 40, 43, 48, 50, 51, 52, 53, 55, 58, 61, 67, 69, 70, 72, 73, 76, 78, 80, 82, 84, 85, 86, 89, 90, 97, 99, 101, 104, 107, 111], [1, 4, 5, 6, 9, 12], [2, 4, 5, 6, 10, 11, 12, 16, 20, 22, 25], [0, 5, 10, 12, 14, 15, 16, 18, 22, 25, 26, 28, 30], [5, 8, 10, 12, 13, 14, 17, 20, 22, 23, 25, 28, 29, 30, 31, 36, 37], [7, 8, 10, 12, 15, 17, 18, 21, 22, 23, 24, 27], [0, 1, 2, 3, 5, 7], [8, 9, 11, 16, 17, 21, 23, 24, 25, 26, 28, 31, 32, 34, 37, 38], [1, 2, 3, 6, 8, 10, 12, 15], [0, 2, 4, 6, 7, 11, 12, 19, 21, 23, 25, 27, 30], [1, 7, 13, 15, 17, 18, 19, 21, 23, 25, 27, 29], [2, 3, 6, 8, 11, 12], [3, 7, 11, 12, 13, 15, 19, 22, 23, 25, 27, 28, 32, 35, 36, 38], [3, 6, 7, 8, 10, 13], [1, 8, 9, 11, 15, 16, 17, 18], [0, 1, 2, 5, 7, 9, 10, 14, 15, 18, 22, 24, 26, 29, 31, 38, 39], [2, 4, 5, 9, 10, 12, 14, 15, 16, 17, 20, 21, 23, 24, 27, 35, 40], [1, 2, 4, 6, 12, 13, 24, 27, 28, 30, 34, 35, 36, 39, 40, 42, 43, 44, 45, 47, 48], [2, 3, 5, 6, 7, 8, 9, 15], [1, 3, 4, 6, 8, 11], [4, 7, 8, 11, 12, 13, 15, 16, 18, 19, 20, 22, 24, 26, 30, 36, 37, 43], [9, 10, 11, 12, 13, 14, 15], [0, 4, 6, 8, 9, 11, 14, 17, 19, 20, 25, 27, 28, 32, 33, 35, 36, 37, 40, 42, 47, 48, 49, 50, 54, 60, 62, 63, 66, 72, 74, 76, 77, 78, 79, 80, 81, 83, 86, 87, 89, 90, 97, 99, 105, 108, 110, 111, 112, 122, 125, 128, 130, 132, 134, 135, 138, 141, 144, 146]]]\n",
      "[(1, 247), (1, 267), (1, 351), (3, 110), (3, 138)]\n"
     ]
    }
   ],
   "source": [
    "#categorized_summary_sentence_indices, faulty_documents = get_summary_sentence_indices(categorized_articles, categorized_summaries)\n",
    "categorized_summary_sentence_indices, faulty_summary_ids = get_summary_sentence_indices(categorized_articles, categorized_summaries)\n",
    "print(categorized_summary_sentence_indices)\n",
    "print(faulty_summary_ids)\n",
    "#print(len(faulty_documents)/len(flatten(categorized_summary_sentence_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_entries(categorized_list: list, faulty_summary_ids: list): \n",
    "    for category_id, sent_id in faulty_summary_ids:\n",
    "        del categorized_list[category_id][sent_id] \n",
    "    return categorized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386\n",
      "383\n",
      "386\n",
      "383\n"
     ]
    }
   ],
   "source": [
    "print(len(categorized_articles[1]))\n",
    "categorized_articles = remove_entries(categorized_articles, faulty_summary_ids)\n",
    "article_file_paths = remove_entries(article_file_paths, faulty_summary_ids)\n",
    "print(len(categorized_articles[1]))\n",
    "print(len(categorized_summaries[1]))\n",
    "categorized_summaries = remove_entries(categorized_summaries, faulty_summary_ids)\n",
    "summary_file_paths = remove_entries(summary_file_paths, faulty_summary_ids)\n",
    "print(len(categorized_summaries[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary_sentence_indices = flatten(categorized_summary_sentence_indices)\n",
    "with open(\"./testing/reference/categorized_summary_sentence_indices.json\", \"w\") as f: \n",
    "    json.dump(categorized_summary_sentence_indices, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) **Indexing** (preprocessing and indexing options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\marti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "from typing import Union\n",
    "import nltk\n",
    "import numpy as np\n",
    "import torch\n",
    "import sklearn\n",
    "import json\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from collections import Counter, defaultdict\n",
    "from tabulate import tabulate\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from textblob import TextBlob\n",
    "\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten list to get uncategorized collection\n",
    "articles = flatten(categorized_articles)\n",
    "summaries = flatten(categorized_summaries)\n",
    "N = len(articles)\n",
    "N_summaries = len(summaries)\n",
    "#article_file_paths = flatten(article_file_paths)\n",
    "dict_path_to_articleID = {path:i for i, path in enumerate(flatten(article_file_paths))}\n",
    "\n",
    "def map_path_to_articleID(path):\n",
    "    path = os.path.normpath(path)\n",
    "    return dict_path_to_articleID.get(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2220"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2220"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverted Index Structure \n",
    " \n",
    "Each term points to a dictionary of document identifier and the term frequency in the document.\n",
    "\n",
    "t1 -> {doc1: TF, doc5: TF, ...}\\\n",
    "t2 -> {doc7: TF, doc8: TF, ...}\\\n",
    "...\n",
    "t2 -> [DF, {doc7: [TF_(t2, doc7), {s1: TF, s4: TF, ...}], doc8: [TF_(t2, doc8), {s2: TF, s4: TF, ...}], ...}]\\\n",
    "\n",
    "use class structure\n",
    "\n",
    "TODO: \n",
    "* Optimize structure?\n",
    "    * Is there a more efficient way? \n",
    "    * Add maybe pointers to sentences and their term frequency? -> Faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_width = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TermFrequencies: \n",
    "    def __init__(self) -> None:\n",
    "        self.tf_d_t = 0\n",
    "        self.sent_tf = list()\n",
    "\n",
    "    def add_sentence(self, sent_number, term_frequency):\n",
    "        self.sent_tf.append((sent_number, term_frequency))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        padding = 5 - len(str(self.tf_d_t))\n",
    "        return f'TF_d_t: {self.tf_d_t}{\" \" * padding}TF_per_sentence: {self.sent_tf}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndexEntry:\n",
    "    def __init__(self) -> None:\n",
    "        self.df_term = 0\n",
    "        self.term_dict = defaultdict(TermFrequencies)\n",
    "    \n",
    "    def get_document(self, document):\n",
    "        return self.term_dict.get(document, None)\n",
    "\n",
    "    def get_or_default_document(self, document):\n",
    "        return self.term_dict[document]\n",
    "\n",
    "    def update_document(self, document, new_value):\n",
    "        self.term_dict[document] = new_value\n",
    "    \n",
    "    def __repr__(self):\n",
    "        out = f'Document Frequency: {self.df_term}\\n {\" \" * (max_width+2)} Term frequencies:\\n'\n",
    "        for doc_number, tfs in self.term_dict.items():\n",
    "            padding = 5 - len(str(doc_number))\n",
    "            out += f'{\" \" * (max_width + 3)} Doc {doc_number}{\" \" * padding}→ {tfs}\\n'\n",
    "        return out\n",
    "    \n",
    "    def calculate_df(self):\n",
    "        self.df_term = len(self.term_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndex:\n",
    "    def __init__(self, collection_size) -> None:\n",
    "        self.inverted_index = defaultdict(InvertedIndexEntry)\n",
    "        self.sentence_term_counts = list()\n",
    "        self.sentence_num_chars = list()\n",
    "        self.indexing_time = 0\n",
    "        self.N = collection_size\n",
    "    \n",
    "    def __repr__(self):\n",
    "        out = f'Time to index: {self.indexing_time}\\nInverted Index:\\n'\n",
    "        for term, entry in self.inverted_index.items():\n",
    "            padding = max_width - len(term)\n",
    "            out += f'{term} {\" \" * padding} → {entry}\\n'\n",
    "        return out\n",
    "\n",
    "    def get_or_default(self, term, document):\n",
    "        return self.inverted_index[term].get_or_default_document(document)\n",
    "    \n",
    "    def update(self, term, document, new_value):\n",
    "        self.inverted_index[term].update_document(document, new_value)\n",
    "    \n",
    "    def set_indexing_time(self, indexing_time):\n",
    "        self.indexing_time = indexing_time\n",
    "    \n",
    "    def calculate_dfs(self):\n",
    "        for entry in self.inverted_index.values():\n",
    "            entry.calculate_df()  \n",
    "    \n",
    "    def get_sentence_lengths(self, document):\n",
    "        return self.sentence_term_counts[document]\n",
    "\n",
    "    def get_document_info(self, document):          \n",
    "        info = {'Vocabulary': [], 'DF_t': [], 'TF_d_t': [], 'TF/sentence': []}\n",
    "        for term, entry in self.inverted_index.items():\n",
    "            doc_tfs = entry.get_document(document)\n",
    "            if doc_tfs == None:\n",
    "                continue\n",
    "            info['Vocabulary'].append(term)\n",
    "            info['DF_t'].append(entry.df_term)\n",
    "            info['TF_d_t'].append(doc_tfs.tf_d_t)\n",
    "            info['TF/sentence'].append(doc_tfs.sent_tf)\n",
    "        return info\n",
    "    \n",
    "    def doc_to_string(self, document: int):\n",
    "        out = f'Document id={document} → vocabulary and term frequencies:\\n'\n",
    "        info = self.get_document_info(document)\n",
    "        table = zip(*info.values())\n",
    "        headers = info.keys()\n",
    "        return out + tabulate(table, headers, tablefmt=\"pretty\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenize(sentence):\n",
    "    sents = list()\n",
    "    for paragraph in sentence.split('\\n '):\n",
    "        # split into sentences  \n",
    "        sents_p = nltk.sent_tokenize(paragraph)\n",
    "        for sent in sents_p:\n",
    "            sents.append(sent)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@ input a sentence to process, a tokenizer to split it into terms, a lemmatizer to normalize the terms,\n",
    "a set consisting of stop_words to ignore\n",
    "\n",
    "@behavior preprocesses the sentence\n",
    "\n",
    "@output a triple consisting of the length in characters of the sentence, the number of terms in the sentence and\n",
    "a list of terms and noun phrases appearing in the sentence (with repeated terms) \n",
    "'''\n",
    "def preprocess(sentence: str, tokenizer: nltk.tokenize.api.TokenizerI, wnl: WordNetLemmatizer, stop_words=set):\n",
    "    sent_out = list()\n",
    "    tokenized_sentence = tokenizer.tokenize(sentence.lower())\n",
    "    for term in tokenized_sentence:\n",
    "        lem_term = wnl.lemmatize(term)\n",
    "        if lem_term not in stop_words:      \n",
    "            sent_out.append(lem_term)\n",
    "    blobbed_sentence = TextBlob(sentence)\n",
    "    all_noun_phrases = blobbed_sentence.noun_phrases\n",
    "    # only include those that have multiple words\n",
    "    noun_phrases = [n_p for n_p in all_noun_phrases if ' ' in n_p]\n",
    "    sent_out.extend(noun_phrases)\n",
    "    return len(sentence), len(tokenized_sentence), sent_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "indexing(D,args)\n",
    "    @input document collection D and optional arguments on text preprocessing\n",
    "\n",
    "    @behavior preprocesses the collection and, using existing libraries, \n",
    "    builds an inverted index with the relevant statistics for the subsequent summarization functions\n",
    "    \n",
    "    @output pair with the inverted index I and indexing time\n",
    "'''\n",
    "def indexing(articles, **args) -> InvertedIndex:\n",
    "    start_time = time.time()\n",
    "    inverted_index = InvertedIndex(len(articles))\n",
    "\n",
    "    # tokenizer split words and keep hyphens e.g. state-of-the-art\n",
    "    tokenizer = RegexpTokenizer(r'[\\w|-]+')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    wnl = WordNetLemmatizer()\n",
    "\n",
    "    # loop through collection \n",
    "    for article_id, article in enumerate(articles): \n",
    "        sents = sentence_tokenize(article)\n",
    "        # remove title (not needed for summarization task)\n",
    "        #sents = sents[1:]\n",
    "        preprocessing_results = [preprocess(sent, tokenizer, wnl, stop_words) for sent in sents]\n",
    "        sent_num_chars, sent_term_counts, preprocessed_sentences = zip(*preprocessing_results)\n",
    "        inverted_index.sentence_num_chars.append(list(sent_num_chars))\n",
    "        inverted_index.sentence_term_counts.append(list(sent_term_counts))\n",
    "        # count the term frequencies per sentence\n",
    "        term_counter_per_sent = [Counter(sentence_terms) for sentence_terms in preprocessed_sentences]\n",
    "        for sent_number, term_counter in enumerate(term_counter_per_sent):\n",
    "            for term in term_counter: \n",
    "                tf = term_counter[term]\n",
    "                term_document_tfs = inverted_index.get_or_default(term, article_id)\n",
    "                term_document_tfs.tf_d_t += tf \n",
    "                term_document_tfs.add_sentence(sent_number, tf)\n",
    "                inverted_index.update(term, article_id, term_document_tfs)\n",
    "    inverted_index.calculate_dfs()\n",
    "    end_time = time.time()\n",
    "    indexing_time = end_time - start_time\n",
    "    inverted_index.set_indexing_time(indexing_time)\n",
    "    return inverted_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'played'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordNetLemmatizer().lemmatize(\"played\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data scientist',\n",
       " 'machine learning enthusiast',\n",
       " 'john williams',\n",
       " 'data scientist',\n",
       " 'centuries-old oak tree']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_removed = 'Hello, I\\'m a data scientist and machine learning enthusiast. My name is John Williams and am a data scientist. The majestic, centuries-old oak tree stood proudly at the edge of the meadow'\n",
    "blob = TextBlob(sent_removed)\n",
    "[a for a in blob.noun_phrases if ' ' in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = 'Title. The little white little rabbit. The person played with the ball.'\n",
    "s1 = 'Title. The white rabbit\\'s ball. Rabbit rabbit ball rabbit.'\n",
    "s2 = 'Title.  White, the little white rabbit. Little, little.'\n",
    "test = [s0, s1, s2]\n",
    "I_test = indexing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to index: 0.0032629966735839844\n",
      "Inverted Index:\n",
      "title                 → Document Frequency: 3\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "                        Doc 1    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "                        Doc 2    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "\n",
      "little                → Document Frequency: 2\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 2    TF_per_sentence: [(1, 2)]\n",
      "                        Doc 2    → TF_d_t: 3    TF_per_sentence: [(1, 1), (2, 2)]\n",
      "\n",
      "white                 → Document Frequency: 3\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "                        Doc 1    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "                        Doc 2    → TF_d_t: 2    TF_per_sentence: [(1, 2)]\n",
      "\n",
      "rabbit                → Document Frequency: 3\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "                        Doc 1    → TF_d_t: 4    TF_per_sentence: [(1, 1), (2, 3)]\n",
      "                        Doc 2    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "\n",
      "white little rabbit   → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "\n",
      "person                → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(2, 1)]\n",
      "\n",
      "played                → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(2, 1)]\n",
      "\n",
      "ball                  → Document Frequency: 2\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(2, 1)]\n",
      "                        Doc 1    → TF_d_t: 2    TF_per_sentence: [(1, 1), (2, 1)]\n",
      "\n",
      "white rabbit 's ball  → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 1    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "\n",
      "rabbit ball rabbit    → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 1    → TF_d_t: 1    TF_per_sentence: [(2, 1)]\n",
      "\n",
      "white rabbit          → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 2    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(I_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document id=2 → vocabulary and term frequencies:\n",
      "+--------------+------+--------+------------------+\n",
      "|  Vocabulary  | DF_t | TF_d_t |   TF/sentence    |\n",
      "+--------------+------+--------+------------------+\n",
      "|    title     |  3   |   1    |     [(0, 1)]     |\n",
      "|    little    |  2   |   3    | [(1, 1), (2, 2)] |\n",
      "|    white     |  3   |   2    |     [(1, 2)]     |\n",
      "|    rabbit    |  3   |   1    |     [(1, 1)]     |\n",
      "| white rabbit |  1   |   1    |     [(1, 1)]     |\n",
      "+--------------+------+--------+------------------+\n"
     ]
    }
   ],
   "source": [
    "print(I_test.doc_to_string(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = indexing(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23, 23, 13, 20, 13, 10, 18, 21, 28, 24, 12, 37, 24, 25, 20, 20, 20, 24, 31, 21], [28, 24, 19, 12, 36, 37, 24, 10, 26, 33, 14, 40, 22, 42, 24]]\n"
     ]
    }
   ],
   "source": [
    "print(I.sentence_term_counts[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document id=508 → vocabulary and term frequencies:\n",
      "+---------------------------+------+--------+-------------------------------------------------------------+\n",
      "|        Vocabulary         | DF_t | TF_d_t |                         TF/sentence                         |\n",
      "+---------------------------+------+--------+-------------------------------------------------------------+\n",
      "|             u             | 830  |   1    |                          [(12, 1)]                          |\n",
      "|             1             | 463  |   3    |                 [(0, 1), (13, 1), (14, 1)]                  |\n",
      "|           three           | 557  |   1    |                          [(14, 1)]                          |\n",
      "|           month           | 578  |   1    |                          [(14, 1)]                          |\n",
      "|           firm            | 459  |   1    |                          [(2, 1)]                           |\n",
      "|            one            | 1042 |   5    |                  [(2, 1), (9, 1), (11, 3)]                  |\n",
      "|          biggest          | 234  |   2    |                      [(1, 1), (9, 1)]                       |\n",
      "|           said            | 1883 |   2    |                     [(10, 1), (13, 1)]                      |\n",
      "|            11             | 189  |   1    |                          [(8, 1)]                           |\n",
      "|           time            | 879  |   1    |                          [(5, 1)]                           |\n",
      "|         business          | 301  |   4    |              [(3, 1), (4, 1), (8, 1), (11, 1)]              |\n",
      "|            ha             | 1824 |   2    |                      [(9, 1), (11, 1)]                      |\n",
      "|          company          | 534  |   7    | [(0, 1), (5, 1), (6, 1), (9, 1), (10, 1), (11, 1), (13, 1)] |\n",
      "|          service          | 368  |   1    |                          [(10, 1)]                          |\n",
      "|         customer          | 117  |   1    |                          [(10, 1)]                          |\n",
      "|           also            | 1261 |   1    |                          [(10, 1)]                          |\n",
      "|          result           | 277  |   1    |                          [(9, 1)]                           |\n",
      "|         exchange          | 100  |   1    |                          [(13, 1)]                          |\n",
      "|         slightly          |  58  |   1    |                          [(9, 1)]                           |\n",
      "|            wa             | 1746 |   1    |                          [(12, 1)]                          |\n",
      "|           chief           | 353  |   4    |             [(7, 1), (10, 1), (13, 1), (14, 1)]             |\n",
      "|         executive         | 262  |   4    |             [(7, 1), (10, 1), (13, 1), (14, 1)]             |\n",
      "|          growth           | 229  |   1    |                          [(2, 1)]                           |\n",
      "|          around           | 312  |   2    |                      [(0, 1), (7, 1)]                       |\n",
      "|           part            | 459  |   1    |                          [(8, 1)]                           |\n",
      "|          market           | 390  |   1    |                          [(10, 1)]                          |\n",
      "|          already          | 372  |   1    |                          [(8, 1)]                           |\n",
      "|           deal            | 261  |   1    |                          [(7, 1)]                           |\n",
      "|          europe           | 248  |   2    |                      [(2, 1), (6, 1)]                       |\n",
      "|          dollar           | 126  |   1    |                          [(12, 1)]                          |\n",
      "|           euro            | 105  |   1    |                          [(13, 1)]                          |\n",
      "|            new            | 960  |   2    |                      [(6, 1), (13, 1)]                      |\n",
      "|            mr             | 795  |   1    |                          [(13, 1)]                          |\n",
      "|           much            | 450  |   1    |                          [(5, 1)]                           |\n",
      "|           year            | 1318 |   4    |              [(2, 1), (3, 1), (9, 1), (12, 1)]              |\n",
      "|           worry           |  62  |   2    |                      [(1, 1), (9, 1)]                       |\n",
      "|           price           | 233  |   1    |                          [(1, 1)]                           |\n",
      "|          highly           |  47  |   1    |                          [(0, 1)]                           |\n",
      "|          fallen           |  51  |   1    |                          [(9, 1)]                           |\n",
      "|           rate            | 179  |   1    |                          [(13, 1)]                          |\n",
      "|             -             | 1087 |   7    |             [(2, 2), (5, 2), (11, 2), (14, 1)]              |\n",
      "|           move            | 323  |   1    |                          [(10, 1)]                          |\n",
      "|           many            | 526  |   1    |                          [(7, 1)]                           |\n",
      "|           could           | 869  |   1    |                          [(10, 1)]                          |\n",
      "|            oil            | 109  |   1    |                          [(1, 1)]                           |\n",
      "|            say            | 664  |   2    |                      [(4, 1), (8, 1)]                       |\n",
      "|           money           | 276  |   1    |                          [(5, 1)]                           |\n",
      "|           2004            | 390  |   1    |                          [(14, 1)]                          |\n",
      "|           cost            | 286  |   1    |                          [(5, 1)]                           |\n",
      "|           last            | 903  |   2    |                      [(9, 1), (14, 1)]                      |\n",
      "|          decline          |  58  |   1    |                          [(12, 1)]                          |\n",
      "|        competition        | 151  |   2    |                      [(1, 1), (9, 1)]                       |\n",
      "|         low-cost          |  21  |   3    |                  [(1, 1), (7, 1), (9, 1)]                   |\n",
      "|          number           | 546  |   1    |                          [(10, 1)]                          |\n",
      "|          united           | 164  |   1    |                          [(5, 1)]                           |\n",
      "|           state           | 268  |   1    |                          [(5, 1)]                           |\n",
      "|          example          | 111  |   1    |                          [(11, 1)]                          |\n",
      "|           world           | 667  |   3    |                  [(0, 1), (7, 1), (14, 1)]                  |\n",
      "|            uk             | 513  |   1    |                          [(2, 1)]                           |\n",
      "|         suggested         | 102  |   1    |                          [(13, 1)]                          |\n",
      "|          global           | 150  |   4    |                 [(4, 1), (10, 1), (11, 2)]                  |\n",
      "|          leader           | 247  |   2    |                      [(4, 1), (11, 1)]                      |\n",
      "|            buy            | 144  |   1    |                          [(13, 1)]                          |\n",
      "|           home            | 408  |   1    |                          [(10, 1)]                          |\n",
      "|            two            | 810  |   1    |                          [(3, 1)]                           |\n",
      "|         suggests          |  78  |   2    |                      [(0, 1), (12, 1)]                      |\n",
      "|         economic          | 190  |   1    |                          [(0, 1)]                           |\n",
      "|         according         | 332  |   1    |                          [(11, 1)]                          |\n",
      "|        favourable         |  9   |   1    |                          [(13, 1)]                          |\n",
      "|          called           | 260  |   1    |                          [(6, 1)]                           |\n",
      "|           brown           | 126  |   1    |                          [(11, 1)]                          |\n",
      "|          country          | 440  |   2    |                      [(8, 1), (10, 1)]                      |\n",
      "|           large           | 137  |   2    |                      [(0, 1), (11, 1)]                      |\n",
      "|          nearly           |  96  |   1    |                          [(3, 1)]                           |\n",
      "|           trend           |  64  |   1    |                          [(11, 1)]                          |\n",
      "|            30             | 182  |   2    |                      [(3, 1), (13, 1)]                      |\n",
      "|           hurt            |  35  |   1    |                          [(10, 1)]                          |\n",
      "|          region           |  60  |   1    |                          [(11, 1)]                          |\n",
      "|        oil prices         |  31  |   1    |                          [(1, 1)]                           |\n",
      "|          decided          | 114  |   1    |                          [(7, 1)]                           |\n",
      "|           boss            |  20  |   3    |                  [(0, 1), (3, 1), (8, 1)]                   |\n",
      "|            90             |  63  |   1    |                          [(0, 1)]                           |\n",
      "|         currently         | 224  |   1    |                          [(6, 1)]                           |\n",
      "|           moved           |  93  |   1    |                          [(8, 1)]                           |\n",
      "|           plan            | 373  |   1    |                          [(8, 1)]                           |\n",
      "|           seen            | 276  |   1    |                          [(12, 1)]                          |\n",
      "|          another          | 316  |   1    |                          [(8, 1)]                           |\n",
      "|          quality          |  91  |   1    |                          [(10, 1)]                          |\n",
      "|          facing           |  85  |   1    |                          [(4, 1)]                           |\n",
      "|            300            |  43  |   1    |                          [(0, 1)]                           |\n",
      "|           force           | 133  |   1    |                          [(5, 1)]                           |\n",
      "|           risk            | 119  |   1    |                          [(11, 1)]                          |\n",
      "|           rapid           |  29  |   1    |                          [(12, 1)]                          |\n",
      "|         corporate         |  67  |   1    |                          [(5, 1)]                           |\n",
      "|          growing          | 130  |   1    |                          [(10, 1)]                          |\n",
      "|            28             |  64  |   1    |                          [(8, 1)]                           |\n",
      "|          scandal          |  41  |   1    |                          [(5, 1)]                           |\n",
      "|            ago            | 199  |   2    |                      [(3, 1), (12, 1)]                      |\n",
      "|          future           | 270  |   1    |                          [(8, 1)]                           |\n",
      "|          complex          |  40  |   1    |                          [(6, 1)]                           |\n",
      "|         position          | 154  |   1    |                          [(13, 1)]                          |\n",
      "|         standard          | 136  |   1    |                          [(6, 1)]                           |\n",
      "|         us dollar         |  24  |   1    |                          [(12, 1)]                          |\n",
      "|           huge            | 180  |   1    |                          [(12, 1)]                          |\n",
      "|          survey           |  80  |   5    |         [(0, 1), (3, 1), (8, 1), (12, 1), (14, 1)]          |\n",
      "|      survey suggests      |  3   |   1    |                          [(12, 1)]                          |\n",
      "|           even            | 351  |   1    |                          [(12, 1)]                          |\n",
      "|          calling          |  43  |   1    |                          [(9, 1)]                           |\n",
      "|          problem          | 343  |   1    |                          [(12, 1)]                          |\n",
      "|          process          | 120  |   1    |                          [(6, 1)]                           |\n",
      "|         operation         | 102  |   1    |                          [(11, 1)]                          |\n",
      "|          polled           |  5   |   1    |                          [(8, 1)]                           |\n",
      "|         conducted         |  34  |   1    |                          [(3, 1)]                           |\n",
      "|           work            | 449  |   1    |                          [(10, 1)]                          |\n",
      "|          moving           |  67  |   1    |                          [(6, 1)]                           |\n",
      "|           slow            |  57  |   1    |                          [(2, 1)]                           |\n",
      "|         adjusted          |  13  |   1    |                          [(13, 1)]                          |\n",
      "|           clear           | 186  |   1    |                          [(11, 1)]                          |\n",
      "|        competitor         |  30  |   1    |                          [(7, 1)]                           |\n",
      "|         meanwhile         | 127  |   1    |                          [(6, 1)]                           |\n",
      "|          others           | 158  |   1    |                          [(13, 1)]                          |\n",
      "|           harm            |  24  |   1    |                          [(10, 1)]                          |\n",
      "|         prospect          |  52  |   2    |                      [(0, 1), (3, 1)]                       |\n",
      "|        confidence         |  86  |   1    |                          [(2, 1)]                           |\n",
      "|           stock           | 104  |   1    |                          [(6, 1)]                           |\n",
      "|         concerned         | 104  |   1    |                          [(10, 1)]                          |\n",
      "|       third-largest       |  4   |   1    |                          [(12, 1)]                          |\n",
      "|          cheaper          |  37  |   1    |                          [(10, 1)]                          |\n",
      "|      sarbanes-oxley       |  4   |   1    |                          [(5, 1)]                           |\n",
      "|            act            | 151  |   1    |                          [(5, 1)]                           |\n",
      "|           enron           |  10  |   1    |                          [(5, 1)]                           |\n",
      "|         worldcom          |  15  |   1    |                          [(5, 1)]                           |\n",
      "|    corporate scandals     |  2   |   1    |                          [(5, 1)]                           |\n",
      "|          middle           |  65  |   1    |                          [(11, 1)]                          |\n",
      "|     business leaders      |  7   |   1    |                          [(4, 1)]                           |\n",
      "|          provide          | 121  |   1    |                          [(10, 1)]                          |\n",
      "|          across           | 196  |   1    |                          [(6, 1)]                           |\n",
      "|        significant        |  94  |   1    |                          [(9, 1)]                           |\n",
      "|            red            |  72  |   1    |                          [(7, 1)]                           |\n",
      "|          western          |  33  |   1    |                          [(2, 1)]                           |\n",
      "|        optimistic         |  40  |   1    |                          [(0, 1)]                           |\n",
      "|        accounting         |  26  |   1    |                          [(6, 1)]                           |\n",
      "|          locked           |  16  |   1    |                          [(13, 1)]                          |\n",
      "|           east            |  83  |   1    |                          [(11, 1)]                          |\n",
      "|            lot            | 266  |   1    |                          [(5, 1)]                           |\n",
      "|           cited           |  13  |   1    |                          [(12, 1)]                          |\n",
      "|        throughout         |  65  |   1    |                          [(14, 1)]                          |\n",
      "|          threat           |  90  |   4    |                  [(1, 1), (9, 2), (12, 1)]                  |\n",
      "|            ups            |  5   |   1    |                          [(1, 1)]                           |\n",
      "|         paperwork         |  4   |   1    |                          [(5, 1)]                           |\n",
      "|        reputation         |  35  |   1    |                          [(10, 1)]                          |\n",
      "|       successfully        |  21  |   1    |                          [(13, 1)]                          |\n",
      "|          assault          |  19  |   1    |                          [(4, 1)]                           |\n",
      "|          adviser          |  26  |   1    |                          [(3, 1)]                           |\n",
      "|          appear           |  83  |   1    |                          [(7, 1)]                           |\n",
      "|          upside           |  3   |   1    |                          [(11, 1)]                          |\n",
      "|        regulatory         |  17  |   1    |                          [(4, 1)]                           |\n",
      "|         outsource         |  2   |   1    |                          [(10, 1)]                          |\n",
      "|          anymore          |  13  |   2    |                     [(11, 1), (12, 1)]                      |\n",
      "|          reality          |  41  |   1    |                          [(13, 1)]                          |\n",
      "|  pricewaterhousecoopers   |  3   |   2    |                      [(3, 1), (14, 1)]                      |\n",
      "|            pwc            |  2   |   3    |                 [(3, 1), (10, 1), (11, 1)]                  |\n",
      "|          string           |  23  |   1    |                          [(5, 1)]                           |\n",
      "|          wo n't           |  41  |   1    |                          [(11, 1)]                          |\n",
      "|        slow growth        |  2   |   1    |                          [(2, 1)]                           |\n",
      "|           tape            |  18  |   1    |                          [(7, 1)]                           |\n",
      "|         advisory          |  10  |   1    |                          [(11, 1)]                          |\n",
      "|     chief executives      |  4   |   3    |                 [(7, 1), (13, 1), (14, 1)]                  |\n",
      "|        transparent        |  12  |   1    |                          [(5, 1)]                           |\n",
      "|         interview         |  68  |   1    |                          [(13, 1)]                          |\n",
      "|        interviewed        |  19  |   1    |                          [(14, 1)]                          |\n",
      "|          hardly           |  26  |   1    |                          [(7, 1)]                           |\n",
      "|          terror           |  33  |   1    |                          [(1, 1)]                           |\n",
      "|    economic prospects     |  2   |   1    |                          [(0, 1)]                           |\n",
      "|          avoided          |  22  |   1    |                          [(7, 1)]                           |\n",
      "|            54             |  20  |   1    |                          [(9, 1)]                           |\n",
      "|         exception         |  8   |   1    |                          [(2, 1)]                           |\n",
      "|         possibly          |  26  |   1    |                          [(9, 1)]                           |\n",
      "|          gloomy           |  6   |   1    |                          [(3, 1)]                           |\n",
      "|          unlike           |  24  |   1    |                          [(12, 1)]                          |\n",
      "|          samuel           |  9   |   1    |                          [(10, 1)]                          |\n",
      "|           frank           |  38  |   1    |                          [(11, 1)]                          |\n",
      "|       surprisingly        |  8   |   1    |                          [(12, 1)]                          |\n",
      "|      large companies      |  6   |   2    |                      [(0, 1), (11, 1)]                      |\n",
      "|      bosses suggests      |  1   |   1    |                          [(0, 1)]                           |\n",
      "|      over-regulation      |  1   |   1    |                          [(1, 1)]                           |\n",
      "|           wild            |  27  |   1    |                          [(1, 1)]                           |\n",
      "|      terror threats       |  2   |   1    |                          [(1, 1)]                           |\n",
      "|   low-cost competition    |  1   |   2    |                      [(1, 1), (9, 1)]                       |\n",
      "|         wild ups          |  1   |   1    |                          [(1, 1)]                           |\n",
      "|          lacking          |  11  |   1    |                          [(2, 1)]                           |\n",
      "|     business advisers     |  1   |   1    |                          [(3, 1)]                           |\n",
      "|        two-pronged        |  1   |   1    |                          [(4, 1)]                           |\n",
      "|    regulatory assault     |  1   |   1    |                          [(4, 1)]                           |\n",
      "|   act forces companies    |  1   |   1    |                          [(5, 1)]                           |\n",
      "|      paperwork costs      |  1   |   1    |                          [(5, 1)]                           |\n",
      "|      exchange-listed      |  1   |   1    |                          [(6, 1)]                           |\n",
      "|           ifrs            |  1   |   1    |                          [(6, 1)]                           |\n",
      "|       across europe       |  1   |   1    |                          [(6, 1)]                           |\n",
      "|          hacking          |  5   |   1    |                          [(7, 1)]                           |\n",
      "|         red tape          |  6   |   1    |                          [(7, 1)]                           |\n",
      "|   low-cost competitors    |  1   |   1    |                          [(7, 1)]                           |\n",
      "|         low-wage          |  1   |   1    |                          [(8, 1)]                           |\n",
      "|    low-wage countries     |  1   |   1    |                          [(8, 1)]                           |\n",
      "|          % plan           |  1   |   1    |                          [(8, 1)]                           |\n",
      "|    significant threat     |  1   |   1    |                          [(9, 1)]                           |\n",
      "|         dipiazza          |  1   |   2    |                     [(10, 1), (13, 1)]                      |\n",
      "|  global chief executive   |  1   |   1    |                          [(10, 1)]                          |\n",
      "|      samuel dipiazza      |  1   |   1    |                          [(10, 1)]                          |\n",
      "|      outsource work       |  1   |   1    |                          [(10, 1)]                          |\n",
      "|       home markets        |  1   |   1    |                          [(10, 1)]                          |\n",
      "|           kill            |  16  |   1    |                          [(11, 1)]                          |\n",
      "|        frank brown        |  1   |   1    |                          [(11, 1)]                          |\n",
      "|  global advisory leader   |  1   |   1    |                          [(11, 1)]                          |\n",
      "|     global operations     |  1   |   1    |                          [(11, 1)]                          |\n",
      "|       clear upside        |  1   |   1    |                          [(11, 1)]                          |\n",
      "|       rapid decline       |  1   |   1    |                          [(12, 1)]                          |\n",
      "|        huge threat        |  2   |   1    |                          [(12, 1)]                          |\n",
      "|   third-largest problem   |  1   |   1    |                          [(12, 1)]                          |\n",
      "|          hedged           |  1   |   1    |                          [(13, 1)]                          |\n",
      "|        mr dipiazza        |  1   |   1    |                          [(13, 1)]                          |\n",
      "|        new reality        |  1   |   1    |                          [(13, 1)]                          |\n",
      "| favourable exchange rates |  1   |   1    |                          [(13, 1)]                          |\n",
      "|            324            |  2   |   1    |                          [(14, 1)]                          |\n",
      "+---------------------------+------+--------+-------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "document_path = os.path.join(\"BBC News Summary\", \"BBC News Summary\", \"News Articles\", \"business\", \"509.txt\")\n",
    "\n",
    "print(I.doc_to_string(map_path_to_articleID(document_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization \n",
    "\n",
    "TF: \n",
    "* Document: Term frequencies are assessed on document level.\n",
    "* Sentence: Term frequencies are assessed on sentence level.\n",
    "\n",
    "IDF: Inverted document frequencies is assessed on collection level.\\\n",
    "\\\n",
    "Additional parameter \"N\" and \"article_id\". Is this allowed?\n",
    "\n",
    "TODO: \n",
    "* Evaluate choice and give reason: \n",
    "    * IDF on document level?\n",
    "    * TF on document level for sentences? \n",
    "* \"order\" parameter o\n",
    "* BM25\n",
    "* BERT embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log10_tf(x):\n",
    "    try:\n",
    "        return (1 + np.log10(x)) \n",
    "    except ValueError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_term(N, df_t, tf_t_d):\n",
    "    return log10_tf(tf_t_d) * np.log10(N/df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_relevance_scores(info: list, N: int):\n",
    "    scores = defaultdict(int)\n",
    "    sq_normalization_term = defaultdict(int)\n",
    "    for _, df_t, tf_t_d, tf_per_sentence in info:\n",
    "        rel_t_d = tf_idf_term(N, df_t, tf_t_d)\n",
    "        for sent_number, tf_s_t in tf_per_sentence:\n",
    "            scores[sent_number] += rel_t_d * log10_tf(tf_s_t)\n",
    "            sq_normalization_term[sent_number] = log10_tf(tf_s_t)**2\n",
    "    # normalization\n",
    "    for sent_number, score in scores.items():\n",
    "        scores[sent_number] = score / np.sqrt(sq_normalization_term[sent_number])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarities_between_sentences(info: zip, N: int, num_sentences: int):\n",
    "    similarity_matrix = np.zeros((num_sentences, num_sentences))\n",
    "    sq_norm_sentence = np.zeros(num_sentences)\n",
    "    for _, df_t, tf_t_d, tf_per_sentence in info:\n",
    "        log10_tfs = np.zeros(num_sentences)\n",
    "        for sent_number, tf_s_t in tf_per_sentence:\n",
    "            log10_tfs[sent_number] = log10_tf(tf_s_t)\n",
    "        similarity_matrix += np.log10(N/df_t) * np.outer(log10_tfs, log10_tfs)\n",
    "        sq_norm_sentence += log10_tfs**2\n",
    "    norm_sentence = np.sqrt(sq_norm_sentence)\n",
    "    normalization = np.outer(norm_sentence, norm_sentence)\n",
    "    print(normalization, '\\n---\\n', similarity_matrix)\n",
    "    print('---', np.where(normalization==0))\n",
    "    return similarity_matrix / normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25_term(df_t, tf_t_d, N, s_len_avg, s_len, k, b): \n",
    "    idf_t = np.log10(N/df_t)\n",
    "    B = 1 - b + b * (s_len/s_len_avg)\n",
    "    return idf_t * (tf_t_d * (k + 1))/(tf_t_d + k * B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_value(d: dict, max_elements: int, reverse=False) -> dict: \n",
    "    return dict(sorted(d.items(), key=lambda item: item[1], reverse=reverse)[:max_elements])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_key(d: dict) -> dict: \n",
    "    return dict(sorted(d.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_order(scores: dict, o: str, p: int, l: int, sentence_lengths: list): \n",
    "    # Don't exceed maximum number of sentences. If it doesn't matter it should be set to 0\n",
    "    max_elements = p if p else len(scores)\n",
    "    sorted_scores = sort_by_value(scores, max_elements=max_elements, reverse=True)\n",
    "\n",
    "    # Don't exceed maximum number of characters. If it doesn't matter it should be set to 0\n",
    "    if l:\n",
    "        total_length = 0\n",
    "        cropped_sorted_scores = dict()\n",
    "        for sent_number, score in sorted_scores.items():\n",
    "            sent_length = sentence_lengths[sent_number]\n",
    "            total_length += sent_length\n",
    "            if total_length > l:\n",
    "                break\n",
    "            cropped_sorted_scores[sent_number] = score\n",
    "        sorted_scores = cropped_sorted_scores\n",
    "\n",
    "    if o == \"rel\": \n",
    "        return sorted_scores\n",
    "    elif o == \"app\": \n",
    "        return sort_by_key(sorted_scores)\n",
    "    else:\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(sentence: str, model, tokenizer, device, max_length=512) -> torch.tensor: \n",
    "    encoded_input = tokenizer(sentence, return_tensors='pt', truncation=True, max_length=max_length)\n",
    "    encoded_input.to(device)\n",
    "    output = model(**encoded_input)\n",
    "    embedding = output[\"pooler_output\"].squeeze()\n",
    "    # mean pooled embedding might be better\n",
    "    # mean_pooled_embedding = last_hidden_states.mean(axis=1)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(sentences: list, model, tokenizer, device, max_length=512) -> list: \n",
    "    encoded_input = tokenizer(sentences, return_tensors='pt', truncation=True, padding=True, max_length=max_length)\n",
    "    encoded_input.to(device)\n",
    "    output = model(**encoded_input)\n",
    "    embedding = output[\"pooler_output\"].squeeze()\n",
    "    # mean pooled embedding might be better\n",
    "    # mean_pooled_embedding = last_hidden_states.mean(axis=1)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_info_after_sent_removal(info: list, sent_removed: int):\n",
    "   for i, (term, df_t, tf_t_d, tf_per_sentence) in enumerate(info):\n",
    "      # decrease term frequency of info of the terms in the removed sentence\n",
    "      info[i][2] -= tf_per_sentence[sent_removed]  \n",
    "      # remove the sentence from info\n",
    "      info[i][3] = [(sent_number, score) for sent_number, score in info[i][3] if sent_number != sent_removed]\n",
    "      if info[i][2] == 0:\n",
    "         info[i][1] -= 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "summarization(d,p,l,o,I,args)\n",
    "    @input document d (the index in I/D), maximum number of sentences (p) and/or characters (l), order\n",
    "    of presentation o (appearance in text vs relevance), inverted index I or the\n",
    "    collection D, and optional arguments on IR models\n",
    "\n",
    "    @behavior preprocesses d, assesses the relevance of each sentence in d against I ac-\n",
    "    cording to args, and presents them in accordance with p, l and o\n",
    "    \n",
    "    @output summary s of document d, i.e. ordered pairs (sentence position in d, score)\n",
    "'''\n",
    "def summarization(d: int, p: int, l: int, o: int, I_or_D: Union[InvertedIndex, list], **args) -> list:\n",
    "\n",
    "    ## if we receive the collection instead of the inverted index we must compute it first\n",
    "    if type(I_or_D) == list:\n",
    "        I = indexing(I_or_D)         \n",
    "    else: \n",
    "        I = I_or_D\n",
    "        \n",
    "    doc_info = I.get_document_info(d)\n",
    "    term_doc_info = zip(*doc_info.values())      \n",
    "    sentence_lengths = I.get_sentence_lengths(d)\n",
    "    num_sentences = len(sentence_lengths)\n",
    "    scores = defaultdict(int)\n",
    "\n",
    "    if args['model'] == 'TF-IDF':\n",
    "        scores = tf_idf_relevance_scores(term_doc_info, I.N)\n",
    "    \n",
    "    elif args['model'] == 'BM25':\n",
    "        k = 0.2\n",
    "        b = 0.75 \n",
    "        avg_sentence_length = sum(sentence_lengths)/len(sentence_lengths)\n",
    "        for term, df_t, tf_t_d, tf_per_sentence in term_doc_info: \n",
    "            for sent_number, tf_s_t in tf_per_sentence: \n",
    "                scores[sent_number] += BM25_term(df_t, tf_s_t, I.N, avg_sentence_length, sentence_lengths[sent_number], k, b)\n",
    "    \n",
    "    elif args['model'] == 'BERT':\n",
    "        document = I_or_D[d]\n",
    "        \n",
    "        tokenizer = args['bert_tokenizer']\n",
    "        bert_model = args['bert_model']\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        bert_model.to(device)\n",
    "        \n",
    "        scores = defaultdict(float)\n",
    "        # sentences \n",
    "        sentences = nltk.sent_tokenize(document)\n",
    "        #sentences = sentences[1:]\n",
    "        sent_embeddings = list()\n",
    "        # every sentences on its own, no padding needed, faster on cpu\n",
    "        # for gpu batches are better \n",
    "        sent_embeddings = get_embeddings(sentences, bert_model, tokenizer, device)\n",
    "        #for sent in sentences: \n",
    "        #    sent_embedding = get_embedding(sent, bert_model, tokenizer, device)\n",
    "        #    sent_embeddings.append(sent_embedding)\n",
    "        # document\n",
    "        doc_embedding = get_embedding(document, bert_model, tokenizer, device, max_length=512)\n",
    "        for sent_id in range(0, num_sentences): \n",
    "            sent_vec = sent_embeddings[sent_id]\n",
    "            score = torch.nn.functional.cosine_similarity(doc_embedding, sent_vec, dim=0)\n",
    "            scores[sent_id] = score.item()\n",
    "    \n",
    "    elif args['model'] == 'MMR-TFIDF':\n",
    "        λ = args['λ']\n",
    "        runs = p or len(scores)\n",
    "        print(list(term_doc_info))\n",
    "        similarity_matrix = compute_similarities_between_sentences(term_doc_info, I.N, num_sentences)\n",
    "        print(list(term_doc_info))\n",
    "        available_sentence_relevance = tf_idf_relevance_scores(term_doc_info, I.N)\n",
    "        selected_sentences = defaultdict(int)\n",
    "        for _ in range(runs):\n",
    "            max_score = 0\n",
    "            best_sentence = None\n",
    "            for sent_num, rel_score in available_sentence_relevance:\n",
    "                mmr_score = λ * rel_score - (1-λ) * np.max(similarity_matrix[sent_num, :])\n",
    "                if mmr_score > max_score:\n",
    "                    max_score = mmr_score\n",
    "                    best_sentence = sent_num\n",
    "            selected_sentences[best_sentence] = max_score\n",
    "            available_sentence_relevance.pop(best_sentence)\n",
    "        scores = selected_sentences\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Currently we only support the following models:\\n→ TF-IDF\\n→ BM-25\\n→ BERT\\n→MMR-TFIDF\")\n",
    "    \n",
    "    return sort_by_order(scores, o, p, l, sentence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL DOCUMENT\n",
      "More than 90% of large companies around the world are highly optimistic about their economic prospects, a survey of 1,300 bosses suggests. Their biggest worries are not terror threats, but over-regulation, low-cost competition and the wild ups and downs of oil prices. There is one exception: Firms in Western Europe - but not the UK - are lacking confidence after years of slow growth. When business advisers PricewaterhouseCoopers (PwC) conducted the same survey two years ago, nearly 30% of bosses were gloomy about their prospects. Global business leaders say that they are facing a two-pronged regulatory assault. After a string of corporate scandals in the United States - from Enron to WorldCom - the Sarbanes-Oxley act forces companies to be much more transparent, but doing all the paperwork costs a lot of time and money. Across Europe, meanwhile, all stock exchange-listed companies are currently in the process of moving to new and complex accounting standards called IFRS. Hacking through the red tape can hardly be avoided, but many chief executives around the world appear to have decided on how to deal with low-cost competitors. Already, about 28% of the bosses polled for the survey say that they have moved parts of their business into low-wage countries, and another 11% plan to do so in the future. Possibly as a result, the worry about low-cost competition has slightly fallen from last year, with just 54% of companies calling it a \"significant threat\" or \"one of the biggest threats\". But PwC's global chief executive, Samuel DiPiazza, said a growing number of companies were also concerned that moves to outsource work to cheaper countries could both hurt their reputation in their home markets and harm the quality of service they provide to their customers. According to Frank Brown, global advisory leader at PwC , the trend of large companies to have global operations has one clear upside: \"One risk in one region - for example the Middle East - won't kill your business anymore.\" Surprisingly, the survey suggests that the rapid decline of the US dollar is not seen as a huge threat anymore, unlike even a year ago, when it was cited as the third-largest problem. Mr DiPiazza said the interviews with chief executives suggested that companies had \"adjusted\" to the new reality of a euro that buys $1.30 and more, while others had successfully hedged their positions and locked in more favourable exchange rates. - For the survey, PricewaterhouseCoopers interviewed 1,324 chief executives throughout the world during the last three months of 2004.\n",
      "SUMMARY\n",
      "34.66: Their biggest worries are not terror threats, but over-regulation, low-cost competition and the wild ups and downs of oil prices.\n",
      "37.39: After a string of corporate scandals in the United States - from Enron to WorldCom - the Sarbanes-Oxley act forces companies to be much more transparent, but doing all the paperwork costs a lot of time and money.\n",
      "33.91: Hacking through the red tape can hardly be avoided, but many chief executives around the world appear to have decided on how to deal with low-cost competitors.\n",
      "53.37: But PwC's global chief executive, Samuel DiPiazza, said a growing number of companies were also concerned that moves to outsource work to cheaper countries could both hurt their reputation in their home markets and harm the quality of service they provide to their customers.\n",
      "57.58: According to Frank Brown, global advisory leader at PwC , the trend of large companies to have global operations has one clear upside: \"One risk in one region - for example the Middle East - won't kill your business anymore.\"\n",
      "44.02: Surprisingly, the survey suggests that the rapid decline of the US dollar is not seen as a huge threat anymore, unlike even a year ago, when it was cited as the third-largest problem.\n",
      "49.77: Mr DiPiazza said the interviews with chief executives suggested that companies had \"adjusted\" to the new reality of a euro that buys $1.30 and more, while others had successfully hedged their positions and locked in more favourable exchange rates.\n"
     ]
    }
   ],
   "source": [
    "article_id = map_path_to_articleID(document_path)\n",
    "print(\"ORIGINAL DOCUMENT\")\n",
    "print(articles[article_id])\n",
    "scores = summarization(d=article_id, p=7, l=1000, o=\"app\", I_or_D=I, model='TF-IDF')\n",
    "\n",
    "print(\"SUMMARY\")\n",
    "sentences = nltk.sent_tokenize(articles[article_id])\n",
    "for sent_id, score in scores.items(): \n",
    "    print(f\"{score:.2f}: {sentences[sent_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL DOCUMENT\n",
      "More than 90% of large companies around the world are highly optimistic about their economic prospects, a survey of 1,300 bosses suggests. Their biggest worries are not terror threats, but over-regulation, low-cost competition and the wild ups and downs of oil prices. There is one exception: Firms in Western Europe - but not the UK - are lacking confidence after years of slow growth. When business advisers PricewaterhouseCoopers (PwC) conducted the same survey two years ago, nearly 30% of bosses were gloomy about their prospects. Global business leaders say that they are facing a two-pronged regulatory assault. After a string of corporate scandals in the United States - from Enron to WorldCom - the Sarbanes-Oxley act forces companies to be much more transparent, but doing all the paperwork costs a lot of time and money. Across Europe, meanwhile, all stock exchange-listed companies are currently in the process of moving to new and complex accounting standards called IFRS. Hacking through the red tape can hardly be avoided, but many chief executives around the world appear to have decided on how to deal with low-cost competitors. Already, about 28% of the bosses polled for the survey say that they have moved parts of their business into low-wage countries, and another 11% plan to do so in the future. Possibly as a result, the worry about low-cost competition has slightly fallen from last year, with just 54% of companies calling it a \"significant threat\" or \"one of the biggest threats\". But PwC's global chief executive, Samuel DiPiazza, said a growing number of companies were also concerned that moves to outsource work to cheaper countries could both hurt their reputation in their home markets and harm the quality of service they provide to their customers. According to Frank Brown, global advisory leader at PwC , the trend of large companies to have global operations has one clear upside: \"One risk in one region - for example the Middle East - won't kill your business anymore.\" Surprisingly, the survey suggests that the rapid decline of the US dollar is not seen as a huge threat anymore, unlike even a year ago, when it was cited as the third-largest problem. Mr DiPiazza said the interviews with chief executives suggested that companies had \"adjusted\" to the new reality of a euro that buys $1.30 and more, while others had successfully hedged their positions and locked in more favourable exchange rates. - For the survey, PricewaterhouseCoopers interviewed 1,324 chief executives throughout the world during the last three months of 2004.\n",
      "SUMMARY\n",
      "48.51: According to Frank Brown, global advisory leader at PwC , the trend of large companies to have global operations has one clear upside: \"One risk in one region - for example the Middle East - won't kill your business anymore.\"\n",
      "45.11: But PwC's global chief executive, Samuel DiPiazza, said a growing number of companies were also concerned that moves to outsource work to cheaper countries could both hurt their reputation in their home markets and harm the quality of service they provide to their customers.\n",
      "42.91: Mr DiPiazza said the interviews with chief executives suggested that companies had \"adjusted\" to the new reality of a euro that buys $1.30 and more, while others had successfully hedged their positions and locked in more favourable exchange rates.\n",
      "39.80: Surprisingly, the survey suggests that the rapid decline of the US dollar is not seen as a huge threat anymore, unlike even a year ago, when it was cited as the third-largest problem.\n",
      "34.99: After a string of corporate scandals in the United States - from Enron to WorldCom - the Sarbanes-Oxley act forces companies to be much more transparent, but doing all the paperwork costs a lot of time and money.\n"
     ]
    }
   ],
   "source": [
    "article_id = map_path_to_articleID(document_path)\n",
    "print(\"ORIGINAL DOCUMENT\")\n",
    "print(articles[article_id])\n",
    "scores = summarization(d=article_id, p=5, l=1000, o=\"rel\", I_or_D=I, model='BM25')\n",
    "\n",
    "print(\"SUMMARY\")\n",
    "sentences = nltk.sent_tokenize(articles[article_id])\n",
    "for sent_id, score in scores.items(): \n",
    "    print(f\"{score:.2f}: {sentences[sent_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5852e3653aeb4748a7d147f4e1270991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\marti\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6f4edb61b24fedb9379157638dfcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30943c41ba74c6581f9062c1ca40795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8b6438e2de4ab581975c2c7bbeac29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL DOCUMENT\n",
      "More than 90% of large companies around the world are highly optimistic about their economic prospects, a survey of 1,300 bosses suggests. Their biggest worries are not terror threats, but over-regulation, low-cost competition and the wild ups and downs of oil prices. There is one exception: Firms in Western Europe - but not the UK - are lacking confidence after years of slow growth. When business advisers PricewaterhouseCoopers (PwC) conducted the same survey two years ago, nearly 30% of bosses were gloomy about their prospects. Global business leaders say that they are facing a two-pronged regulatory assault. After a string of corporate scandals in the United States - from Enron to WorldCom - the Sarbanes-Oxley act forces companies to be much more transparent, but doing all the paperwork costs a lot of time and money. Across Europe, meanwhile, all stock exchange-listed companies are currently in the process of moving to new and complex accounting standards called IFRS. Hacking through the red tape can hardly be avoided, but many chief executives around the world appear to have decided on how to deal with low-cost competitors. Already, about 28% of the bosses polled for the survey say that they have moved parts of their business into low-wage countries, and another 11% plan to do so in the future. Possibly as a result, the worry about low-cost competition has slightly fallen from last year, with just 54% of companies calling it a \"significant threat\" or \"one of the biggest threats\". But PwC's global chief executive, Samuel DiPiazza, said a growing number of companies were also concerned that moves to outsource work to cheaper countries could both hurt their reputation in their home markets and harm the quality of service they provide to their customers. According to Frank Brown, global advisory leader at PwC , the trend of large companies to have global operations has one clear upside: \"One risk in one region - for example the Middle East - won't kill your business anymore.\" Surprisingly, the survey suggests that the rapid decline of the US dollar is not seen as a huge threat anymore, unlike even a year ago, when it was cited as the third-largest problem. Mr DiPiazza said the interviews with chief executives suggested that companies had \"adjusted\" to the new reality of a euro that buys $1.30 and more, while others had successfully hedged their positions and locked in more favourable exchange rates. - For the survey, PricewaterhouseCoopers interviewed 1,324 chief executives throughout the world during the last three months of 2004.\n",
      "SUMMARY\n",
      "0.95: When business advisers PricewaterhouseCoopers (PwC) conducted the same survey two years ago, nearly 30% of bosses were gloomy about their prospects.\n",
      "0.94: According to Frank Brown, global advisory leader at PwC , the trend of large companies to have global operations has one clear upside: \"One risk in one region - for example the Middle East - won't kill your business anymore.\"\n",
      "0.92: But PwC's global chief executive, Samuel DiPiazza, said a growing number of companies were also concerned that moves to outsource work to cheaper countries could both hurt their reputation in their home markets and harm the quality of service they provide to their customers.\n",
      "0.91: Mr DiPiazza said the interviews with chief executives suggested that companies had \"adjusted\" to the new reality of a euro that buys $1.30 and more, while others had successfully hedged their positions and locked in more favourable exchange rates.\n",
      "0.91: - For the survey, PricewaterhouseCoopers interviewed 1,324 chief executives throughout the world during the last three months of 2004.\n"
     ]
    }
   ],
   "source": [
    "article_id = map_path_to_articleID(document_path)\n",
    "print(\"ORIGINAL DOCUMENT\")\n",
    "print(articles[article_id])\n",
    "scores = summarization(d=article_id, p=5, l=1000, o=\"rel\", I_or_D=articles, model='BERT', bert_model=bert_model, bert_tokenizer=bert_tokenizer)\n",
    "\n",
    "print(\"SUMMARY\")\n",
    "sentences = nltk.sent_tokenize(articles[article_id])\n",
    "for sent_id, score in scores.items(): \n",
    "    print(f\"{score:.2f}: {sentences[sent_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "scores = list()\n",
    "for category_id, category in enumerate(article_file_paths): \n",
    "    scores.append([])\n",
    "    for path in category: \n",
    "        article_id = map_path_to_articleID(path)\n",
    "        article_score = summarization(d=article_id, p=7, l=1000, o=\"rel\", I_or_D=I, model='TF-IDF')\n",
    "        scores[-1].append(article_score)\n",
    "with open('./testing/extracts/tf_idf/categorized_scores.json', 'w') as f: \n",
    "    json.dump(scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25\n",
    "scores = list()\n",
    "for category_id, category in enumerate(article_file_paths): \n",
    "    scores.append([])\n",
    "    for path in category: \n",
    "        article_id = map_path_to_articleID(path)\n",
    "        article_score = summarization(d=article_id, p=7, l=1000, o=\"rel\", I_or_D=I, model='BM25')\n",
    "        scores[-1].append(article_score)\n",
    "with open('./testing/extracts/bm25/categorized_scores.json', 'w') as f: \n",
    "    json.dump(scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m         article_id \u001b[38;5;241m=\u001b[39m map_path_to_articleID(path)\n\u001b[0;32m      7\u001b[0m         scores \u001b[38;5;241m=\u001b[39m summarization(d\u001b[38;5;241m=\u001b[39marticle_id, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, l\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, o\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrel\u001b[39m\u001b[38;5;124m\"\u001b[39m, I_or_D\u001b[38;5;241m=\u001b[39marticles, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBERT\u001b[39m\u001b[38;5;124m'\u001b[39m, bert_model\u001b[38;5;241m=\u001b[39mbert_model, bert_tokenizer\u001b[38;5;241m=\u001b[39mbert_tokenizer)\n\u001b[1;32m----> 8\u001b[0m         scores[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(article_score)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./testing/extracts/bert/categorized_scores.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: \n\u001b[0;32m     10\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(scores, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "scores = list()\n",
    "for category_id, category in enumerate(article_file_paths): \n",
    "    scores.append([])\n",
    "    for path in category: \n",
    "        article_id = map_path_to_articleID(path)\n",
    "        scores = summarization(d=article_id, p=5, l=1000, o=\"rel\", I_or_D=articles, model='BERT', bert_model=bert_model, bert_tokenizer=bert_tokenizer)\n",
    "        scores[-1].append(article_score)\n",
    "with open('./testing/extracts/bert/categorized_scores.json', 'w') as f: \n",
    "    json.dump(scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Extraction\n",
    "\n",
    "Calculates the keywords based on the tf-idf of the document.\\\n",
    "\\\n",
    "Additional parameter \"N\" and \"article_id\". Is this allowed?\n",
    "\n",
    "Parameter for including only noun phrases. \n",
    "\n",
    "No need of BERT (see assigment sheet, p.4 IR Models)\n",
    "\n",
    "should be primarly based on TF-IDF\n",
    "\n",
    "\n",
    "TODO:\n",
    "* Nouns: just unigrams or also bigrams?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.classify import Senna\n",
    "from nltk.tag import SennaChunkTagger\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "keyword extraction(d,p,I,args)\n",
    "    @input document d, maximum number of keywords p, inverted index I, and op-\n",
    "    tional arguments on IR model choices\n",
    "\n",
    "    @behavior extracts the top informative p keywords in d against I according to args\n",
    "    \n",
    "    @output ordered set of p keywords\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_extraction(d: int, p: int, I: InvertedIndex, **args) -> dict:\n",
    "     \n",
    "    doc_info = I.get_document_info(d)\n",
    "    term_doc_info = zip(*doc_info.values())    \n",
    "\n",
    "    scores = defaultdict(str)\n",
    "\n",
    "    for term, df_t, tf_t_d, tf_per_sentence in term_doc_info:\n",
    "        rel_t_d = tf_idf_term(I.N, df_t, tf_t_d)\n",
    "        scores[term] = rel_t_d\n",
    "    scores = sort_by_value(scores, p, reverse=True)\n",
    "    return scores         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_id = map_path_to_articleID(document_path)\n",
    "scores = keyword_extraction(article_id, 10, I)\n",
    "print(scores)\n",
    "\n",
    "print(I.doc_to_string(article_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "TODO:\n",
    "* Implement evaluation\n",
    "* Evaluation:\n",
    "    * Statistics \n",
    "    * F-meassure\n",
    "    * Recall-precision-curve\n",
    "    * MAP\n",
    "    * Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "evaluation(Sset,Rset,args)\n",
    "    @input the set of summaries Sset produced from selected documents Dset ⊆ D\n",
    "    (e.g. a single document, a category of documents, the whole collection),\n",
    "    the corresponding reference extracts Rset, and optional arguments (evalu-\n",
    "    ation, preprocessing, model options)\n",
    "\n",
    "    @behavior assesses the produced summaries against the reference ones using the tar-\n",
    "    get evaluation criteria\n",
    "\n",
    "    @output evaluation statistics, including F-measuring at predefined p-or-l summary\n",
    "    limits, recall-and-precision curves, MAP, and efficiency\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(extracted_indices, relevant_indices):\n",
    "    extracted_indices = set(extracted_indices)\n",
    "    relevant_indices = set(relevant_indices)\n",
    "    return len(relevant_indices.intersection(extracted_indices))/len(extracted_indices)\n",
    "\n",
    "def get_recall(extracted_indices, relevant_indices):\n",
    "    extracted_indices = set(extracted_indices)\n",
    "    relevant_indices = set(relevant_indices)\n",
    "    return len(relevant_indices.intersection(extracted_indices))/len(relevant_indices)\n",
    "\n",
    "def get_F1(extracted_indices, relevant_indices):\n",
    "    extracted_indices = set(extracted_indices)\n",
    "    relevant_indices = set(relevant_indices)\n",
    "    p = get_precision(extracted_indices, relevant_indices)\n",
    "    r = get_recall(extracted_indices, relevant_indices)\n",
    "    if p+r == 0: return 0\n",
    "    return 2 * (p*r) / (p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f1_per_category(f1_per_category, std_per_category, category_names, title):\n",
    "    x = category_names\n",
    "    color = [\"red\", \"blue\", \"green\", \"orange\", \"magenta\"]\n",
    "    plt.bar(x, f1_per_category, color=color)\n",
    "    plt.errorbar(x, f1_per_category, std_per_category, fmt='.', color='Black', elinewidth=2,capthick=10,errorevery=1, alpha=0.5, ms=4, capsize = 2)\n",
    "    plt.xlabel(\"Category\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall_curve_data(extracted_indices, relevant_indices):\n",
    "    extracted_indices = list(extracted_indices.keys())\n",
    "    extracted_indices = list(map(int, extracted_indices))\n",
    "    relevant_indices = set(relevant_indices)\n",
    "    precision_level = list()\n",
    "    recall_level = list()\n",
    "    for k in range(len(extracted_indices)): \n",
    "        extracted_indices_at_k = set(extracted_indices[:k+1])\n",
    "        intersect = extracted_indices_at_k.intersection(relevant_indices)\n",
    "        precision = len(intersect)/len(extracted_indices_at_k)\n",
    "        precision_level.append(precision)\n",
    "        recall_level.append((k+1)/len(extracted_indices))\n",
    "    return precision_level, recall_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(precision_level, recall_level): \n",
    "    plt.plot(recall_level, precision_level)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1.01)\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision-Recall\")\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(S: list, R: list, **args) -> list:\n",
    "    precisions = list()\n",
    "    recalls = list() \n",
    "    f1_scores = list()\n",
    "    for category_id, (category_extracted_indices_rel, category_relevant_indices) in enumerate(zip(R, S)):\n",
    "            precisions.append([])\n",
    "            recalls.append([])\n",
    "            f1_scores.append([])\n",
    "            for extracted_indices_rel, relevant_indices in zip(category_extracted_indices_rel, category_relevant_indices):\n",
    "                extracted_indices = list(extracted_indices_rel.keys())\n",
    "                extracted_indices = list(map(int, extracted_indices))\n",
    "                precisions[-1].append(get_precision(extracted_indices, relevant_indices))\n",
    "                recalls[-1].append(get_recall(extracted_indices, relevant_indices))\n",
    "                f1_scores[-1].append(get_F1(extracted_indices, relevant_indices))\n",
    "    \n",
    "    mean_f1_per_catgory = list()\n",
    "    mean_std_per_category = list()\n",
    "    for f1 in f1_scores: \n",
    "        mean_f1_per_catgory.append(statistics.mean(f1))\n",
    "        mean_std_per_category.append(statistics.stdev(f1))\n",
    "\n",
    "    plot_f1_per_category(mean_f1_per_catgory, mean_std_per_category, args['category_names'], args['model_name'])\n",
    "\n",
    "    mean_precision = statistics.mean(flatten(precisions))\n",
    "    mean_recall = statistics.mean(flatten(recalls))\n",
    "    mean_f1_scores = statistics.mean(flatten(f1_scores))\n",
    "    \n",
    "    # precision-recall curve only for one document \n",
    "    example_category = 0\n",
    "    example_article = 1\n",
    "    precision_c, recall_c = get_precision_recall_curve_data(R[example_category][example_article], S[example_category][example_article])\n",
    "    plot_precision_recall_curve(precision_c, recall_c)\n",
    "    mAP = statistics.mean(precision_c)\n",
    "    print(f\"Mean average precision: {mAP}\")\n",
    "    return mean_precision, mean_recall, mean_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./testing/reference/categorized_summary_sentence_indices.json\", \"r\") as f:\n",
    "    categorized_summary_sentence_indices = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./testing/extracts/tf_idf/categorized_scores.json\", \"r\") as f: \n",
    "    tf_idf_extract = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./testing/extracts/bm25/categorized_scores.json\", \"r\") as f: \n",
    "    bm25_extract = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(categorized_summary_sentence_indices, tf_idf_extract, category_names=category_names, model_name=\"TF-IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(categorized_summary_sentence_indices, bm25_extract, category_names=category_names, model_name=\"BM25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subset for BERT comparison\\\n",
    "takes too long otherwise\\ \n",
    "\n",
    "TODO: \n",
    "* evaluation + first question -> Sebastian   \n",
    "* question 2, 3, 4 -> Francisco\n",
    "* question 5 and 6 -> Tuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) **Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.1 Summarization solution: results for a given document*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here\n",
    "article_id = 0\n",
    "print(articles[article_id])\n",
    "summarization(articles[article_id], num_sent=5, order=\"rel\", inverted_index=I, N=len(articles), article_id=article_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.2 IR models (TF-IDF, BM25 and EBRT)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.3 Reciprocal rank funsion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RRF(article_id, index, collection, mu=5, p=5):\n",
    "    \n",
    "    #get all scores for BERT\n",
    "    scores_bert = summarization(d=article_id, p=0, l=0, o=\"rel\", I_or_D=collection, model='BERT', bert_model=bert_model, bert_tokenizer=bert_tokenizer)\n",
    "    ranks_bert = {key: rank for rank, key in enumerate(scores_bert, 1)}\n",
    "    #get all scores of BM25\n",
    "    scores_bm25 = summarization(d=article_id, p=0, l=0, o=\"rel\", I_or_D=index, model='BM25')\n",
    "    ranks_bm25 = {key: rank for rank, key in enumerate(scores_bm25, 1)} \n",
    "    \n",
    "    #get RRF\n",
    "    scores_rrf = defaultdict(int)\n",
    "    for sent_number in ranks_bert.keys():\n",
    "        scores_rrf[sent_number] = 1/(mu + ranks_bert[sent_number]) + 1/(mu + ranks_bm25[sent_number])\n",
    "        \n",
    "    return sort_by_value(scores_rrf, p, reverse=True)\n",
    "\n",
    "article_id = map_path_to_articleID(document_path)\n",
    "print(\"ORIGINAL DOCUMENT\")\n",
    "print(articles[article_id])\n",
    "scores = get_RRF (article_id, I, articles, mu=5, p=5)\n",
    "scores = dict(sorted(scores.items()))\n",
    "print(\"SUMMARY\")\n",
    "sentences = nltk.sent_tokenize(articles[article_id])\n",
    "for sent_id, rank in scores.items(): \n",
    "    print(f\"{rank:.2f}: {sentences[sent_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.4 Maximal Marginal Relevance*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMR \n",
    "Maximal Marginal Relevance (MRR) is a method that can be used to increase sentence diversity. \n",
    "\n",
    "The proposed method iteratively selects the most informative sentence according to a given IR model, adding it to the set of sentences in the summary and removing it from the document. Next sentence selection is based on the MMR score that simultaneously attempts to select sentences that are relevant and dissimilar to the sentences selected so far (non-redundancy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('quarterly', 20, 1, [(0, 1)]), ('profit', 113, 9, [(0, 1), (3, 2), (6, 1), (7, 1), (10, 1), (11, 1), (12, 1), (14, 1)]), ('u', 830, 3, [(0, 1), (9, 1), (15, 1)]), ('medium', 201, 1, [(0, 1)]), ('giant', 159, 1, [(0, 1)]), ('timewarner', 1, 7, [(0, 1), (2, 1), (8, 1), (9, 1), (12, 1), (14, 1), (15, 1)]), ('jumped', 31, 1, [(0, 1)]), ('76', 13, 1, [(0, 1)]), ('1', 463, 1, [(0, 1)]), ('13bn', 6, 1, [(0, 1)]), ('â', 646, 1, [(0, 1)]), ('600m', 6, 1, [(0, 1)]), ('three', 557, 2, [(0, 1), (6, 1)]), ('month', 578, 1, [(0, 1)]), ('december', 214, 1, [(0, 1)]), ('639m', 1, 1, [(0, 1)]), ('year-earlier', 1, 2, [(0, 1), (11, 1)]), ('us media', 1, 1, [(0, 1)]), ('$ 1.13bn', 2, 1, [(0, 1)]), ('$ 639m', 1, 1, [(0, 1)]), ('firm', 459, 1, [(1, 1)]), ('one', 1042, 1, [(1, 1)]), ('biggest', 234, 1, [(1, 1)]), ('investor', 101, 1, [(1, 1)]), ('google', 37, 2, [(1, 1), (4, 1)]), ('benefited', 6, 1, [(1, 1)]), ('sale', 324, 4, [(1, 2), (2, 1), (19, 1)]), ('high-speed', 29, 2, [(1, 1), (8, 1)]), ('internet', 163, 4, [(1, 1), (5, 1), (7, 1), (8, 1)]), ('connection', 75, 1, [(1, 1)]), ('higher', 138, 2, [(1, 1), (14, 1)]), ('advert', 28, 1, [(1, 1)]), ('internet connections', 4, 1, [(1, 1)]), ('advert sales', 1, 1, [(1, 1)]), ('said', 1883, 5, [(2, 1), (4, 1), (7, 1), (13, 1), (17, 1)]), ('fourth', 114, 3, [(2, 1), (6, 1), (10, 1)]), ('quarter', 151, 4, [(2, 1), (6, 2), (10, 1)]), ('rose', 129, 2, [(2, 1), (7, 1)]), ('2', 388, 1, [(2, 1)]), ('11', 189, 1, [(2, 1)]), ('1bn', 67, 1, [(2, 1)]), ('10', 388, 1, [(2, 1)]), ('9bn', 24, 1, [(2, 1)]), ('quarter sales', 1, 1, [(2, 1)]), ('$ 11.1bn', 1, 1, [(2, 1)]), ('$ 10.9bn', 1, 1, [(2, 1)]), ('buoyed', 5, 1, [(3, 1)]), ('one-off', 14, 1, [(3, 1)]), ('gain', 75, 1, [(3, 1)]), ('offset', 21, 1, [(3, 1)]), ('dip', 19, 1, [(3, 1)]), ('warner', 13, 3, [(3, 1), (4, 1), (10, 1)]), ('bros', 8, 1, [(3, 1)]), ('le', 248, 1, [(3, 1)]), ('user', 186, 1, [(3, 1)]), ('aol', 15, 7, [(3, 1), (5, 1), (7, 1), (8, 1), (15, 1), (18, 1), (19, 1)]), ('one-off gains', 1, 1, [(3, 1)]), ('profit dip', 1, 1, [(3, 1)]), ('warner bros', 6, 1, [(3, 1)]), ('time', 879, 2, [(4, 1), (10, 1)]), ('friday', 161, 1, [(4, 1)]), ('owns', 41, 1, [(4, 1)]), ('8', 189, 2, [(4, 1), (7, 1)]), ('search-engine', 1, 1, [(4, 1)]), ('business', 301, 1, [(5, 1)]), ('ha', 1824, 3, [(5, 1), (9, 1), (16, 1)]), ('mixed', 23, 1, [(5, 1)]), ('fortune', 36, 1, [(5, 1)]), ('own internet business', 1, 1, [(5, 1)]), ('lost', 245, 1, [(6, 1)]), ('464', 2, 1, [(6, 1)]), ('000', 480, 1, [(6, 1)]), ('subscriber', 30, 2, [(6, 1), (8, 1)]), ('lower', 98, 1, [(6, 1)]), ('preceding', 4, 1, [(6, 1)]), ('quarter profits', 3, 2, [(6, 1), (10, 1)]), ('however', 417, 1, [(7, 1)]), ('company', 534, 2, [(7, 1), (17, 1)]), ('underlying', 14, 1, [(7, 1)]), ('exceptional', 10, 1, [(7, 1)]), ('item', 33, 1, [(7, 1)]), ('back', 550, 1, [(7, 1)]), ('stronger', 50, 1, [(7, 1)]), ('advertising', 33, 2, [(7, 1), (18, 1)]), ('revenue', 102, 4, [(7, 1), (12, 1), (14, 1), (18, 1)]), ('exceptional items', 1, 1, [(7, 1)]), ('hope', 239, 1, [(8, 1)]), ('increase', 205, 1, [(8, 1)]), ('offering', 86, 1, [(8, 1)]), ('online', 163, 1, [(8, 1)]), ('service', 368, 1, [(8, 1)]), ('free', 152, 1, [(8, 1)]), ('customer', 117, 2, [(8, 2)]), ('try', 184, 1, [(8, 1)]), ('sign', 111, 1, [(8, 1)]), ('existing', 75, 1, [(8, 1)]), ('broadband', 72, 1, [(8, 1)]), ('online service', 1, 1, [(8, 1)]), ('internet customers', 1, 1, [(8, 1)]), ('also', 1261, 2, [(9, 1), (14, 1)]), ('restate', 4, 2, [(9, 1), (15, 1)]), ('2000', 110, 1, [(9, 1)]), ('2003', 315, 2, [(9, 1), (12, 1)]), ('result', 277, 2, [(9, 1), (11, 1)]), ('following', 235, 1, [(9, 1)]), ('probe', 14, 1, [(9, 1)]), ('security', 190, 1, [(9, 1)]), ('exchange', 100, 1, [(9, 1)]), ('commission', 111, 1, [(9, 1)]), ('sec', 16, 2, [(9, 1), (16, 1)]), ('close', 166, 1, [(9, 1)]), ('concluding', 4, 1, [(9, 1)]), ('exchange commission', 18, 1, [(9, 1)]), ('slightly', 58, 1, [(10, 1)]), ('better', 272, 1, [(10, 1)]), ('analyst', 263, 1, [(10, 1)]), ('expectation', 72, 1, [(10, 1)]), ('film', 275, 2, [(11, 2)]), ('division', 61, 1, [(11, 1)]), ('saw', 152, 1, [(11, 1)]), ('slump', 14, 1, [(11, 1)]), ('27', 85, 2, [(11, 1), (12, 1)]), ('284m', 1, 1, [(11, 1)]), ('helped', 125, 1, [(11, 1)]), ('box-office', 4, 1, [(11, 1)]), ('flop', 6, 1, [(11, 1)]), ('alexander', 22, 1, [(11, 1)]), ('catwoman', 1, 1, [(11, 1)]), ('sharp', 40, 1, [(11, 1)]), ('contrast', 45, 1, [(11, 1)]), ('third', 309, 1, [(11, 1)]), ('final', 230, 1, [(11, 1)]), ('lord', 110, 1, [(11, 1)]), ('ring', 39, 1, [(11, 1)]), ('trilogy', 11, 1, [(11, 1)]), ('boosted', 32, 1, [(11, 1)]), ('film division', 1, 1, [(11, 1)]), ('profits slump', 1, 1, [(11, 1)]), ('$ 284m', 1, 1, [(11, 1)]), ('box-office flops', 1, 1, [(11, 1)]), ('sharp contrast', 1, 1, [(11, 1)]), ('final film', 2, 1, [(11, 1)]), ('full-year', 5, 2, [(12, 1), (13, 1)]), ('posted', 28, 1, [(12, 1)]), ('3', 270, 1, [(12, 1)]), ('36bn', 2, 1, [(12, 1)]), ('performance', 199, 2, [(12, 1), (13, 1)]), ('grew', 54, 1, [(12, 1)]), ('6', 204, 1, [(12, 1)]), ('4', 322, 1, [(12, 1)]), ('42', 27, 1, [(12, 1)]), ('09bn', 1, 1, [(12, 1)]), ('$ 3.36bn', 1, 1, [(12, 1)]), ('$ 42.09bn', 1, 1, [(12, 1)]), ('financial', 182, 1, [(13, 1)]), ('wa', 1746, 2, [(13, 1), (17, 1)]), ('strong', 213, 1, [(13, 1)]), ('meeting', 182, 1, [(13, 1)]), ('exceeding', 3, 1, [(13, 1)]), ('objective', 18, 1, [(13, 1)]), ('greatly', 9, 1, [(13, 1)]), ('enhancing', 4, 1, [(13, 1)]), ('flexibility', 21, 1, [(13, 1)]), ('chairman', 176, 1, [(13, 1)]), ('chief', 353, 1, [(13, 1)]), ('executive', 262, 1, [(13, 1)]), ('richard', 80, 1, [(13, 1)]), ('parson', 2, 1, [(13, 1)]), ('financial performance', 1, 1, [(13, 1)]), ('full-year objectives', 1, 1, [(13, 1)]), ('chief executive', 150, 1, [(13, 1)]), ('richard parsons', 1, 1, [(13, 1)]), ('2005', 293, 1, [(14, 1)]), ('projecting', 2, 1, [(14, 1)]), ('operating', 80, 1, [(14, 1)]), ('earnings', 59, 1, [(14, 1)]), ('growth', 229, 1, [(14, 1)]), ('around', 312, 1, [(14, 1)]), ('5', 330, 1, [(14, 1)]), ('expects', 54, 1, [(14, 1)]), ('wider', 44, 1, [(14, 1)]), ('margin', 32, 1, [(14, 1)]), ('earnings growth', 3, 1, [(14, 1)]), ('profit margins', 3, 1, [(14, 1)]), ('account', 142, 2, [(15, 1), (18, 1)]), ('part', 459, 1, [(15, 1)]), ('effort', 160, 1, [(15, 1)]), ('resolve', 19, 1, [(15, 1)]), ('inquiry', 48, 1, [(15, 1)]), ('market', 390, 1, [(15, 1)]), ('regulator', 44, 1, [(15, 1)]), ('us market regulators', 1, 1, [(15, 1)]), ('already', 372, 1, [(16, 1)]), ('offered', 108, 1, [(16, 1)]), ('pay', 184, 1, [(16, 1)]), ('300m', 13, 1, [(16, 1)]), ('settle', 38, 1, [(16, 1)]), ('charge', 179, 1, [(16, 1)]), ('deal', 261, 2, [(16, 1), (18, 1)]), ('review', 81, 1, [(16, 1)]), ('$ 300m', 4, 1, [(16, 1)]), ('unable', 42, 1, [(17, 1)]), ('estimate', 62, 1, [(17, 1)]), ('amount', 127, 1, [(17, 1)]), ('needed', 171, 1, [(17, 1)]), ('set', 496, 2, [(17, 2)]), ('aside', 34, 1, [(17, 1)]), ('legal', 163, 1, [(17, 1)]), ('reserve', 46, 1, [(17, 1)]), ('previously', 103, 1, [(17, 1)]), ('500m', 19, 1, [(17, 1)]), ('legal reserves', 1, 1, [(17, 1)]), ('$ 500m', 9, 1, [(17, 1)]), ('intends', 19, 1, [(18, 1)]), ('adjust', 5, 1, [(18, 1)]), ('way', 579, 1, [(18, 1)]), ('german', 85, 1, [(18, 1)]), ('music', 230, 1, [(18, 1)]), ('publisher', 26, 1, [(18, 1)]), ('bertelsmann', 1, 1, [(18, 1)]), ('purchase', 42, 1, [(18, 1)]), ('stake', 59, 3, [(18, 1), (19, 2)]), ('europe', 248, 2, [(18, 1), (19, 1)]), ('reported', 141, 1, [(18, 1)]), ('german music publisher', 1, 1, [(18, 1)]), (\"'s purchase\", 3, 1, [(18, 1)]), ('aol europe', 1, 2, [(18, 1), (19, 1)]), ('book', 116, 1, [(19, 1)]), ('loss', 104, 1, [(19, 1)]), ('value', 134, 1, [(19, 1)])]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "---\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "--- (array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "        2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,\n",
      "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,\n",
      "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "        5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "        6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "        7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,\n",
      "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10,\n",
      "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11,\n",
      "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "       11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "       12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "       13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15,\n",
      "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16,\n",
      "       16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "       17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "       17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "       18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "       19, 19, 19, 19, 19, 19, 19, 19, 19], dtype=int64), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
      "       14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,\n",
      "       11, 12, 13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,  5,  6,  7,\n",
      "        8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,\n",
      "        5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,  0,  1,\n",
      "        2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "       19,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
      "       16, 17, 18, 19,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,\n",
      "       13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
      "       10, 11, 12, 13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,  5,  6,\n",
      "        7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3,\n",
      "        4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,  0,\n",
      "        1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "       18, 19,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,\n",
      "       15, 16, 17, 18, 19,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,\n",
      "       12, 13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,  5,  6,  7,  8,\n",
      "        9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,  5,\n",
      "        6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,  0,  1,  2,\n",
      "        3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
      "        0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
      "       14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,\n",
      "       11, 12, 13, 14, 15, 16, 17, 18, 19], dtype=int64))\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_4056\\1776359779.py:14: RuntimeWarning: invalid value encountered in divide\n",
      "  return similarity_matrix / normalization\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[169], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#code, statistics and/or charts here\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m summarization(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrel\u001b[39m\u001b[38;5;124m'\u001b[39m, I, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMMR-TFIDF\u001b[39m\u001b[38;5;124m'\u001b[39m, λ\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n",
      "Cell \u001b[1;32mIn[163], line 80\u001b[0m, in \u001b[0;36msummarization\u001b[1;34m(d, p, l, o, I_or_D, **args)\u001b[0m\n\u001b[0;32m     78\u001b[0m                 best_sentence \u001b[38;5;241m=\u001b[39m sent_num\n\u001b[0;32m     79\u001b[0m         selected_sentences[best_sentence] \u001b[38;5;241m=\u001b[39m max_score\n\u001b[1;32m---> 80\u001b[0m         available_sentence_relevance\u001b[38;5;241m.\u001b[39mpop(best_sentence)\n\u001b[0;32m     81\u001b[0m     scores \u001b[38;5;241m=\u001b[39m selected_sentences\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "#code, statistics and/or charts here\n",
    "summarization(0, 10, 0, 'rel', I, model='MMR-TFIDF', λ=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) **Keyword extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here\n",
    "article_id = 0\n",
    "print(articles[article_id])\n",
    "keyword_extraction(articles[0], 10, I, len(articles), 0, use_only_nouns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D) **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Part II: questions materials (optional)</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** Corpus *D* and summaries *S* description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_sentences(documents: list) -> list: \n",
    "    number_of_sentences = list()\n",
    "    for document in documents: \n",
    "        sents = sent_tokenize(document) \n",
    "        number_of_sentences.append(len(sents))\n",
    "    return number_of_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(documents: list) -> Union[float, float, float]: \n",
    "    number_of_sentences = get_number_of_sentences(documents)\n",
    "    mean = statistics.mean(number_of_sentences)\n",
    "    median = statistics.median(number_of_sentences)\n",
    "    std = statistics.stdev(number_of_sentences)\n",
    "    return mean, std, median "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(documents: list):\n",
    "    number_of_sentences = get_number_of_sentences(documents)\n",
    "    mean, std, median = get_statistics(documents)\n",
    "    plt.hist(number_of_sentences, bins=80)\n",
    "    plt.title(f\"mean: {mean:.2f}, std: {std:.2f}, median: {median:.2f}\")\n",
    "    plt.xlabel(\"Number of sentences\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here\n",
    "\n",
    "# average number of sentences \n",
    "mean, std, median = get_statistics(articles)\n",
    "plot_distribution(articles)\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Standard deviation: {std}\")\n",
    "print(f\"Median: {median}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##mean, std, median = get_statistics(summaries)\n",
    "#plot_distribution(summaries)\n",
    "#print(f\"Mean: {mean}\")\n",
    "##print(f\"Standard deviation: {std}\")\n",
    "#print(f\"Median: {median}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_sentences = [len(l) for l in summary_sentence_indices]\n",
    "mean = statistics.mean(number_of_sentences)\n",
    "median = statistics.median(number_of_sentences)\n",
    "std = statistics.stdev(number_of_sentences)\n",
    "plt.hist(number_of_sentences, bins=80)\n",
    "plt.title(f\"mean: {mean:.2f}, std: {std:.2f}, median: {median:.2f}\")\n",
    "plt.xlabel(\"Number of sentences\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** Summarization performance for the overall and category-conditional corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**...** (additional questions with empirical results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>END</H3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
