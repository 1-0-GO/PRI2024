{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>PRI 2023/24: first project delivery</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GROUP 11**\n",
    "- Francisco Martins, 99068\n",
    "- Tunahan Güneş, 108108\n",
    "- Sebastian Weidinger, 111612"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Part I: demo of facilities</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    texts = []\n",
    "    file_paths = []\n",
    "    for folder in os.listdir(path):\n",
    "        category_path = os.path.join(path, folder)\n",
    "        texts.append([])\n",
    "        for file in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, file)\n",
    "            file_paths.append(file_path)\n",
    "            with open(file_path, \"r\", errors=\"ignore\") as f:\n",
    "                text = f.read()\n",
    "                texts[-1].append(text)\n",
    "                \n",
    "    print(\"Number of Categories:\",len(os.listdir(path)))\n",
    "    for i in range(len(os.listdir(path))):\n",
    "        print(\"Number of Articles in\", \"'\"+os.listdir(path)[i]+\"'\", \"Category:\",len(texts[i]))\n",
    "    return file_paths, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: BBC News Summary/BBC News Summary/News Articles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Categories: 5\n",
      "Number of Articles in 'tech' Category: 401\n",
      "Number of Articles in 'entertainment' Category: 386\n",
      "Number of Articles in 'sport' Category: 511\n",
      "Number of Articles in 'business' Category: 510\n",
      "Number of Articles in 'politics' Category: 417\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(\"BBC News Summary\", \"BBC News Summary\", \"News Articles\")\n",
    "print(\"Dataset path:\", dataset_path)\n",
    "file_paths, categorized_articles = read_files(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bond game fails to shake or stir\n",
      "\n",
      "For gaming fans, the word GoldenEye evokes excited memories not only of the James Bond revival flick of 1995, but also the classic shoot-em-up that accompanied it and left N64 owners glued to their consoles for many an hour.\n",
      "\n",
      "Adopting that hallowed title somewhat backfires on this new game, for it fails to deliver on the promise of its name and struggles to generate the original's massive sense of fun. This however is not a sequel, nor does it relate to the GoldenEye film. You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6. Your new commander-in-chief is the portly Auric Goldfinger, last seen in 1964, but happily running around bent on world domination. With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "\n",
      "Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter. The notion is of course to add a novel dark edge to a 007 game, but the premise simply does not get the juices flowing like it needs to.\n",
      "\n",
      "Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise. This title lacks that aura, and when the Bond magic shines through, it feels like a lucky accident. The central problem is that the gameplay just is not good enough. Quite aside from the bizarre inability to jump, the even more bizarre glaring graphical bugs and dubious enemy AI, the levels simply are not put together with much style or imagination. Admittedly the competition has been tough, even in recent weeks, with the likes of Halo 2 and Half Life 2 triumphing in virtually every department. What the game is good at is enveloping you in noisy, dynamic scenes of violent chaos. As is the trend of late, you are made to feel like you are in the midst of a really messy and fraught encounter. Sadly that sense of action is outweighed by the difficulty of navigating and battling within the chaos, meaning that frustration is often the outcome. And irregular save points mean you have to backtrack each time you are killed. A minute red dot passes for a crosshair, although the collision-detection is so suspect that the difficulties of aiming weapons are compensated for. Shooting enemies from a distance can be tricky, and you will not always know you have picked them off, since dead enemies vanish literally before they have fully hit the floor, and they do so in some woefully uninspiring death animations. It is perhaps indicative of a lack of confidence that the game maker's allow you several different weapons almost immediately and throw you quickly into raging firefights - no time is risked with a measured build-up.\n",
      "\n",
      "By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "\n",
      "There is a real thrill from doing battle with these legendary villains, and it is a testament to the power of the Bond universe that they can cut such a dash. But the in-game niggles, combined with a story and presentation that just do not feel sufficiently well thought-through, will make this a disappointment for most. Diehard fans of Bond will probably find enough here to make it a worthwhile purchase and try to ignore the failings. The game is weak, not completely unplayable. Then again, 007 fanatics may also take umbrage at the cavalier blending of characters from different eras. Given James Bond's healthy pedigree in past games, there is every reason to hope that this is just a blip, a commendable idea that just has not worked, that will be rectified when the character inevitably makes his return.\n",
      "\n",
      "GoldenEye: Rogue Agent is out now\n",
      "\n",
      "['BBC News Summary/BBC News Summary/News Articles/entertainment/050.txt', 'BBC News Summary/BBC News Summary/News Articles/entertainment/132.txt', 'BBC News Summary/BBC News Summary/News Articles/entertainment/017.txt', 'BBC News Summary/BBC News Summary/News Articles/entertainment/296.txt']\n"
     ]
    }
   ],
   "source": [
    "#Examplary text. The structure of the read file is: articles[category_no][document_no]. \n",
    "print(categorized_articles[0][0])\n",
    "print(file_paths[508:512])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) **Indexing** (preprocessing and indexing options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mono/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "from typing import Union\n",
    "import nltk\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import sklearn\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter, defaultdict\n",
    "from tabulate import tabulate\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten list to get uncategorized collection \n",
    "def flatten(lists) -> list: \n",
    "    return [element for sublist in lists for element in sublist]\n",
    "\n",
    "articles = flatten(categorized_articles)\n",
    "N = len(articles)\n",
    "dict_path_to_articleID = {path:i for i, path in enumerate(file_paths)}\n",
    "def map_path_to_articleID(path):\n",
    "    path = os.path.normpath(path)\n",
    "    return dict_path_to_articleID.get(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverted Index Structure \n",
    " \n",
    "Each term points to a dictionary of document identifier and the term frequency in the document.\n",
    "\n",
    "t1 -> {doc1: TF, doc5: TF, ...}\\\n",
    "t2 -> {doc7: TF, doc8: TF, ...}\\\n",
    "...\n",
    "t2 -> [DF, {doc7: [TF_(t2, doc7), {s1: TF, s4: TF, ...}], doc8: [TF_(t2, doc8), {s2: TF, s4: TF, ...}], ...}]\\\n",
    "\n",
    "use class structure\n",
    "\n",
    "TODO: \n",
    "* Optimize structure?\n",
    "    * Is there a more efficient way? \n",
    "    * Add maybe pointers to sentences and their term frequency? -> Faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_width = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TermFrequencies: \n",
    "    def __init__(self) -> None:\n",
    "        self.tf_d_t = 0\n",
    "        self.sent_tf = list()\n",
    "\n",
    "    def add_sentence(self, sent_number, term_frequency):\n",
    "        self.sent_tf.append((sent_number, term_frequency))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        padding = 5 - len(str(self.tf_d_t))\n",
    "        return f'TF_d_t: {self.tf_d_t}{\" \" * padding}TF_per_sentence: {self.sent_tf}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndexEntry:\n",
    "    def __init__(self) -> None:\n",
    "        self.df_term = 0\n",
    "        self.term_dict = defaultdict(TermFrequencies)\n",
    "    \n",
    "    def get_document(self, document):\n",
    "        return self.term_dict.get(document, None)\n",
    "\n",
    "    def get_or_default_document(self, document):\n",
    "        return self.term_dict[document]\n",
    "\n",
    "    def update_document(self, document, new_value):\n",
    "        self.term_dict[document] = new_value\n",
    "    \n",
    "    def __repr__(self):\n",
    "        out = f'Document Frequency: {self.df_term}\\n {\" \" * (max_width+2)} Term frequencies:\\n'\n",
    "        for doc_number, tfs in self.term_dict.items():\n",
    "            padding = 5 - len(str(doc_number))\n",
    "            out += f'{\" \" * (max_width + 3)} Doc {doc_number}{\" \" * padding}→ {tfs}\\n'\n",
    "        return out\n",
    "    \n",
    "    def calculate_df(self):\n",
    "        self.df_term = len(self.term_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndex:\n",
    "    def __init__(self, collection_size) -> None:\n",
    "        self.inverted_index = defaultdict(InvertedIndexEntry)\n",
    "        self.sentence_lengths = list()\n",
    "        self.indexing_time = 0\n",
    "        self.N = collection_size\n",
    "    \n",
    "    def __repr__(self):\n",
    "        out = f'Time to index: {self.indexing_time}\\nInverted Index:\\n'\n",
    "        for term, entry in self.inverted_index.items():\n",
    "            padding = max_width - len(term)\n",
    "            out += f'{term} {\" \" * padding} → {entry}\\n'\n",
    "        return out\n",
    "\n",
    "    def get_or_default(self, term, document):\n",
    "        return self.inverted_index[term].get_or_default_document(document)\n",
    "    \n",
    "    def update(self, term, document, new_value):\n",
    "        self.inverted_index[term].update_document(document, new_value)\n",
    "    \n",
    "    def set_indexing_time(self, indexing_time):\n",
    "        self.indexing_time = indexing_time\n",
    "    \n",
    "    def calculate_dfs(self):\n",
    "        for entry in self.inverted_index.values():\n",
    "            entry.calculate_df()  \n",
    "    \n",
    "    def get_sentence_lengths(self, document):\n",
    "        return self.sentence_lengths[document]\n",
    "\n",
    "    def get_document_info(self, document):          \n",
    "        info = {'Vocabulary': [], 'DF_t': [], 'TF_d_t': [], 'TF/sentence': []}\n",
    "        for term, entry in self.inverted_index.items():\n",
    "            doc_tfs = entry.get_document(document)\n",
    "            if doc_tfs == None:\n",
    "                continue\n",
    "            info['Vocabulary'].append(term)\n",
    "            info['DF_t'].append(entry.df_term)\n",
    "            info['TF_d_t'].append(doc_tfs.tf_d_t)\n",
    "            info['TF/sentence'].append(doc_tfs.sent_tf)\n",
    "        return info\n",
    "    \n",
    "    def doc_to_string(self, document):\n",
    "        out = f'Document {document} vocabulary and term frequencies:\\n'\n",
    "        info = self.get_document_info(document)\n",
    "        table = zip(*info.values())\n",
    "        headers = info.keys()\n",
    "        return out + tabulate(table, headers, tablefmt=\"pretty\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "indexing(D,args)\n",
    "    @input document collection D and optional arguments on text preprocessing\n",
    "\n",
    "    @behavior preprocesses the collection and, using existing libraries, \n",
    "    builds an inverted index with the relevant statistics for the subsequent summarization functions\n",
    "    \n",
    "    @output pair with the inverted index I and indexing time\n",
    "'''\n",
    "def indexing(articles, args=None) -> InvertedIndex:\n",
    "    start_time = time.time()\n",
    "    inverted_index = InvertedIndex(len(articles))\n",
    "\n",
    "    # tokenizer split words and keep hyphons e.g. state-of-the-art\n",
    "    tokenizer = RegexpTokenizer(r'[\\w|-]+')\n",
    "\n",
    "    # loop through collection \n",
    "    for article_id, article in enumerate(articles): \n",
    "        # split into sentences\n",
    "        sents = nltk.sent_tokenize(article)\n",
    "        # remove title (not needed for summarization task)\n",
    "        sents = sents[1:]\n",
    "        # save words per sent in list \n",
    "        tokenized_sentences = [tokenizer.tokenize(sent.lower()) for sent in sents]\n",
    "        # calculate length of the sentences in the article\n",
    "        sent_lengths = [len(sentence_terms) for sentence_terms in tokenized_sentences]\n",
    "        inverted_index.sentence_lengths.append(sent_lengths)\n",
    "        # count the term frequencies per sentence\n",
    "        term_counter_per_sent = [Counter(sentence_terms) for sentence_terms in tokenized_sentences]\n",
    "        for sent_number, term_counter in enumerate(term_counter_per_sent):\n",
    "            for term in term_counter: \n",
    "                tf = term_counter[term]\n",
    "                term_document_tfs = inverted_index.get_or_default(term, article_id)\n",
    "                term_document_tfs.tf_d_t += tf \n",
    "                term_document_tfs.add_sentence(sent_number, tf)\n",
    "                inverted_index.update(term, article_id, term_document_tfs)\n",
    "    inverted_index.calculate_dfs()\n",
    "    end_time = time.time()\n",
    "    indexing_time = end_time - start_time\n",
    "    inverted_index.set_indexing_time(indexing_time)\n",
    "    return inverted_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = 'Title. The little white little rabbit. The person played with the ball.'\n",
    "s1 = 'Title. The white rabbit\\'s ball. Rabbit rabbit ball rabbit.'\n",
    "s2 = 'Title.  White, the little white rabbit. Little, little.'\n",
    "test = [s0, s1, s2]\n",
    "I_test = indexing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to index: 0.0060422420501708984\n",
      "Inverted Index:\n",
      "the                   → Document Frequency: 3\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 3    TF_per_sentence: [(0, 1), (1, 2)]\n",
      "                        Doc 1    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "                        Doc 2    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "\n",
      "little                → Document Frequency: 2\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 2    TF_per_sentence: [(0, 2)]\n",
      "                        Doc 2    → TF_d_t: 3    TF_per_sentence: [(0, 1), (1, 2)]\n",
      "\n",
      "white                 → Document Frequency: 3\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "                        Doc 1    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "                        Doc 2    → TF_d_t: 2    TF_per_sentence: [(0, 2)]\n",
      "\n",
      "rabbit                → Document Frequency: 3\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "                        Doc 1    → TF_d_t: 4    TF_per_sentence: [(0, 1), (1, 3)]\n",
      "                        Doc 2    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "\n",
      "person                → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "\n",
      "played                → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "\n",
      "with                  → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "\n",
      "ball                  → Document Frequency: 2\n",
      "                        Term frequencies:\n",
      "                        Doc 0    → TF_d_t: 1    TF_per_sentence: [(1, 1)]\n",
      "                        Doc 1    → TF_d_t: 2    TF_per_sentence: [(0, 1), (1, 1)]\n",
      "\n",
      "s                     → Document Frequency: 1\n",
      "                        Term frequencies:\n",
      "                        Doc 1    → TF_d_t: 1    TF_per_sentence: [(0, 1)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(I_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 2 vocabulary and term frequencies:\n",
      "+------------+------+--------+------------------+\n",
      "| Vocabulary | DF_t | TF_d_t |   TF/sentence    |\n",
      "+------------+------+--------+------------------+\n",
      "|    the     |  3   |   1    |     [(0, 1)]     |\n",
      "|   little   |  2   |   3    | [(0, 1), (1, 2)] |\n",
      "|   white    |  3   |   2    |     [(0, 2)]     |\n",
      "|   rabbit   |  3   |   1    |     [(0, 1)]     |\n",
      "+------------+------+--------+------------------+\n"
     ]
    }
   ],
   "source": [
    "print(I_test.doc_to_string(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = indexing(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32, 14, 27, 20, 40, 23, 29, 30, 18, 12, 31, 25, 16, 24, 24, 14, 23, 41, 37, 41, 31, 25, 21, 7, 17, 40, 6], [18, 18, 17, 12, 14, 10, 15, 7, 15, 32, 18, 15, 24, 18]]\n"
     ]
    }
   ],
   "source": [
    "print(I.sentence_lengths[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document None vocabulary and term frequencies:\n",
      "+------------+------+--------+-------------+\n",
      "| Vocabulary | DF_t | TF_d_t | TF/sentence |\n",
      "+------------+------+--------+-------------+\n",
      "+------------+------+--------+-------------+\n"
     ]
    }
   ],
   "source": [
    "document_path = 'BBC News Summary/BBC News Summary/News Articles\\\\business\\\\509.txt'\n",
    "print(I.doc_to_string(map_path_to_articleID(document_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization \n",
    "\n",
    "TF: \n",
    "* Document: Term frequencies are assessed on document level.\n",
    "* Sentence: Term frequencies are assessed on sentence level.\n",
    "\n",
    "IDF: Inverted document frequencies is assessed on collection level.\\\n",
    "\\\n",
    "Additional parameter \"N\" and \"article_id\". Is this allowed?\n",
    "\n",
    "TODO: \n",
    "* Evaluate choice and give reason: \n",
    "    * IDF on document level?\n",
    "    * TF on document level for sentences? \n",
    "* \"order\" parameter o\n",
    "* BM25\n",
    "* BERT embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_term(N, df_t, tf_t_d):\n",
    "    return (1 + math.log10(tf_t_d)) * math.log10(N/df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_value(d: dict, max_sent: int, reverse=False) -> dict: \n",
    "    return dict(sorted(d.items(), key=lambda item: item[1], reverse=reverse)[:max_sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(sentence: str, model, tokenizer, max_length=512) -> torch.tensor: \n",
    "    encoded_input = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True, max_length=max_length)\n",
    "    output = model(**encoded_input)\n",
    "    embedding = output[\"pooler_output\"].squeeze()\n",
    "    # mean pooled embedding might be better\n",
    "    # mean_pooled_embedding = last_hidden_states.mean(axis=1)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "summarization(d,p,l,o,I,args)\n",
    "    @input document d (the index in I/D), maximum number of sentences (p) and/or characters (l), order\n",
    "    of presentation o (appearance in text vs relevance), inverted index I or the\n",
    "    collection D, and optional arguments on IR models\n",
    "\n",
    "    @behavior preprocesses d, assesses the relevance of each sentence in d against I ac-\n",
    "    cording to args, and presents them in accordance with p, l and o\n",
    "    \n",
    "    @output summary s of document d, i.e. ordered pairs (sentence position in d, score)\n",
    "'''\n",
    "def summarization(d: int, p: int, l: int, o: int, I_or_D: Union[InvertedIndex, list], **args) -> list:\n",
    "\n",
    "    if args['model'] != 'BERT':\n",
    "\n",
    "        ## if we receive the collection instead of the inverted index we must compute it first\n",
    "        if type(I_or_D) == list:\n",
    "            I = indexing(I_or_D)         \n",
    "        else: \n",
    "            I = I_or_D\n",
    "        \n",
    "        doc_info = I.get_document_info(d)\n",
    "        sentence_lengths = I.get_sentence_lengths(d)\n",
    "        term_doc_info = zip(*doc_info.values())    \n",
    "\n",
    "    scores = defaultdict(int)\n",
    "\n",
    "    if args['model'] == 'TF-IDF':\n",
    "        for term, df_t, tf_t_d, tf_per_sentence in term_doc_info:\n",
    "            rel_t_d = tf_idf_term(I.N, tf_t_d, df_t)\n",
    "            for sent_number, tf_s_t in tf_per_sentence:\n",
    "                scores[sent_number] += rel_t_d * (1 + math.log10(tf_s_t))\n",
    "        # normalization\n",
    "        for sent_number, score in scores.items():\n",
    "            scores[sent_number] = score / sentence_lengths[sent_number] \n",
    "    \n",
    "    elif args['model'] == 'BM25':\n",
    "        pass\n",
    "    \n",
    "    elif args['model'] == 'BERT':\n",
    "        document = I_or_D[d]\n",
    "        tokenizer = args['bert_tokenizer']\n",
    "        bert_model = args['bert_model']\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        bert_model.to(device)\n",
    "        scores = defaultdict(float)\n",
    "        # sentences \n",
    "        sentences = nltk.sent_tokenize(document)\n",
    "        sentences = sentences[1:]\n",
    "        num_sentences = len(sentences)\n",
    "        sent_embeddings = list()\n",
    "        # every sentences on its own, no padding needed, faster on cpu\n",
    "        # for gpu batches are better \n",
    "        for sent in sentences: \n",
    "            sent_embedding = get_embedding(sent, bert_model, tokenizer)\n",
    "            sent_embeddings.append(sent_embedding)\n",
    "        # document\n",
    "        doc_embedding = get_embedding(document, bert_model, tokenizer, max_length=256)\n",
    "        for sent_id in range(0, num_sentences): \n",
    "            sent_vec = sent_embeddings[sent_id]\n",
    "            score = torch.nn.functional.cosine_similarity(doc_embedding, sent_vec, dim=0)\n",
    "            scores[sent_id] = score.item()\n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Currently we only support the following models:\\n→ TF-IDF\\n→ BM-25\\n→ BERT\")\n",
    "    \n",
    "    sorted_scores = sort_by_value(scores, max_sent=p, reverse=True)\n",
    "    \n",
    "    return sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL DOCUMENT\n",
      "Bond game fails to shake or stir\n",
      "\n",
      "For gaming fans, the word GoldenEye evokes excited memories not only of the James Bond revival flick of 1995, but also the classic shoot-em-up that accompanied it and left N64 owners glued to their consoles for many an hour.\n",
      "\n",
      "Adopting that hallowed title somewhat backfires on this new game, for it fails to deliver on the promise of its name and struggles to generate the original's massive sense of fun. This however is not a sequel, nor does it relate to the GoldenEye film. You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6. Your new commander-in-chief is the portly Auric Goldfinger, last seen in 1964, but happily running around bent on world domination. With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "\n",
      "Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter. The notion is of course to add a novel dark edge to a 007 game, but the premise simply does not get the juices flowing like it needs to.\n",
      "\n",
      "Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise. This title lacks that aura, and when the Bond magic shines through, it feels like a lucky accident. The central problem is that the gameplay just is not good enough. Quite aside from the bizarre inability to jump, the even more bizarre glaring graphical bugs and dubious enemy AI, the levels simply are not put together with much style or imagination. Admittedly the competition has been tough, even in recent weeks, with the likes of Halo 2 and Half Life 2 triumphing in virtually every department. What the game is good at is enveloping you in noisy, dynamic scenes of violent chaos. As is the trend of late, you are made to feel like you are in the midst of a really messy and fraught encounter. Sadly that sense of action is outweighed by the difficulty of navigating and battling within the chaos, meaning that frustration is often the outcome. And irregular save points mean you have to backtrack each time you are killed. A minute red dot passes for a crosshair, although the collision-detection is so suspect that the difficulties of aiming weapons are compensated for. Shooting enemies from a distance can be tricky, and you will not always know you have picked them off, since dead enemies vanish literally before they have fully hit the floor, and they do so in some woefully uninspiring death animations. It is perhaps indicative of a lack of confidence that the game maker's allow you several different weapons almost immediately and throw you quickly into raging firefights - no time is risked with a measured build-up.\n",
      "\n",
      "By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "\n",
      "There is a real thrill from doing battle with these legendary villains, and it is a testament to the power of the Bond universe that they can cut such a dash. But the in-game niggles, combined with a story and presentation that just do not feel sufficiently well thought-through, will make this a disappointment for most. Diehard fans of Bond will probably find enough here to make it a worthwhile purchase and try to ignore the failings. The game is weak, not completely unplayable. Then again, 007 fanatics may also take umbrage at the cavalier blending of characters from different eras. Given James Bond's healthy pedigree in past games, there is every reason to hope that this is just a blip, a commendable idea that just has not worked, that will be rectified when the character inevitably makes his return.\n",
      "\n",
      "GoldenEye: Rogue Agent is out now\n",
      "\n",
      "SUMMARY\n",
      "8.89: This however is not a sequel, nor does it relate to the GoldenEye film.\n",
      "8.85: But the in-game niggles, combined with a story and presentation that just do not feel sufficiently well thought-through, will make this a disappointment for most.\n",
      "8.81: And irregular save points mean you have to backtrack each time you are killed.\n",
      "8.76: Admittedly the competition has been tough, even in recent weeks, with the likes of Halo 2 and Half Life 2 triumphing in virtually every department.\n",
      "8.68: GoldenEye: Rogue Agent is out now\n"
     ]
    }
   ],
   "source": [
    "article_id = 0\n",
    "print(\"ORIGINAL DOCUMENT\")\n",
    "print(articles[article_id])\n",
    "scores = summarization(d=0, p=5, l=1000, o=\"rel\", I_or_D=I, model='TF-IDF')\n",
    "\n",
    "print(\"SUMMARY\")\n",
    "sentences = nltk.sent_tokenize(articles[article_id])\n",
    "sentences = sentences[1:]\n",
    "for sent_id, score in scores.items(): \n",
    "    print(f\"{score:.2f}: {sentences[sent_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL DOCUMENT\n",
      "Bond game fails to shake or stir\n",
      "\n",
      "For gaming fans, the word GoldenEye evokes excited memories not only of the James Bond revival flick of 1995, but also the classic shoot-em-up that accompanied it and left N64 owners glued to their consoles for many an hour.\n",
      "\n",
      "Adopting that hallowed title somewhat backfires on this new game, for it fails to deliver on the promise of its name and struggles to generate the original's massive sense of fun. This however is not a sequel, nor does it relate to the GoldenEye film. You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6. Your new commander-in-chief is the portly Auric Goldfinger, last seen in 1964, but happily running around bent on world domination. With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "\n",
      "Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter. The notion is of course to add a novel dark edge to a 007 game, but the premise simply does not get the juices flowing like it needs to.\n",
      "\n",
      "Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise. This title lacks that aura, and when the Bond magic shines through, it feels like a lucky accident. The central problem is that the gameplay just is not good enough. Quite aside from the bizarre inability to jump, the even more bizarre glaring graphical bugs and dubious enemy AI, the levels simply are not put together with much style or imagination. Admittedly the competition has been tough, even in recent weeks, with the likes of Halo 2 and Half Life 2 triumphing in virtually every department. What the game is good at is enveloping you in noisy, dynamic scenes of violent chaos. As is the trend of late, you are made to feel like you are in the midst of a really messy and fraught encounter. Sadly that sense of action is outweighed by the difficulty of navigating and battling within the chaos, meaning that frustration is often the outcome. And irregular save points mean you have to backtrack each time you are killed. A minute red dot passes for a crosshair, although the collision-detection is so suspect that the difficulties of aiming weapons are compensated for. Shooting enemies from a distance can be tricky, and you will not always know you have picked them off, since dead enemies vanish literally before they have fully hit the floor, and they do so in some woefully uninspiring death animations. It is perhaps indicative of a lack of confidence that the game maker's allow you several different weapons almost immediately and throw you quickly into raging firefights - no time is risked with a measured build-up.\n",
      "\n",
      "By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "\n",
      "There is a real thrill from doing battle with these legendary villains, and it is a testament to the power of the Bond universe that they can cut such a dash. But the in-game niggles, combined with a story and presentation that just do not feel sufficiently well thought-through, will make this a disappointment for most. Diehard fans of Bond will probably find enough here to make it a worthwhile purchase and try to ignore the failings. The game is weak, not completely unplayable. Then again, 007 fanatics may also take umbrage at the cavalier blending of characters from different eras. Given James Bond's healthy pedigree in past games, there is every reason to hope that this is just a blip, a commendable idea that just has not worked, that will be rectified when the character inevitably makes his return.\n",
      "\n",
      "GoldenEye: Rogue Agent is out now\n",
      "\n",
      "SUMMARY\n",
      "0.94: There is a real thrill from doing battle with these legendary villains, and it is a testament to the power of the Bond universe that they can cut such a dash.\n",
      "0.93: The notion is of course to add a novel dark edge to a 007 game, but the premise simply does not get the juices flowing like it needs to.\n",
      "0.93: Adopting that hallowed title somewhat backfires on this new game, for it fails to deliver on the promise of its name and struggles to generate the original's massive sense of fun.\n",
      "0.93: You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6.\n",
      "0.92: With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n"
     ]
    }
   ],
   "source": [
    "article_id = 0\n",
    "print(\"ORIGINAL DOCUMENT\")\n",
    "print(articles[article_id])\n",
    "scores = summarization(d=0, p=5, l=1000, o=\"rel\", I_or_D=articles, model='BERT', bert_model=bert_model, bert_tokenizer=bert_tokenizer)\n",
    "\n",
    "print(\"SUMMARY\")\n",
    "sentences = nltk.sent_tokenize(articles[article_id])\n",
    "sentences = sentences[1:]\n",
    "for sent_id, score in scores.items(): \n",
    "    print(f\"{score:.2f}: {sentences[sent_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Extraction\n",
    "\n",
    "Calculates the keywords based on the tf-idf of the document.\\\n",
    "\\\n",
    "Additional parameter \"N\" and \"article_id\". Is this allowed?\n",
    "\n",
    "Parameter for including only noun phrases. \n",
    "\n",
    "TODO:\n",
    "* Nouns: just unigrams or also bigrams?\n",
    "* BM25\n",
    "* BERT embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import Senna\n",
    "from nltk.tag import SennaChunkTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkeyword extraction(d,p,I,args)\\n    @input document d, maximum number of keywords p, inverted index I, and op-\\n    tional arguments on IR model choices\\n\\n    @behavior extracts the top informative p keywords in d against I according to args\\n    \\n    @output ordered set of p keywords\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "keyword extraction(d,p,I,args)\n",
    "    @input document d, maximum number of keywords p, inverted index I, and op-\n",
    "    tional arguments on IR model choices\n",
    "\n",
    "    @behavior extracts the top informative p keywords in d against I according to args\n",
    "    \n",
    "    @output ordered set of p keywords\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inverted_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc_tf_idf[word]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(doc_tf_idf)\n\u001b[0;32m---> 49\u001b[0m keyword_extraction(articles[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m10\u001b[39m, \u001b[43minverted_index\u001b[49m, \u001b[38;5;28mlen\u001b[39m(articles), \u001b[38;5;241m0\u001b[39m, use_only_nouns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inverted_index' is not defined"
     ]
    }
   ],
   "source": [
    "def keyword_extraction(article: str, max_num: int, inverted_index: dict, N: int, article_id: int, use_only_nouns=False, args=None) -> dict: \n",
    "    # tokenizer split words and keep hyphons e.g. state-of-the-art\n",
    "    tokenizer = RegexpTokenizer(r'[\\w|-]+')\n",
    "    # tokenize sentences\n",
    "    sents = nltk.sent_tokenize(article)\n",
    "    # remove title (not needed for summarization task)\n",
    "    sents = sents[1:]\n",
    "    \n",
    "    # get words per document\n",
    "    # either use all words or only nouns\n",
    "    if use_only_nouns: \n",
    "        #tagger = SennaChunkTagger('/usr/share/senna-v3.0/senna')\n",
    "        words_per_doc = list()\n",
    "        for sent in sents: \n",
    "            words = tokenizer.tokenize(sent.lower())\n",
    "            \n",
    "            # senna chunk tagging of nouns \n",
    "            # not sure if needed, just a test\n",
    "            #tags = tagger.tag(words)\n",
    "            #chunks = list(tagger.bio_to_chunks(tags, chunk_type='N'))\n",
    "\n",
    "            # nltk pos tag \n",
    "            tagged_words = nltk.pos_tag(words)\n",
    "            named_entities = nltk.ne_chunk(tagged_words)\n",
    "            for word, tag in named_entities:\n",
    "                if 'NN' in tag: \n",
    "                    words_per_doc.append(word)\n",
    "    else: \n",
    "        words_per_sent = [set(tokenizer.tokenize(sent.lower())) for sent in sents]\n",
    "        words_per_doc = flatten(words_per_sent)\n",
    "\n",
    "    doc_tf_idf = defaultdict(str)\n",
    "    for word in words_per_doc: \n",
    "        # inverse document frequency (idf)\n",
    "        idf = math.log10(N/len(inverted_index[word]))\n",
    "        # term frequency (tf) by document\n",
    "        # get it from inverted index \n",
    "        doc_tf = inverted_index[word][article_id]\n",
    "        doc_tf = 1 + math.log10(doc_tf)\n",
    "\n",
    "        # tf-idf for the document \n",
    "        doc_tf_idf[word] = doc_tf * idf\n",
    "    \n",
    "    doc_tf_idf = dict(sorted(doc_tf_idf.items(), key=lambda item: item[1], reverse=True)[:max_num])\n",
    "    for word in doc_tf_idf: \n",
    "        print(f\"{word}: {doc_tf_idf[word]}\")\n",
    "    print(doc_tf_idf)\n",
    "\n",
    "keyword_extraction(articles[0], 10, inverted_index, len(articles), 0, use_only_nouns=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "TODO:\n",
    "* Implement evaluation\n",
    "* Evaluation:\n",
    "    * Statistics \n",
    "    * F-meassure\n",
    "    * Recall-precision-curve\n",
    "    * MAP\n",
    "    * Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nevaluation(Sset,Rset,args)\\n    @input the set of summaries Sset produced from selected documents Dset ⊆ D\\n    (e.g. a single document, a category of documents, the whole collection),\\n    the corresponding reference extracts Rset, and optional arguments (evalu-\\n    ation, preprocessing, model options)\\n\\n    @behavior assesses the produced summaries against the reference ones using the tar-\\n    get evaluation criteria\\n\\n    @output evaluation statistics, including F-measuring at predefined p-or-l summary\\n    limits, recall-and-precision curves, MAP, and efficiency\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "evaluation(Sset,Rset,args)\n",
    "    @input the set of summaries Sset produced from selected documents Dset ⊆ D\n",
    "    (e.g. a single document, a category of documents, the whole collection),\n",
    "    the corresponding reference extracts Rset, and optional arguments (evalu-\n",
    "    ation, preprocessing, model options)\n",
    "\n",
    "    @behavior assesses the produced summaries against the reference ones using the tar-\n",
    "    get evaluation criteria\n",
    "\n",
    "    @output evaluation statistics, including F-measuring at predefined p-or-l summary\n",
    "    limits, recall-and-precision curves, MAP, and efficiency\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(S: list, R: list, args=None) -> list:\n",
    "    # do evaluation... \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) **Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.1 Summarization solution: results for a given document*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bond game fails to shake or stir\n",
      "\n",
      "For gaming fans, the word GoldenEye evokes excited memories not only of the James Bond revival flick of 1995, but also the classic shoot-em-up that accompanied it and left N64 owners glued to their consoles for many an hour.\n",
      "\n",
      "Adopting that hallowed title somewhat backfires on this new game, for it fails to deliver on the promise of its name and struggles to generate the original's massive sense of fun. This however is not a sequel, nor does it relate to the GoldenEye film. You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6. Your new commander-in-chief is the portly Auric Goldfinger, last seen in 1964, but happily running around bent on world domination. With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "\n",
      "Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter. The notion is of course to add a novel dark edge to a 007 game, but the premise simply does not get the juices flowing like it needs to.\n",
      "\n",
      "Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise. This title lacks that aura, and when the Bond magic shines through, it feels like a lucky accident. The central problem is that the gameplay just is not good enough. Quite aside from the bizarre inability to jump, the even more bizarre glaring graphical bugs and dubious enemy AI, the levels simply are not put together with much style or imagination. Admittedly the competition has been tough, even in recent weeks, with the likes of Halo 2 and Half Life 2 triumphing in virtually every department. What the game is good at is enveloping you in noisy, dynamic scenes of violent chaos. As is the trend of late, you are made to feel like you are in the midst of a really messy and fraught encounter. Sadly that sense of action is outweighed by the difficulty of navigating and battling within the chaos, meaning that frustration is often the outcome. And irregular save points mean you have to backtrack each time you are killed. A minute red dot passes for a crosshair, although the collision-detection is so suspect that the difficulties of aiming weapons are compensated for. Shooting enemies from a distance can be tricky, and you will not always know you have picked them off, since dead enemies vanish literally before they have fully hit the floor, and they do so in some woefully uninspiring death animations. It is perhaps indicative of a lack of confidence that the game maker's allow you several different weapons almost immediately and throw you quickly into raging firefights - no time is risked with a measured build-up.\n",
      "\n",
      "By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "\n",
      "There is a real thrill from doing battle with these legendary villains, and it is a testament to the power of the Bond universe that they can cut such a dash. But the in-game niggles, combined with a story and presentation that just do not feel sufficiently well thought-through, will make this a disappointment for most. Diehard fans of Bond will probably find enough here to make it a worthwhile purchase and try to ignore the failings. The game is weak, not completely unplayable. Then again, 007 fanatics may also take umbrage at the cavalier blending of characters from different eras. Given James Bond's healthy pedigree in past games, there is every reason to hope that this is just a blip, a commendable idea that just has not worked, that will be rectified when the character inevitably makes his return.\n",
      "\n",
      "GoldenEye: Rogue Agent is out now\n",
      "\n",
      "0.2495193303958334: By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "0.21019493577531412: Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter.\n",
      "0.20079836196045564: You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6.\n",
      "0.1995382299926325: With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "0.19033491063190966: Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{19: 0.2495193303958334,\n",
       " 5: 0.21019493577531412,\n",
       " 2: 0.20079836196045564,\n",
       " 4: 0.1995382299926325,\n",
       " 7: 0.19033491063190966}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code, statistics and/or charts here\n",
    "article_id = 0\n",
    "print(articles[article_id])\n",
    "summarization(articles[article_id], num_sent=5, order=\"rel\", inverted_index=inverted_index, N=len(articles), article_id=article_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.2 IR models (TF-IDF, BM25 and EBRT)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.3 Reciprocal rank funsion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.4 Maximal Marginal Relevance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) **Keyword extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bond game fails to shake or stir\n",
      "\n",
      "For gaming fans, the word GoldenEye evokes excited memories not only of the James Bond revival flick of 1995, but also the classic shoot-em-up that accompanied it and left N64 owners glued to their consoles for many an hour.\n",
      "\n",
      "Adopting that hallowed title somewhat backfires on this new game, for it fails to deliver on the promise of its name and struggles to generate the original's massive sense of fun. This however is not a sequel, nor does it relate to the GoldenEye film. You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6. Your new commander-in-chief is the portly Auric Goldfinger, last seen in 1964, but happily running around bent on world domination. With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "\n",
      "Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter. The notion is of course to add a novel dark edge to a 007 game, but the premise simply does not get the juices flowing like it needs to.\n",
      "\n",
      "Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise. This title lacks that aura, and when the Bond magic shines through, it feels like a lucky accident. The central problem is that the gameplay just is not good enough. Quite aside from the bizarre inability to jump, the even more bizarre glaring graphical bugs and dubious enemy AI, the levels simply are not put together with much style or imagination. Admittedly the competition has been tough, even in recent weeks, with the likes of Halo 2 and Half Life 2 triumphing in virtually every department. What the game is good at is enveloping you in noisy, dynamic scenes of violent chaos. As is the trend of late, you are made to feel like you are in the midst of a really messy and fraught encounter. Sadly that sense of action is outweighed by the difficulty of navigating and battling within the chaos, meaning that frustration is often the outcome. And irregular save points mean you have to backtrack each time you are killed. A minute red dot passes for a crosshair, although the collision-detection is so suspect that the difficulties of aiming weapons are compensated for. Shooting enemies from a distance can be tricky, and you will not always know you have picked them off, since dead enemies vanish literally before they have fully hit the floor, and they do so in some woefully uninspiring death animations. It is perhaps indicative of a lack of confidence that the game maker's allow you several different weapons almost immediately and throw you quickly into raging firefights - no time is risked with a measured build-up.\n",
      "\n",
      "By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "\n",
      "There is a real thrill from doing battle with these legendary villains, and it is a testament to the power of the Bond universe that they can cut such a dash. But the in-game niggles, combined with a story and presentation that just do not feel sufficiently well thought-through, will make this a disappointment for most. Diehard fans of Bond will probably find enough here to make it a worthwhile purchase and try to ignore the failings. The game is weak, not completely unplayable. Then again, 007 fanatics may also take umbrage at the cavalier blending of characters from different eras. Given James Bond's healthy pedigree in past games, there is every reason to hope that this is just a blip, a commendable idea that just has not worked, that will be rectified when the character inevitably makes his return.\n",
      "\n",
      "GoldenEye: Rogue Agent is out now\n",
      "\n",
      "goldfinger: 4.354976755313726\n",
      "goldeneye: 3.7342276913546106\n",
      "bond: 3.6992505932864606\n",
      "masterminds: 3.3473300153169503\n",
      "commander-in-chief: 3.3473300153169503\n",
      "juices: 3.3473300153169503\n",
      "nightfire: 3.3473300153169503\n",
      "aura: 3.3473300153169503\n",
      "crosshair: 3.3473300153169503\n",
      "firefights: 3.3473300153169503\n",
      "{'goldfinger': 4.354976755313726, 'goldeneye': 3.7342276913546106, 'bond': 3.6992505932864606, 'masterminds': 3.3473300153169503, 'commander-in-chief': 3.3473300153169503, 'juices': 3.3473300153169503, 'nightfire': 3.3473300153169503, 'aura': 3.3473300153169503, 'crosshair': 3.3473300153169503, 'firefights': 3.3473300153169503}\n"
     ]
    }
   ],
   "source": [
    "#code, statistics and/or charts here\n",
    "article_id = 0\n",
    "print(articles[article_id])\n",
    "keyword_extraction(articles[0], 10, inverted_index, len(articles), 0, use_only_nouns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D) **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Part II: questions materials (optional)</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** Corpus *D* and summaries *S* description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** Summarization performance for the overall and category-conditional corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**...** (additional questions with empirical results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>END</H3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
