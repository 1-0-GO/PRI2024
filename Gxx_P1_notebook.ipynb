{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>PRI 2023/24: first project delivery</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GROUP 11**\n",
    "- Francisco Martins, 99068\n",
    "- Tunahan Güneş, 108108\n",
    "- Sebastian Weidinger, 111612"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Part I: demo of facilities</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    texts = []\n",
    "    for folder in os.listdir(path):\n",
    "        category_path = os.path.join(path, folder)\n",
    "        texts.append([])\n",
    "        for file in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, file)\n",
    "            with open(file_path, \"r\", errors=\"ignore\") as f:\n",
    "                text = f.read()\n",
    "                texts[-1].append(text)\n",
    "                \n",
    "    print(\"Number of Categories:\",len(os.listdir(path)))\n",
    "    for i in range(len(os.listdir(path))):\n",
    "        print(\"Number of Articles in\", \"'\"+os.listdir(path)[i]+\"'\", \"Category:\",len(texts[i]))\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: BBC News Summary/BBC News Summary/News Articles\n",
      "Number of Categories: 5\n",
      "Number of Articles in 'tech' Category: 401\n",
      "Number of Articles in 'entertainment' Category: 386\n",
      "Number of Articles in 'sport' Category: 511\n",
      "Number of Articles in 'business' Category: 510\n",
      "Number of Articles in 'politics' Category: 417\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(\"BBC News Summary\", \"BBC News Summary\", \"News Articles\")\n",
    "print(\"Dataset path:\", dataset_path)\n",
    "categorized_articles = read_files(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bond game fails to shake or stir\n",
      "\n",
      "For gaming fans, the word GoldenEye evokes excited memories not only of the James Bond revival flick of 1995, but also the classic shoot-em-up that accompanied it and left N64 owners glued to their consoles for many an hour.\n",
      "\n",
      "Adopting that hallowed title somewhat backfires on this new game, for it fails to deliver on the promise of its name and struggles to generate the original's massive sense of fun. This however is not a sequel, nor does it relate to the GoldenEye film. You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6. Your new commander-in-chief is the portly Auric Goldfinger, last seen in 1964, but happily running around bent on world domination. With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "\n",
      "Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter. The notion is of course to add a novel dark edge to a 007 game, but the premise simply does not get the juices flowing like it needs to.\n",
      "\n",
      "Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise. This title lacks that aura, and when the Bond magic shines through, it feels like a lucky accident. The central problem is that the gameplay just is not good enough. Quite aside from the bizarre inability to jump, the even more bizarre glaring graphical bugs and dubious enemy AI, the levels simply are not put together with much style or imagination. Admittedly the competition has been tough, even in recent weeks, with the likes of Halo 2 and Half Life 2 triumphing in virtually every department. What the game is good at is enveloping you in noisy, dynamic scenes of violent chaos. As is the trend of late, you are made to feel like you are in the midst of a really messy and fraught encounter. Sadly that sense of action is outweighed by the difficulty of navigating and battling within the chaos, meaning that frustration is often the outcome. And irregular save points mean you have to backtrack each time you are killed. A minute red dot passes for a crosshair, although the collision-detection is so suspect that the difficulties of aiming weapons are compensated for. Shooting enemies from a distance can be tricky, and you will not always know you have picked them off, since dead enemies vanish literally before they have fully hit the floor, and they do so in some woefully uninspiring death animations. It is perhaps indicative of a lack of confidence that the game maker's allow you several different weapons almost immediately and throw you quickly into raging firefights - no time is risked with a measured build-up.\n",
      "\n",
      "By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "\n",
      "There is a real thrill from doing battle with these legendary villains, and it is a testament to the power of the Bond universe that they can cut such a dash. But the in-game niggles, combined with a story and presentation that just do not feel sufficiently well thought-through, will make this a disappointment for most. Diehard fans of Bond will probably find enough here to make it a worthwhile purchase and try to ignore the failings. The game is weak, not completely unplayable. Then again, 007 fanatics may also take umbrage at the cavalier blending of characters from different eras. Given James Bond's healthy pedigree in past games, there is every reason to hope that this is just a blip, a commendable idea that just has not worked, that will be rectified when the character inevitably makes his return.\n",
      "\n",
      "GoldenEye: Rogue Agent is out now\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Examplary text. The structure of the read file is: articles[category_no][document_no]. \n",
    "print(categorized_articles[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) **Indexing** (preprocessing and indexing options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from typing import Union\n",
    "import nltk\n",
    "import numpy as np\n",
    "import math\n",
    "import sklearn\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten list to get uncategorized collection \n",
    "def flatten(lists) -> list: \n",
    "    return [element for sublist in lists for element in sublist]\n",
    "\n",
    "articles = flatten(categorized_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverted Index Structure \n",
    " \n",
    "Each term points to a dictionary of document identifier and the term frequency in the document.\n",
    "\n",
    "t1 -> {doc1: TF, doc5: TF, ...}\\\n",
    "t2 -> {doc7: TF, doc8: TF, ...}\\\n",
    "...\n",
    "t2 -> [DF, {doc7: [TF_(t2, doc7), {s1: TF, s4: TF, ...}], doc8: [TF_(t2, doc8), {s2: TF, s4: TF, ...}], ...}]\\\n",
    "\n",
    "use class structure\n",
    "\n",
    "TODO: \n",
    "* Optimize structure?\n",
    "    * Is there a more efficient way? \n",
    "    * Add maybe pointers to sentences and their term frequency? -> Faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TermFrequencies: \n",
    "    def __init__(self, tf_d_t: int, sent_tf: dict) -> None:\n",
    "        self.tf_d_t = 0\n",
    "        self.sent_tf = dict()\n",
    "\n",
    "    def get_sentence(self, s):\n",
    "        return self.sent_tf.get(s, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndexInfo:\n",
    "    def __init__(self) -> None:\n",
    "        self.df_term = 0\n",
    "        self.term_dict = dict()\n",
    "\n",
    "    def get_document(self, d):\n",
    "        return self.term_dict.get(d, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m tf_s:\n\u001b[1;32m     19\u001b[0m                 sent_tf[sent_id] \u001b[38;5;241m=\u001b[39m tf_s[term]\n\u001b[0;32m---> 22\u001b[0m \u001b[43mindexing2\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticles\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[63], line 15\u001b[0m, in \u001b[0;36mindexing2\u001b[0;34m(articles, args)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent_id, terms \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(terms_per_sent): \n\u001b[1;32m     14\u001b[0m     tf_s \u001b[38;5;241m=\u001b[39m Counter(terms)\n\u001b[0;32m---> 15\u001b[0m     sent_tf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m()\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m tf_s:\n\u001b[1;32m     19\u001b[0m         sent_tf[sent_id] \u001b[38;5;241m=\u001b[39m tf_s[term]\n",
      "Cell \u001b[0;32mIn[63], line 15\u001b[0m, in \u001b[0;36mindexing2\u001b[0;34m(articles, args)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent_id, terms \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(terms_per_sent): \n\u001b[1;32m     14\u001b[0m     tf_s \u001b[38;5;241m=\u001b[39m Counter(terms)\n\u001b[0;32m---> 15\u001b[0m     sent_tf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m()\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m tf_s:\n\u001b[1;32m     19\u001b[0m         sent_tf[sent_id] \u001b[38;5;241m=\u001b[39m tf_s[term]\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def indexing2(articles, args=None) -> Union[dict, int]: \n",
    "    start_time = time.time()\n",
    "    inverted_index = dict()\n",
    "    # tokenizer split words and keep hyphons e.g. state-of-the-art\n",
    "    tokenizer = RegexpTokenizer(r'[\\w|-]+')\n",
    "\n",
    "    for article_id, article in enumerate(articles):\n",
    "        # split into sentences\n",
    "        sents = nltk.sent_tokenize(article)\n",
    "\n",
    "        terms_per_sent = [tokenizer.tokenize(sent.lower()) for sent in sents]\n",
    "\n",
    "        for sent_id, terms in enumerate(terms_per_sent): \n",
    "            tf_s = Counter(terms)\n",
    "            for term in tf_s:\n",
    "                if term not in inverted_index: \n",
    "                    index_info_of_term = InvertedIndexInfo()\n",
    "                else: \n",
    "                    index_info_of_term = inverted_index[term]\n",
    "                if \n",
    "                \n",
    "\n",
    "                    \n",
    "\n",
    "indexing2(articles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing time: 1.0544142723083496 seconds\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "indexing(D,args)\n",
    "    @input document collection D and optional arguments on text preprocessing\n",
    "\n",
    "    @behavior preprocesses the collection and, using existing libraries, \n",
    "    builds an inverted index with the relevant statistics for the subsequent summarization functions\n",
    "    \n",
    "    @output pair with the inverted index I and indexing time\n",
    "'''\n",
    "\n",
    "def indexing(articles, args=None) -> Union[dict, int]:\n",
    "    inverted_index = defaultdict(dict)\n",
    "    start_time = time.time()\n",
    "    # tokenizer split words and keep hyphons e.g. state-of-the-art\n",
    "    tokenizer = RegexpTokenizer(r'[\\w|-]+')\n",
    "\n",
    "    # loop through collection \n",
    "    for article_id, article in enumerate(articles): \n",
    "        # split into sentences\n",
    "        sents = nltk.sent_tokenize(article)\n",
    "        # remove title (not needed for summarization task)\n",
    "        sents = sents[1:]\n",
    "        # save words per sent in list \n",
    "        words_per_sent = [tokenizer.tokenize(sent.lower()) for sent in sents]\n",
    "        # add words to inverted index \n",
    "        word_counter_doc = Counter(flatten(words_per_sent))\n",
    "        for word in word_counter_doc: \n",
    "            tf = word_counter_doc[word]\n",
    "            inverted_index[word][article_id] = tf\n",
    "    end_time = time.time()\n",
    "    indexing_time = end_time - start_time\n",
    "    return inverted_index, indexing_time\n",
    "\n",
    "inverted_index, indexing_time = indexing(articles)\n",
    "print(f\"indexing time: {indexing_time} seconds\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization \n",
    "\n",
    "TF: \n",
    "* Document: Term frequencies are assessed on document level.\n",
    "* Sentence: Term frequencies are assessed on sentence level.\n",
    "\n",
    "IDF: Inverted document frequencies is assessed on collection level.\\\n",
    "\\\n",
    "Additional parameter \"N\" and \"article_id\". Is this allowed?\n",
    "\n",
    "TODO: \n",
    "* Evaluate choice and give reason: \n",
    "    * IDF on document level?\n",
    "    * TF on document level for sentences? \n",
    "* \"order\" parameter o\n",
    "* BM25\n",
    "* BERT embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2495193303958334: By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "0.21019493577531412: Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter.\n",
      "0.20079836196045564: You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6.\n",
      "0.1995382299926325: With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "0.19033491063190966: Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{19: 0.2495193303958334,\n",
       " 5: 0.21019493577531412,\n",
       " 2: 0.20079836196045564,\n",
       " 4: 0.1995382299926325,\n",
       " 7: 0.19033491063190966}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "summarization(d,p,l,o,I,args)\n",
    "    @input document d, maximum number of sentences (p) and/or characters (l), order\n",
    "    of presentation o (appearance in text vs relevance), inverted index I or the\n",
    "    collection D, and optional arguments on IR models\n",
    "\n",
    "    @behavior preprocesses d, assesses the relevance of each sentence in d against I ac-\n",
    "    cording to args, and presents them in accordance with p, l and o\n",
    "    \n",
    "    @output summary s of document d, i.e. ordered pairs (sentence position in d, score)\n",
    "'''\n",
    "\n",
    "def summarization(article: str, num_sent: int, order: str, inverted_index: dict, N: int, article_id: int, args=None) -> list:\n",
    "    \n",
    "    # tokenizer split words and keep hyphons e.g. state-of-the-art\n",
    "    tokenizer = RegexpTokenizer(r'[\\w|-]+')\n",
    "    # tokenize sentences\n",
    "    sents = nltk.sent_tokenize(article)\n",
    "    # remove title (not needed for summarization task)\n",
    "    sents = sents[1:]\n",
    "    \n",
    "    # get words per sentence \n",
    "    words_per_sent = [set(tokenizer.tokenize(sent.lower())) for sent in sents]\n",
    "\n",
    "    # create sentence vector\n",
    "    sent_vecs = list()\n",
    "    for sent_id, words in enumerate(words_per_sent):\n",
    "        # term frequency (tf) by sentence \n",
    "        sent_tf = dict(Counter(words))\n",
    "        for word in sent_tf: \n",
    "            sent_tf[word] = 1 + math.log10(sent_tf[word]) \n",
    "\n",
    "        # create dense sentence vectors\n",
    "        # no need for idf (see lecture)\n",
    "        sent_vec = dict.fromkeys(inverted_index.keys(), 0)\n",
    "        sent_vec.update(sent_tf)\n",
    "        sent_vec = list(sent_vec.values())\n",
    "        sent_vecs.append(sent_vec)\n",
    "\n",
    "    # inverse document frequency (idf) and term frequency (tf) per document \n",
    "    words_per_doc = set(flatten(words_per_sent))\n",
    "    doc_tf_idf = defaultdict(str)\n",
    "    for word in words_per_doc: \n",
    "        # inverse document frequency (idf)\n",
    "        idf = math.log10(N/len(inverted_index[word]))\n",
    "        # term frequency (tf) by document\n",
    "        # get it from inverted index \n",
    "        doc_tf = inverted_index[word][article_id]\n",
    "        doc_tf = 1 + math.log10(doc_tf)\n",
    "\n",
    "        # tf-idf for the document \n",
    "        doc_tf_idf[word] = doc_tf * idf \n",
    "\n",
    "    # create document vector\n",
    "    doc_vec = dict.fromkeys(inverted_index.keys(), 0)\n",
    "    doc_vec.update(doc_tf_idf)\n",
    "    doc_vec = list(doc_vec.values())\n",
    "    \n",
    "    # cosine similarity \n",
    "    similarities = dict()\n",
    "    for sent_id, sent_vec in enumerate(sent_vecs): \n",
    "        similarity = sklearn.metrics.pairwise_distances([sent_vec, doc_vec], metric=\"cosine\")\n",
    "        similarities[sent_id] = 1-similarity[0][1]\n",
    "    similarities = dict(sorted(similarities.items(), key=lambda item: item[1], reverse=True)[:num_sent])\n",
    "\n",
    "    for sent_id in similarities: \n",
    "        print(f\"{similarities[sent_id]}: {sents[sent_id]}\")\n",
    "    return similarities  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Extraction\n",
    "\n",
    "Calculates the keywords based on the tf-idf of the document.\\\n",
    "\\\n",
    "Additional parameter \"N\" and \"article_id\". Is this allowed?\n",
    "\n",
    "Parameter for including only noun phrases. \n",
    "\n",
    "TODO:\n",
    "* Nouns: just unigrams or also bigrams?\n",
    "* BM25\n",
    "* BERT embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import Senna\n",
    "from nltk.tag import SennaChunkTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkeyword extraction(d,p,I,args)\\n    @input document d, maximum number of keywords p, inverted index I, and op-\\n    tional arguments on IR model choices\\n\\n    @behavior extracts the top informative p keywords in d against I according to args\\n    \\n    @output ordered set of p keywords\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "keyword extraction(d,p,I,args)\n",
    "    @input document d, maximum number of keywords p, inverted index I, and op-\n",
    "    tional arguments on IR model choices\n",
    "\n",
    "    @behavior extracts the top informative p keywords in d against I according to args\n",
    "    \n",
    "    @output ordered set of p keywords\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goldfinger: 4.354976755313726\n",
      "goldeneye: 3.7342276913546106\n",
      "bond: 3.6992505932864606\n",
      "masterminds: 3.3473300153169503\n",
      "commander-in-chief: 3.3473300153169503\n",
      "juices: 3.3473300153169503\n",
      "nightfire: 3.3473300153169503\n",
      "aura: 3.3473300153169503\n",
      "crosshair: 3.3473300153169503\n",
      "firefights: 3.3473300153169503\n",
      "{'goldfinger': 4.354976755313726, 'goldeneye': 3.7342276913546106, 'bond': 3.6992505932864606, 'masterminds': 3.3473300153169503, 'commander-in-chief': 3.3473300153169503, 'juices': 3.3473300153169503, 'nightfire': 3.3473300153169503, 'aura': 3.3473300153169503, 'crosshair': 3.3473300153169503, 'firefights': 3.3473300153169503}\n"
     ]
    }
   ],
   "source": [
    "def keyword_extraction(article: str, max_num: int, inverted_index: dict, N: int, article_id: int, use_only_nouns=False, args=None) -> dict: \n",
    "    # tokenizer split words and keep hyphons e.g. state-of-the-art\n",
    "    tokenizer = RegexpTokenizer(r'[\\w|-]+')\n",
    "    # tokenize sentences\n",
    "    sents = nltk.sent_tokenize(article)\n",
    "    # remove title (not needed for summarization task)\n",
    "    sents = sents[1:]\n",
    "    \n",
    "    # get words per document\n",
    "    # either use all words or only nouns\n",
    "    if use_only_nouns: \n",
    "        #tagger = SennaChunkTagger('/usr/share/senna-v3.0/senna')\n",
    "        words_per_doc = list()\n",
    "        for sent in sents: \n",
    "            words = tokenizer.tokenize(sent.lower())\n",
    "            \n",
    "            # senna chunk tagging of nouns \n",
    "            # not sure if needed, just a test\n",
    "            #tags = tagger.tag(words)\n",
    "            #chunks = list(tagger.bio_to_chunks(tags, chunk_type='N'))\n",
    "\n",
    "            # nltk pos tag \n",
    "            tagged_words = nltk.pos_tag(words)\n",
    "            named_entities = nltk.ne_chunk(tagged_words)\n",
    "            for word, tag in named_entities:\n",
    "                if 'NN' in tag: \n",
    "                    words_per_doc.append(word)\n",
    "    else: \n",
    "        words_per_sent = [set(tokenizer.tokenize(sent.lower())) for sent in sents]\n",
    "        words_per_doc = flatten(words_per_sent)\n",
    "\n",
    "    doc_tf_idf = defaultdict(str)\n",
    "    for word in words_per_doc: \n",
    "        # inverse document frequency (idf)\n",
    "        idf = math.log10(N/len(inverted_index[word]))\n",
    "        # term frequency (tf) by document\n",
    "        # get it from inverted index \n",
    "        doc_tf = inverted_index[word][article_id]\n",
    "        doc_tf = 1 + math.log10(doc_tf)\n",
    "\n",
    "        # tf-idf for the document \n",
    "        doc_tf_idf[word] = doc_tf * idf\n",
    "    \n",
    "    doc_tf_idf = dict(sorted(doc_tf_idf.items(), key=lambda item: item[1], reverse=True)[:max_num])\n",
    "    for word in doc_tf_idf: \n",
    "        print(f\"{word}: {doc_tf_idf[word]}\")\n",
    "    print(doc_tf_idf)\n",
    "\n",
    "keyword_extraction(articles[0], 10, inverted_index, len(articles), 0, use_only_nouns=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "TODO:\n",
    "* Implement evaluation\n",
    "* Evaluation:\n",
    "    * Statistics \n",
    "    * F-meassure\n",
    "    * Recall-precision-curve\n",
    "    * MAP\n",
    "    * Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nevaluation(Sset,Rset,args)\\n    @input the set of summaries Sset produced from selected documents Dset ⊆ D\\n    (e.g. a single document, a category of documents, the whole collection),\\n    the corresponding reference extracts Rset, and optional arguments (evalu-\\n    ation, preprocessing, model options)\\n\\n    @behavior assesses the produced summaries against the reference ones using the tar-\\n    get evaluation criteria\\n\\n    @output evaluation statistics, including F-measuring at predefined p-or-l summary\\n    limits, recall-and-precision curves, MAP, and efficiency\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "evaluation(Sset,Rset,args)\n",
    "    @input the set of summaries Sset produced from selected documents Dset ⊆ D\n",
    "    (e.g. a single document, a category of documents, the whole collection),\n",
    "    the corresponding reference extracts Rset, and optional arguments (evalu-\n",
    "    ation, preprocessing, model options)\n",
    "\n",
    "    @behavior assesses the produced summaries against the reference ones using the tar-\n",
    "    get evaluation criteria\n",
    "\n",
    "    @output evaluation statistics, including F-measuring at predefined p-or-l summary\n",
    "    limits, recall-and-precision curves, MAP, and efficiency\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(S: list, R: list, args=None) -> list:\n",
    "    # do evaluation... \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) **Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.1 Summarization solution: results for a given document*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bond game fails to shake or stir\n",
      "\n",
      "For gaming fans, the word GoldenEye evokes excited memories not only of the James Bond revival flick of 1995, but also the classic shoot-em-up that accompanied it and left N64 owners glued to their consoles for many an hour.\n",
      "\n",
      "Adopting that hallowed title somewhat backfires on this new game, for it fails to deliver on the promise of its name and struggles to generate the original's massive sense of fun. This however is not a sequel, nor does it relate to the GoldenEye film. You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6. Your new commander-in-chief is the portly Auric Goldfinger, last seen in 1964, but happily running around bent on world domination. With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "\n",
      "Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter. The notion is of course to add a novel dark edge to a 007 game, but the premise simply does not get the juices flowing like it needs to.\n",
      "\n",
      "Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise. This title lacks that aura, and when the Bond magic shines through, it feels like a lucky accident. The central problem is that the gameplay just is not good enough. Quite aside from the bizarre inability to jump, the even more bizarre glaring graphical bugs and dubious enemy AI, the levels simply are not put together with much style or imagination. Admittedly the competition has been tough, even in recent weeks, with the likes of Halo 2 and Half Life 2 triumphing in virtually every department. What the game is good at is enveloping you in noisy, dynamic scenes of violent chaos. As is the trend of late, you are made to feel like you are in the midst of a really messy and fraught encounter. Sadly that sense of action is outweighed by the difficulty of navigating and battling within the chaos, meaning that frustration is often the outcome. And irregular save points mean you have to backtrack each time you are killed. A minute red dot passes for a crosshair, although the collision-detection is so suspect that the difficulties of aiming weapons are compensated for. Shooting enemies from a distance can be tricky, and you will not always know you have picked them off, since dead enemies vanish literally before they have fully hit the floor, and they do so in some woefully uninspiring death animations. It is perhaps indicative of a lack of confidence that the game maker's allow you several different weapons almost immediately and throw you quickly into raging firefights - no time is risked with a measured build-up.\n",
      "\n",
      "By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "\n",
      "There is a real thrill from doing battle with these legendary villains, and it is a testament to the power of the Bond universe that they can cut such a dash. But the in-game niggles, combined with a story and presentation that just do not feel sufficiently well thought-through, will make this a disappointment for most. Diehard fans of Bond will probably find enough here to make it a worthwhile purchase and try to ignore the failings. The game is weak, not completely unplayable. Then again, 007 fanatics may also take umbrage at the cavalier blending of characters from different eras. Given James Bond's healthy pedigree in past games, there is every reason to hope that this is just a blip, a commendable idea that just has not worked, that will be rectified when the character inevitably makes his return.\n",
      "\n",
      "GoldenEye: Rogue Agent is out now\n",
      "\n",
      "0.2495193303958334: By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "0.21019493577531412: Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter.\n",
      "0.20079836196045564: You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6.\n",
      "0.1995382299926325: With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "0.19033491063190966: Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{19: 0.2495193303958334,\n",
       " 5: 0.21019493577531412,\n",
       " 2: 0.20079836196045564,\n",
       " 4: 0.1995382299926325,\n",
       " 7: 0.19033491063190966}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code, statistics and/or charts here\n",
    "article_id = 0\n",
    "print(articles[article_id])\n",
    "summarization(articles[article_id], num_sent=5, order=\"rel\", inverted_index=inverted_index, N=len(articles), article_id=article_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.2 IR models (TF-IDF, BM25 and EBRT)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.3 Reciprocal rank funsion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.4 Maximal Marginal Relevance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) **Keyword extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bond game fails to shake or stir\n",
      "\n",
      "For gaming fans, the word GoldenEye evokes excited memories not only of the James Bond revival flick of 1995, but also the classic shoot-em-up that accompanied it and left N64 owners glued to their consoles for many an hour.\n",
      "\n",
      "Adopting that hallowed title somewhat backfires on this new game, for it fails to deliver on the promise of its name and struggles to generate the original's massive sense of fun. This however is not a sequel, nor does it relate to the GoldenEye film. You are the eponymous renegade spy, an agent who deserts to the Bond world's extensive ranks of criminal masterminds, after being deemed too brutal for MI6. Your new commander-in-chief is the portly Auric Goldfinger, last seen in 1964, but happily running around bent on world domination. With a determination to justify its name which is even less convincing than that of Tina Turner's similarly-titled theme song, the game literally gives the player a golden eye following an injury, which enables a degree of X-ray vision.\n",
      "\n",
      "Rogue Agent signals its intentions by featuring James Bond initially and proceeding to kill him off within moments, squashed by a plummeting helicopter. The notion is of course to add a novel dark edge to a 007 game, but the premise simply does not get the juices flowing like it needs to.\n",
      "\n",
      "Recent Bond games like Nightfire and Everything Or Nothing were very competent and did a fine job of capturing the sense of flair, invention and glamour of the film franchise. This title lacks that aura, and when the Bond magic shines through, it feels like a lucky accident. The central problem is that the gameplay just is not good enough. Quite aside from the bizarre inability to jump, the even more bizarre glaring graphical bugs and dubious enemy AI, the levels simply are not put together with much style or imagination. Admittedly the competition has been tough, even in recent weeks, with the likes of Halo 2 and Half Life 2 triumphing in virtually every department. What the game is good at is enveloping you in noisy, dynamic scenes of violent chaos. As is the trend of late, you are made to feel like you are in the midst of a really messy and fraught encounter. Sadly that sense of action is outweighed by the difficulty of navigating and battling within the chaos, meaning that frustration is often the outcome. And irregular save points mean you have to backtrack each time you are killed. A minute red dot passes for a crosshair, although the collision-detection is so suspect that the difficulties of aiming weapons are compensated for. Shooting enemies from a distance can be tricky, and you will not always know you have picked them off, since dead enemies vanish literally before they have fully hit the floor, and they do so in some woefully uninspiring death animations. It is perhaps indicative of a lack of confidence that the game maker's allow you several different weapons almost immediately and throw you quickly into raging firefights - no time is risked with a measured build-up.\n",
      "\n",
      "By far the most satisfying element of the game is seeing old favourites like Dr No, Goldfinger, hat-fiend Oddjob and crazed Russian sex beast Xenia Onatopp resurrected after all these years, and with their faces rendered in an impressively recognisable fashion.\n",
      "\n",
      "There is a real thrill from doing battle with these legendary villains, and it is a testament to the power of the Bond universe that they can cut such a dash. But the in-game niggles, combined with a story and presentation that just do not feel sufficiently well thought-through, will make this a disappointment for most. Diehard fans of Bond will probably find enough here to make it a worthwhile purchase and try to ignore the failings. The game is weak, not completely unplayable. Then again, 007 fanatics may also take umbrage at the cavalier blending of characters from different eras. Given James Bond's healthy pedigree in past games, there is every reason to hope that this is just a blip, a commendable idea that just has not worked, that will be rectified when the character inevitably makes his return.\n",
      "\n",
      "GoldenEye: Rogue Agent is out now\n",
      "\n",
      "goldfinger: 4.354976755313726\n",
      "goldeneye: 3.7342276913546106\n",
      "bond: 3.6992505932864606\n",
      "masterminds: 3.3473300153169503\n",
      "commander-in-chief: 3.3473300153169503\n",
      "juices: 3.3473300153169503\n",
      "nightfire: 3.3473300153169503\n",
      "aura: 3.3473300153169503\n",
      "crosshair: 3.3473300153169503\n",
      "firefights: 3.3473300153169503\n",
      "{'goldfinger': 4.354976755313726, 'goldeneye': 3.7342276913546106, 'bond': 3.6992505932864606, 'masterminds': 3.3473300153169503, 'commander-in-chief': 3.3473300153169503, 'juices': 3.3473300153169503, 'nightfire': 3.3473300153169503, 'aura': 3.3473300153169503, 'crosshair': 3.3473300153169503, 'firefights': 3.3473300153169503}\n"
     ]
    }
   ],
   "source": [
    "#code, statistics and/or charts here\n",
    "article_id = 0\n",
    "print(articles[article_id])\n",
    "keyword_extraction(articles[0], 10, inverted_index, len(articles), 0, use_only_nouns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D) **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Part II: questions materials (optional)</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** Corpus *D* and summaries *S* description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** Summarization performance for the overall and category-conditional corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**...** (additional questions with empirical results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>END</H3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
